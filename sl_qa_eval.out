rdzv_endpoint: worker-4:40000
[32m2023-10-18T00:40:54 | loopitr: [0mLogging to: /home/wiss/zhang/Jinhe/singularity/anet_qa/anetqa_show/train.log
[32m2023-10-18T00:40:54 | __main__: [0mconfig: 
{'dataset_name': 'anet', 'data_root': '/home/wiss/zhang/nfs/Anet_sing', 'anno_root_downstream': '/home/wiss/zhang/Jinhe/singularity/anno_downstream_ori', 'train_file': [['/nfs/data2/zhang/AnetQA/qa_train/qa_train_light.json', '/home/wiss/zhang/nfs/Anet_sing', 'video']], 'test_types': ['val'], 'test_file': {'val': ['/nfs/data2/zhang/AnetQA/qa_val/qa_val_light.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'test': ['/nfs/data2/zhang/AnetQA/qa_val/qa_val_light.json', '/home/wiss/zhang/nfs/Anet_sing', 'video']}, 'stop_key': 'val', 'answer_list': '/nfs/data2/zhang/AnetQA/qa_train/answer_list_light.json', 'text_encoder': 'bert-base-uncased', 'text_decoder': 'bert-base-uncased', 'bert_config': 'configs/config_bert.json', 'vit_type': 'beit', 'vit_zoo': {'beit': 'microsoft/beit-base-patch16-224-pt22k-ft22k'}, 'vit_name_or_pretrained_path': '${vit_zoo[${vit_type}]}', 'temporal_vision_encoder': {'enable': False, 'num_layers': 2, 'update_pooler_embed': False}, 'add_temporal_embed': False, 'image_res': 224, 'embed_dim': 256, 'video_input': {'num_frames': 1, 'reader': 'decord', 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle'}, 'batch_size': {'image': 128, 'video': 32}, 'batch_size_test': {'image': 64, 'video': 64}, 'k_test': 128, 'temp': 0.07, 'eos': '[SEP]', 'max_q_len': 25, 'max_a_len': 5, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 10, 'min_lr_multi': 0.1, 'warmup_epochs': 0.5}, 'output_dir': '/home/wiss/zhang/Jinhe/singularity/anet_qa/anetqa_show', 'pretrained_path': '/home/wiss/zhang/Jinhe/singularity/anet_qa/ft_anet_qa_singularity_17m.pth', 'resume': False, 'evaluate': True, 'eval_frame_ensemble': 'concat', 'device': 'cuda', 'seed': 42, 'log_freq': 100, 'dist_url': 'env://', 'distributed': True, 'fp16': True, 'debug': False, 'num_workers': 24, 'wandb': {'enable': False, 'entity': 'gengyuanzhang', 'project': 'vqa'}, 'rank': 0, 'world_size': 1, 'gpu': 0, 'dist_backend': 'nccl', 'result_dir': '/home/wiss/zhang/Jinhe/singularity/anet_qa/anetqa_show'}
[32m2023-10-18T00:40:54 | __main__: [0mtrain_file: [['/nfs/data2/zhang/AnetQA/qa_train/qa_train_light.json', '/home/wiss/zhang/nfs/Anet_sing', 'video']]
[32m2023-10-18T00:40:54 | __main__: [0mCreating vqa QA datasets
[5m[31mWARNING[0m [32m2023-10-18T00:40:58 | py.warnings: [0m/home/wiss/zhang/Jinhe/singularity/utils/distributed.py:18: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2023-10-18T00:40:58 | py.warnings: [0m/home/wiss/zhang/Jinhe/singularity/utils/distributed.py:18: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  builtin_warn(*args, **kwargs)

[32m2023-10-18T00:40:58 | tasks.shared_utils: [0mCreating model
[32m2023-10-18T00:41:08 | models.model_retrieval_base: [0mLoading vit pre-trained weights from huggingface microsoft/beit-base-patch16-224-pt22k-ft22k.
[5m[31mWARNING[0m [32m2023-10-18T00:42:05 | py.warnings: [0m/home/wiss/zhang/anaconda3/envs/probe-sl/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

[5m[31mWARNING[0m [32m2023-10-18T00:42:05 | py.warnings: [0m/home/wiss/zhang/anaconda3/envs/probe-sl/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

[32m2023-10-18T00:42:07 | models.model_retrieval_base: [0mInit new model with new image size 224, and load weights.
[32m2023-10-18T00:42:11 | models.model_retrieval_base: [0m_IncompatibleKeys(missing_keys=['encoder.layer.0.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.1.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.2.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.3.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.4.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.5.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.6.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.7.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.8.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.9.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.10.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.11.attention.attention.relative_position_bias.relative_position_index'], unexpected_keys=[])
[32m2023-10-18T00:42:11 | models.model_retrieval_base: [0mBuild text_encoder bert-base-uncased
[32m2023-10-18T00:42:59 | models.model_retrieval_base: [0mBuild text_encoder bert-base-uncased, done!
[32m2023-10-18T00:42:59 | models.model_vqa: [0mBuild text_decoder bert-base-uncased
[32m2023-10-18T00:43:03 | models.model_vqa: [0mBuild text_decoder bert-base-uncased, done!
[32m2023-10-18T00:43:04 | utils.optimizer: [0moptimizer -- lr=1e-05 wd=0.02 len(p)=208
[32m2023-10-18T00:43:04 | utils.optimizer: [0moptimizer -- lr=1e-05 wd=0 len(p)=329
[32m2023-10-18T00:43:04 | tasks.shared_utils: [0mLoading checkpoint from /home/wiss/zhang/Jinhe/singularity/anet_qa/ft_anet_qa_singularity_17m.pth
[32m2023-10-18T00:47:28 | models.utils: [0mLoad temporal_embeddings, lengths: 64-->1
[32m2023-10-18T00:47:29 | tasks.shared_utils: [0m<All keys matched successfully>
[32m2023-10-18T00:47:29 | tasks.shared_utils: [0mLoaded checkpoint from /home/wiss/zhang/Jinhe/singularity/anet_qa/ft_anet_qa_singularity_17m.pth
[32m2023-10-18T00:47:29 | __main__: [0mStart evaluation
[32m2023-10-18T00:47:29 | __main__: [0mEvaluating val split...
[32m2023-10-18T00:47:30 | __main__: [0mStart generating results.
[32m2023-10-18T01:04:03 | utils.basic_utils: [0m[evaluation] Generating answers:  [ 0/74]  eta: 20:24:11    time: 992.5852  data: 546.0016  max mem: 13488 res mem: 15992
[32m2023-10-18T01:07:21 | utils.basic_utils: [0m[evaluation] Generating answers:  [50/74]  eta: 0:09:20    time: 8.1165  data: 6.2821  max mem: 13489 res mem: 15992
[32m2023-10-18T01:07:42 | utils.basic_utils: [0m[evaluation] Generating answers:  [73/74]  eta: 0:00:16    time: 0.8417  data: 0.2645  max mem: 13489 res mem: 15992
[32m2023-10-18T01:07:42 | utils.basic_utils: [0m[evaluation] Generating answers: Total time: 0:20:11 (16.3730 s / it)
[32m2023-10-18T01:07:43 | dataset.utils: [0mresult file saved to /home/wiss/zhang/Jinhe/singularity/anet_qa/anetqa_show/val_latest.json
[32m2023-10-18T01:07:43 | tasks.vqa_utils: [0mMissing predictions for 0 questions, example[:3] []
[32m2023-10-18T01:07:43 | __main__: [0mSkip eval test split. All test_types ['val']
[32m2023-10-18T01:07:43 | __main__: [0meval_res {'val': {'overall': 20.64}}
[32m2023-10-18T01:07:44 | __main__: [0mTraining time 0:20:14
[32m2023-10-18T01:07:44 | __main__: [0mbest epoch 0
[32m2023-10-18T01:07:44 | __main__: [0mCheckpoints and Logs saved at /home/wiss/zhang/Jinhe/singularity/anet_qa/anetqa_show
