output dir >> /home/wiss/zhang/Jinhe/singularity/neg/ret_anet/anet_anet_neg
rdzv_endpoint: zypern:22347
[32m2023-10-19T19:57:22 | loopitr: [0mLogging to: /home/wiss/zhang/Jinhe/singularity/neg/ret_anet/anet_anet_neg/train.log

[32m2023-10-19T19:57:31 | __main__: [0mconfig: 
{'data_root': '/home/wiss/zhang/nfs/Anet_sing', 'anno_root_downstream': '/home/wiss/zhang/Jinhe/singularity/Data/anetqa', 'train_type': 'anet_ret_train_3.json', 'train_file': ['${anno_root_downstream}/${train_type}', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'test_types': ['temporal_contact_swap', 'temporal_contact_swap_mani', 'temporal_action_swap', 'temporal_action_swap_mani', 'neighborhood_same_entity', 'neighborhood_same_entity_mani', 'neighborhood_diff_entity', 'neighborhood_diff_entity_mani', 'counter_spatial', 'counter_spatial_mani', 'counter_contact', 'counter_contact_mani', 'counter_action', 'counter_action_mani', 'counter_attribute', 'counter_attribute_mani'], 'test_file': {'temporal_contact_swap': ['${anno_root_downstream}/anet_ret_temporal_contact_swap.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'temporal_contact_swap_mani': ['${anno_root_downstream}/anet_ret_temporal_contact_swap_mani.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'temporal_action_swap': ['${anno_root_downstream}/anet_ret_temporal_action_swap.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'temporal_action_swap_mani': ['${anno_root_downstream}/anet_ret_temporal_action_swap_mani.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'neighborhood_same_entity': ['${anno_root_downstream}/anet_ret_neighborhood_same_entity.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'neighborhood_same_entity_mani': ['${anno_root_downstream}/anet_ret_neighborhood_same_entity_mani.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'neighborhood_diff_entity': ['${anno_root_downstream}/anet_ret_neighborhood_diff_entity.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'neighborhood_diff_entity_mani': ['${anno_root_downstream}/anet_ret_neighborhood_diff_entity_mani.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'counter_spatial': ['${anno_root_downstream}/anet_ret_counter_spatial.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'counter_spatial_mani': ['${anno_root_downstream}/anet_ret_counter_spatial_mani.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'counter_contact': ['${anno_root_downstream}/anet_ret_counter_contact.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'counter_contact_mani': ['${anno_root_downstream}/anet_ret_counter_contact_mani.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'counter_action': ['${anno_root_downstream}/anet_ret_counter_action.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'counter_action_mani': ['${anno_root_downstream}/anet_ret_counter_action_mani.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'counter_attribute': ['${anno_root_downstream}/anet_ret_counter_attribute.json', '/home/wiss/zhang/nfs/Anet_sing', 'video'], 'counter_attribute_mani': ['${anno_root_downstream}/anet_ret_counter_attribute_mani.json', '/home/wiss/zhang/nfs/Anet_sing', 'video']}, 'stop_key': 'val1/', 'is_paragraph_retrieval': True, 'text_encoder': 'bert-base-uncased', 'bert_config': 'configs/config_bert.json', 'vit_type': 'beit', 'vit_zoo': {'beit': 'microsoft/beit-base-patch16-224-pt22k-ft22k'}, 'vit_name_or_pretrained_path': '${vit_zoo[${vit_type}]}', 'temporal_vision_encoder': {'enable': True, 'num_layers': 2, 'update_pooler_embed': False}, 'add_temporal_embed': True, 'image_res': 224, 'embed_dim': 256, 'video_input': {'num_frames': 4, 'reader': 'decord', 'sample_type': 'rand', 'num_frames_test': 4, 'sample_type_test': 'middle'}, 'max_txt_l': 60, 'batch_size': {'image': 160, 'video': 4}, 'batch_size_test': {'image': 128, 'video': 32}, 'k_test': 128, 'temp': 0.01, 'loss_weight': {'itc': 1.0, 'itm': 1.0}, 'itm_hard_neg': True, 'optimizer': {'opt': 'adamW', 'lr': 1e-05, 'opt_betas': [0.9, 0.999], 'weight_decay': 0.02, 'max_grad_norm': -1, 'different_lr': {'enable': False, 'module_names': [], 'lr': 0.001}}, 'scheduler': {'sched': 'cosine', 'epochs': 30, 'min_lr_multi': 0.1, 'warmup_epochs': 0, 'epoch': 30}, 'output_dir': '/home/wiss/zhang/Jinhe/singularity/neg/ret_anet/anet_anet_neg', 'resume': False, 'pretrained_path': '/home/wiss/zhang/nfs/anetqa_train_qa_full/ckpt_best.pth', 'evaluate': False, 'eval_frame_ensemble': 'concat', 'eval_x_only': False, 'eval_offload': True, 'device': 'cuda', 'seed': 3, 'log_freq': 100, 'dist_url': 'env://', 'distributed': True, 'fp16': True, 'debug': False, 'num_workers': 24, 'wandb': {'enable': True, 'entity': 'gengyuanzhang', 'project': 'sb_ret_anet'}, 'save_path': '/home/wiss/zhang/nfs/video_prober/singularity/anetqa/', '22347': None, 'rank': 0, 'world_size': 1, 'gpu': 0, 'dist_backend': 'nccl'}
[32m2023-10-19T19:57:31 | __main__: [0mtrain_file: ['${anno_root_downstream}/${train_type}', '/home/wiss/zhang/nfs/Anet_sing', 'video']
[32m2023-10-19T19:57:31 | tasks.pretrain: [0mCreating dataset for ret
[5m[31mWARNING[0m [32m2023-10-19T19:57:31 | py.warnings: [0m/home/wiss/zhang/Jinhe/singularity/utils/distributed.py:18: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2023-10-19T19:57:31 | py.warnings: [0m/home/wiss/zhang/Jinhe/singularity/utils/distributed.py:18: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  builtin_warn(*args, **kwargs)

[32m2023-10-19T19:57:31 | tasks.shared_utils: [0mCreating model
[32m2023-10-19T19:57:38 | models.model_retrieval_base: [0mLoading vit pre-trained weights from huggingface microsoft/beit-base-patch16-224-pt22k-ft22k.
[5m[31mWARNING[0m [32m2023-10-19T19:57:44 | py.warnings: [0m/home/wiss/zhang/anaconda3/envs/probe-sl/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

[5m[31mWARNING[0m [32m2023-10-19T19:57:44 | py.warnings: [0m/home/wiss/zhang/anaconda3/envs/probe-sl/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]

[32m2023-10-19T19:57:45 | models.model_retrieval_base: [0mInit new model with new image size 224, and load weights.
[32m2023-10-19T19:57:47 | models.model_retrieval_base: [0m_IncompatibleKeys(missing_keys=['encoder.layer.0.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.1.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.2.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.3.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.4.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.5.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.6.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.7.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.8.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.9.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.10.attention.attention.relative_position_bias.relative_position_index', 'encoder.layer.11.attention.attention.relative_position_bias.relative_position_index'], unexpected_keys=[])
[32m2023-10-19T19:57:47 | models.model_retrieval_base: [0mBuild text_encoder bert-base-uncased
[32m2023-10-19T19:57:53 | models.model_retrieval_base: [0mBuild text_encoder bert-base-uncased, done!
[32m2023-10-19T19:57:53 | models.model_retrieval_base: [0mBuild temporal_vision_encoder (#layer=2), randomly initialised.
[32m2023-10-19T19:57:53 | models.model_retrieval_base: [0mBuild temporal_vision_encoder, done!
[32m2023-10-19T19:57:54 | utils.optimizer: [0moptimizer -- lr=1e-05 wd=0.02 len(p)=190
[32m2023-10-19T19:57:54 | utils.optimizer: [0moptimizer -- lr=1e-05 wd=0 len(p)=300
[32m2023-10-19T19:57:54 | tasks.shared_utils: [0mLoading checkpoint from /home/wiss/zhang/nfs/anetqa_train_qa_full/ckpt_best.pth
state_dict.keys():  odict_keys(['temporal_embeddings', 'vision_encoder.embeddings.cls_token', 'vision_encoder.embeddings.patch_embeddings.projection.weight', 'vision_encoder.embeddings.patch_embeddings.projection.bias', 'vision_encoder.encoder.layer.0.lambda_1', 'vision_encoder.encoder.layer.0.lambda_2', 'vision_encoder.encoder.layer.0.attention.attention.query.weight', 'vision_encoder.encoder.layer.0.attention.attention.query.bias', 'vision_encoder.encoder.layer.0.attention.attention.key.weight', 'vision_encoder.encoder.layer.0.attention.attention.value.weight', 'vision_encoder.encoder.layer.0.attention.attention.value.bias', 'vision_encoder.encoder.layer.0.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.0.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.0.attention.output.dense.weight', 'vision_encoder.encoder.layer.0.attention.output.dense.bias', 'vision_encoder.encoder.layer.0.intermediate.dense.weight', 'vision_encoder.encoder.layer.0.intermediate.dense.bias', 'vision_encoder.encoder.layer.0.output.dense.weight', 'vision_encoder.encoder.layer.0.output.dense.bias', 'vision_encoder.encoder.layer.0.layernorm_before.weight', 'vision_encoder.encoder.layer.0.layernorm_before.bias', 'vision_encoder.encoder.layer.0.layernorm_after.weight', 'vision_encoder.encoder.layer.0.layernorm_after.bias', 'vision_encoder.encoder.layer.1.lambda_1', 'vision_encoder.encoder.layer.1.lambda_2', 'vision_encoder.encoder.layer.1.attention.attention.query.weight', 'vision_encoder.encoder.layer.1.attention.attention.query.bias', 'vision_encoder.encoder.layer.1.attention.attention.key.weight', 'vision_encoder.encoder.layer.1.attention.attention.value.weight', 'vision_encoder.encoder.layer.1.attention.attention.value.bias', 'vision_encoder.encoder.layer.1.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.1.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.1.attention.output.dense.weight', 'vision_encoder.encoder.layer.1.attention.output.dense.bias', 'vision_encoder.encoder.layer.1.intermediate.dense.weight', 'vision_encoder.encoder.layer.1.intermediate.dense.bias', 'vision_encoder.encoder.layer.1.output.dense.weight', 'vision_encoder.encoder.layer.1.output.dense.bias', 'vision_encoder.encoder.layer.1.layernorm_before.weight', 'vision_encoder.encoder.layer.1.layernorm_before.bias', 'vision_encoder.encoder.layer.1.layernorm_after.weight', 'vision_encoder.encoder.layer.1.layernorm_after.bias', 'vision_encoder.encoder.layer.2.lambda_1', 'vision_encoder.encoder.layer.2.lambda_2', 'vision_encoder.encoder.layer.2.attention.attention.query.weight', 'vision_encoder.encoder.layer.2.attention.attention.query.bias', 'vision_encoder.encoder.layer.2.attention.attention.key.weight', 'vision_encoder.encoder.layer.2.attention.attention.value.weight', 'vision_encoder.encoder.layer.2.attention.attention.value.bias', 'vision_encoder.encoder.layer.2.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.2.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.2.attention.output.dense.weight', 'vision_encoder.encoder.layer.2.attention.output.dense.bias', 'vision_encoder.encoder.layer.2.intermediate.dense.weight', 'vision_encoder.encoder.layer.2.intermediate.dense.bias', 'vision_encoder.encoder.layer.2.output.dense.weight', 'vision_encoder.encoder.layer.2.output.dense.bias', 'vision_encoder.encoder.layer.2.layernorm_before.weight', 'vision_encoder.encoder.layer.2.layernorm_before.bias', 'vision_encoder.encoder.layer.2.layernorm_after.weight', 'vision_encoder.encoder.layer.2.layernorm_after.bias', 'vision_encoder.encoder.layer.3.lambda_1', 'vision_encoder.encoder.layer.3.lambda_2', 'vision_encoder.encoder.layer.3.attention.attention.query.weight', 'vision_encoder.encoder.layer.3.attention.attention.query.bias', 'vision_encoder.encoder.layer.3.attention.attention.key.weight', 'vision_encoder.encoder.layer.3.attention.attention.value.weight', 'vision_encoder.encoder.layer.3.attention.attention.value.bias', 'vision_encoder.encoder.layer.3.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.3.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.3.attention.output.dense.weight', 'vision_encoder.encoder.layer.3.attention.output.dense.bias', 'vision_encoder.encoder.layer.3.intermediate.dense.weight', 'vision_encoder.encoder.layer.3.intermediate.dense.bias', 'vision_encoder.encoder.layer.3.output.dense.weight', 'vision_encoder.encoder.layer.3.output.dense.bias', 'vision_encoder.encoder.layer.3.layernorm_before.weight', 'vision_encoder.encoder.layer.3.layernorm_before.bias', 'vision_encoder.encoder.layer.3.layernorm_after.weight', 'vision_encoder.encoder.layer.3.layernorm_after.bias', 'vision_encoder.encoder.layer.4.lambda_1', 'vision_encoder.encoder.layer.4.lambda_2', 'vision_encoder.encoder.layer.4.attention.attention.query.weight', 'vision_encoder.encoder.layer.4.attention.attention.query.bias', 'vision_encoder.encoder.layer.4.attention.attention.key.weight', 'vision_encoder.encoder.layer.4.attention.attention.value.weight', 'vision_encoder.encoder.layer.4.attention.attention.value.bias', 'vision_encoder.encoder.layer.4.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.4.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.4.attention.output.dense.weight', 'vision_encoder.encoder.layer.4.attention.output.dense.bias', 'vision_encoder.encoder.layer.4.intermediate.dense.weight', 'vision_encoder.encoder.layer.4.intermediate.dense.bias', 'vision_encoder.encoder.layer.4.output.dense.weight', 'vision_encoder.encoder.layer.4.output.dense.bias', 'vision_encoder.encoder.layer.4.layernorm_before.weight', 'vision_encoder.encoder.layer.4.layernorm_before.bias', 'vision_encoder.encoder.layer.4.layernorm_after.weight', 'vision_encoder.encoder.layer.4.layernorm_after.bias', 'vision_encoder.encoder.layer.5.lambda_1', 'vision_encoder.encoder.layer.5.lambda_2', 'vision_encoder.encoder.layer.5.attention.attention.query.weight', 'vision_encoder.encoder.layer.5.attention.attention.query.bias', 'vision_encoder.encoder.layer.5.attention.attention.key.weight', 'vision_encoder.encoder.layer.5.attention.attention.value.weight', 'vision_encoder.encoder.layer.5.attention.attention.value.bias', 'vision_encoder.encoder.layer.5.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.5.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.5.attention.output.dense.weight', 'vision_encoder.encoder.layer.5.attention.output.dense.bias', 'vision_encoder.encoder.layer.5.intermediate.dense.weight', 'vision_encoder.encoder.layer.5.intermediate.dense.bias', 'vision_encoder.encoder.layer.5.output.dense.weight', 'vision_encoder.encoder.layer.5.output.dense.bias', 'vision_encoder.encoder.layer.5.layernorm_before.weight', 'vision_encoder.encoder.layer.5.layernorm_before.bias', 'vision_encoder.encoder.layer.5.layernorm_after.weight', 'vision_encoder.encoder.layer.5.layernorm_after.bias', 'vision_encoder.encoder.layer.6.lambda_1', 'vision_encoder.encoder.layer.6.lambda_2', 'vision_encoder.encoder.layer.6.attention.attention.query.weight', 'vision_encoder.encoder.layer.6.attention.attention.query.bias', 'vision_encoder.encoder.layer.6.attention.attention.key.weight', 'vision_encoder.encoder.layer.6.attention.attention.value.weight', 'vision_encoder.encoder.layer.6.attention.attention.value.bias', 'vision_encoder.encoder.layer.6.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.6.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.6.attention.output.dense.weight', 'vision_encoder.encoder.layer.6.attention.output.dense.bias', 'vision_encoder.encoder.layer.6.intermediate.dense.weight', 'vision_encoder.encoder.layer.6.intermediate.dense.bias', 'vision_encoder.encoder.layer.6.output.dense.weight', 'vision_encoder.encoder.layer.6.output.dense.bias', 'vision_encoder.encoder.layer.6.layernorm_before.weight', 'vision_encoder.encoder.layer.6.layernorm_before.bias', 'vision_encoder.encoder.layer.6.layernorm_after.weight', 'vision_encoder.encoder.layer.6.layernorm_after.bias', 'vision_encoder.encoder.layer.7.lambda_1', 'vision_encoder.encoder.layer.7.lambda_2', 'vision_encoder.encoder.layer.7.attention.attention.query.weight', 'vision_encoder.encoder.layer.7.attention.attention.query.bias', 'vision_encoder.encoder.layer.7.attention.attention.key.weight', 'vision_encoder.encoder.layer.7.attention.attention.value.weight', 'vision_encoder.encoder.layer.7.attention.attention.value.bias', 'vision_encoder.encoder.layer.7.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.7.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.7.attention.output.dense.weight', 'vision_encoder.encoder.layer.7.attention.output.dense.bias', 'vision_encoder.encoder.layer.7.intermediate.dense.weight', 'vision_encoder.encoder.layer.7.intermediate.dense.bias', 'vision_encoder.encoder.layer.7.output.dense.weight', 'vision_encoder.encoder.layer.7.output.dense.bias', 'vision_encoder.encoder.layer.7.layernorm_before.weight', 'vision_encoder.encoder.layer.7.layernorm_before.bias', 'vision_encoder.encoder.layer.7.layernorm_after.weight', 'vision_encoder.encoder.layer.7.layernorm_after.bias', 'vision_encoder.encoder.layer.8.lambda_1', 'vision_encoder.encoder.layer.8.lambda_2', 'vision_encoder.encoder.layer.8.attention.attention.query.weight', 'vision_encoder.encoder.layer.8.attention.attention.query.bias', 'vision_encoder.encoder.layer.8.attention.attention.key.weight', 'vision_encoder.encoder.layer.8.attention.attention.value.weight', 'vision_encoder.encoder.layer.8.attention.attention.value.bias', 'vision_encoder.encoder.layer.8.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.8.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.8.attention.output.dense.weight', 'vision_encoder.encoder.layer.8.attention.output.dense.bias', 'vision_encoder.encoder.layer.8.intermediate.dense.weight', 'vision_encoder.encoder.layer.8.intermediate.dense.bias', 'vision_encoder.encoder.layer.8.output.dense.weight', 'vision_encoder.encoder.layer.8.output.dense.bias', 'vision_encoder.encoder.layer.8.layernorm_before.weight', 'vision_encoder.encoder.layer.8.layernorm_before.bias', 'vision_encoder.encoder.layer.8.layernorm_after.weight', 'vision_encoder.encoder.layer.8.layernorm_after.bias', 'vision_encoder.encoder.layer.9.lambda_1', 'vision_encoder.encoder.layer.9.lambda_2', 'vision_encoder.encoder.layer.9.attention.attention.query.weight', 'vision_encoder.encoder.layer.9.attention.attention.query.bias', 'vision_encoder.encoder.layer.9.attention.attention.key.weight', 'vision_encoder.encoder.layer.9.attention.attention.value.weight', 'vision_encoder.encoder.layer.9.attention.attention.value.bias', 'vision_encoder.encoder.layer.9.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.9.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.9.attention.output.dense.weight', 'vision_encoder.encoder.layer.9.attention.output.dense.bias', 'vision_encoder.encoder.layer.9.intermediate.dense.weight', 'vision_encoder.encoder.layer.9.intermediate.dense.bias', 'vision_encoder.encoder.layer.9.output.dense.weight', 'vision_encoder.encoder.layer.9.output.dense.bias', 'vision_encoder.encoder.layer.9.layernorm_before.weight', 'vision_encoder.encoder.layer.9.layernorm_before.bias', 'vision_encoder.encoder.layer.9.layernorm_after.weight', 'vision_encoder.encoder.layer.9.layernorm_after.bias', 'vision_encoder.encoder.layer.10.lambda_1', 'vision_encoder.encoder.layer.10.lambda_2', 'vision_encoder.encoder.layer.10.attention.attention.query.weight', 'vision_encoder.encoder.layer.10.attention.attention.query.bias', 'vision_encoder.encoder.layer.10.attention.attention.key.weight', 'vision_encoder.encoder.layer.10.attention.attention.value.weight', 'vision_encoder.encoder.layer.10.attention.attention.value.bias', 'vision_encoder.encoder.layer.10.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.10.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.10.attention.output.dense.weight', 'vision_encoder.encoder.layer.10.attention.output.dense.bias', 'vision_encoder.encoder.layer.10.intermediate.dense.weight', 'vision_encoder.encoder.layer.10.intermediate.dense.bias', 'vision_encoder.encoder.layer.10.output.dense.weight', 'vision_encoder.encoder.layer.10.output.dense.bias', 'vision_encoder.encoder.layer.10.layernorm_before.weight', 'vision_encoder.encoder.layer.10.layernorm_before.bias', 'vision_encoder.encoder.layer.10.layernorm_after.weight', 'vision_encoder.encoder.layer.10.layernorm_after.bias', 'vision_encoder.encoder.layer.11.lambda_1', 'vision_encoder.encoder.layer.11.lambda_2', 'vision_encoder.encoder.layer.11.attention.attention.query.weight', 'vision_encoder.encoder.layer.11.attention.attention.query.bias', 'vision_encoder.encoder.layer.11.attention.attention.key.weight', 'vision_encoder.encoder.layer.11.attention.attention.value.weight', 'vision_encoder.encoder.layer.11.attention.attention.value.bias', 'vision_encoder.encoder.layer.11.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.11.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.11.attention.output.dense.weight', 'vision_encoder.encoder.layer.11.attention.output.dense.bias', 'vision_encoder.encoder.layer.11.intermediate.dense.weight', 'vision_encoder.encoder.layer.11.intermediate.dense.bias', 'vision_encoder.encoder.layer.11.output.dense.weight', 'vision_encoder.encoder.layer.11.output.dense.bias', 'vision_encoder.encoder.layer.11.layernorm_before.weight', 'vision_encoder.encoder.layer.11.layernorm_before.bias', 'vision_encoder.encoder.layer.11.layernorm_after.weight', 'vision_encoder.encoder.layer.11.layernorm_after.bias', 'vision_layernorm.weight', 'vision_layernorm.bias', 'text_encoder.embeddings.position_ids', 'text_encoder.embeddings.word_embeddings.weight', 'text_encoder.embeddings.position_embeddings.weight', 'text_encoder.embeddings.token_type_embeddings.weight', 'text_encoder.embeddings.LayerNorm.weight', 'text_encoder.embeddings.LayerNorm.bias', 'text_encoder.encoder.layer.0.attention.self.query.weight', 'text_encoder.encoder.layer.0.attention.self.query.bias', 'text_encoder.encoder.layer.0.attention.self.key.weight', 'text_encoder.encoder.layer.0.attention.self.key.bias', 'text_encoder.encoder.layer.0.attention.self.value.weight', 'text_encoder.encoder.layer.0.attention.self.value.bias', 'text_encoder.encoder.layer.0.attention.output.dense.weight', 'text_encoder.encoder.layer.0.attention.output.dense.bias', 'text_encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.0.intermediate.dense.weight', 'text_encoder.encoder.layer.0.intermediate.dense.bias', 'text_encoder.encoder.layer.0.output.dense.weight', 'text_encoder.encoder.layer.0.output.dense.bias', 'text_encoder.encoder.layer.0.output.LayerNorm.weight', 'text_encoder.encoder.layer.0.output.LayerNorm.bias', 'text_encoder.encoder.layer.1.attention.self.query.weight', 'text_encoder.encoder.layer.1.attention.self.query.bias', 'text_encoder.encoder.layer.1.attention.self.key.weight', 'text_encoder.encoder.layer.1.attention.self.key.bias', 'text_encoder.encoder.layer.1.attention.self.value.weight', 'text_encoder.encoder.layer.1.attention.self.value.bias', 'text_encoder.encoder.layer.1.attention.output.dense.weight', 'text_encoder.encoder.layer.1.attention.output.dense.bias', 'text_encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.1.intermediate.dense.weight', 'text_encoder.encoder.layer.1.intermediate.dense.bias', 'text_encoder.encoder.layer.1.output.dense.weight', 'text_encoder.encoder.layer.1.output.dense.bias', 'text_encoder.encoder.layer.1.output.LayerNorm.weight', 'text_encoder.encoder.layer.1.output.LayerNorm.bias', 'text_encoder.encoder.layer.2.attention.self.query.weight', 'text_encoder.encoder.layer.2.attention.self.query.bias', 'text_encoder.encoder.layer.2.attention.self.key.weight', 'text_encoder.encoder.layer.2.attention.self.key.bias', 'text_encoder.encoder.layer.2.attention.self.value.weight', 'text_encoder.encoder.layer.2.attention.self.value.bias', 'text_encoder.encoder.layer.2.attention.output.dense.weight', 'text_encoder.encoder.layer.2.attention.output.dense.bias', 'text_encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.2.intermediate.dense.weight', 'text_encoder.encoder.layer.2.intermediate.dense.bias', 'text_encoder.encoder.layer.2.output.dense.weight', 'text_encoder.encoder.layer.2.output.dense.bias', 'text_encoder.encoder.layer.2.output.LayerNorm.weight', 'text_encoder.encoder.layer.2.output.LayerNorm.bias', 'text_encoder.encoder.layer.3.attention.self.query.weight', 'text_encoder.encoder.layer.3.attention.self.query.bias', 'text_encoder.encoder.layer.3.attention.self.key.weight', 'text_encoder.encoder.layer.3.attention.self.key.bias', 'text_encoder.encoder.layer.3.attention.self.value.weight', 'text_encoder.encoder.layer.3.attention.self.value.bias', 'text_encoder.encoder.layer.3.attention.output.dense.weight', 'text_encoder.encoder.layer.3.attention.output.dense.bias', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.3.intermediate.dense.weight', 'text_encoder.encoder.layer.3.intermediate.dense.bias', 'text_encoder.encoder.layer.3.output.dense.weight', 'text_encoder.encoder.layer.3.output.dense.bias', 'text_encoder.encoder.layer.3.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.attention.self.query.weight', 'text_encoder.encoder.layer.4.attention.self.query.bias', 'text_encoder.encoder.layer.4.attention.self.key.weight', 'text_encoder.encoder.layer.4.attention.self.key.bias', 'text_encoder.encoder.layer.4.attention.self.value.weight', 'text_encoder.encoder.layer.4.attention.self.value.bias', 'text_encoder.encoder.layer.4.attention.output.dense.weight', 'text_encoder.encoder.layer.4.attention.output.dense.bias', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.intermediate.dense.weight', 'text_encoder.encoder.layer.4.intermediate.dense.bias', 'text_encoder.encoder.layer.4.output.dense.weight', 'text_encoder.encoder.layer.4.output.dense.bias', 'text_encoder.encoder.layer.4.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.attention.self.query.weight', 'text_encoder.encoder.layer.5.attention.self.query.bias', 'text_encoder.encoder.layer.5.attention.self.key.weight', 'text_encoder.encoder.layer.5.attention.self.key.bias', 'text_encoder.encoder.layer.5.attention.self.value.weight', 'text_encoder.encoder.layer.5.attention.self.value.bias', 'text_encoder.encoder.layer.5.attention.output.dense.weight', 'text_encoder.encoder.layer.5.attention.output.dense.bias', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.intermediate.dense.weight', 'text_encoder.encoder.layer.5.intermediate.dense.bias', 'text_encoder.encoder.layer.5.output.dense.weight', 'text_encoder.encoder.layer.5.output.dense.bias', 'text_encoder.encoder.layer.5.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.attention.self.query.weight', 'text_encoder.encoder.layer.6.attention.self.query.bias', 'text_encoder.encoder.layer.6.attention.self.key.weight', 'text_encoder.encoder.layer.6.attention.self.key.bias', 'text_encoder.encoder.layer.6.attention.self.value.weight', 'text_encoder.encoder.layer.6.attention.self.value.bias', 'text_encoder.encoder.layer.6.attention.output.dense.weight', 'text_encoder.encoder.layer.6.attention.output.dense.bias', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.intermediate.dense.weight', 'text_encoder.encoder.layer.6.intermediate.dense.bias', 'text_encoder.encoder.layer.6.output.dense.weight', 'text_encoder.encoder.layer.6.output.dense.bias', 'text_encoder.encoder.layer.6.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.attention.self.query.weight', 'text_encoder.encoder.layer.7.attention.self.query.bias', 'text_encoder.encoder.layer.7.attention.self.key.weight', 'text_encoder.encoder.layer.7.attention.self.key.bias', 'text_encoder.encoder.layer.7.attention.self.value.weight', 'text_encoder.encoder.layer.7.attention.self.value.bias', 'text_encoder.encoder.layer.7.attention.output.dense.weight', 'text_encoder.encoder.layer.7.attention.output.dense.bias', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.intermediate.dense.weight', 'text_encoder.encoder.layer.7.intermediate.dense.bias', 'text_encoder.encoder.layer.7.output.dense.weight', 'text_encoder.encoder.layer.7.output.dense.bias', 'text_encoder.encoder.layer.7.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.attention.self.query.weight', 'text_encoder.encoder.layer.8.attention.self.query.bias', 'text_encoder.encoder.layer.8.attention.self.key.weight', 'text_encoder.encoder.layer.8.attention.self.key.bias', 'text_encoder.encoder.layer.8.attention.self.value.weight', 'text_encoder.encoder.layer.8.attention.self.value.bias', 'text_encoder.encoder.layer.8.attention.output.dense.weight', 'text_encoder.encoder.layer.8.attention.output.dense.bias', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.intermediate.dense.weight', 'text_encoder.encoder.layer.8.intermediate.dense.bias', 'text_encoder.encoder.layer.8.output.dense.weight', 'text_encoder.encoder.layer.8.output.dense.bias', 'text_encoder.encoder.layer.8.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.attention.self.query.weight', 'text_encoder.encoder.layer.9.attention.self.query.bias', 'text_encoder.encoder.layer.9.attention.self.key.weight', 'text_encoder.encoder.layer.9.attention.self.key.bias', 'text_encoder.encoder.layer.9.attention.self.value.weight', 'text_encoder.encoder.layer.9.attention.self.value.bias', 'text_encoder.encoder.layer.9.attention.output.dense.weight', 'text_encoder.encoder.layer.9.attention.output.dense.bias', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.crossattention.self.query.weight', 'text_encoder.encoder.layer.9.crossattention.self.query.bias', 'text_encoder.encoder.layer.9.crossattention.self.key.weight', 'text_encoder.encoder.layer.9.crossattention.self.key.bias', 'text_encoder.encoder.layer.9.crossattention.self.value.weight', 'text_encoder.encoder.layer.9.crossattention.self.value.bias', 'text_encoder.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.intermediate.dense.weight', 'text_encoder.encoder.layer.9.intermediate.dense.bias', 'text_encoder.encoder.layer.9.output.dense.weight', 'text_encoder.encoder.layer.9.output.dense.bias', 'text_encoder.encoder.layer.9.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.attention.self.query.weight', 'text_encoder.encoder.layer.10.attention.self.query.bias', 'text_encoder.encoder.layer.10.attention.self.key.weight', 'text_encoder.encoder.layer.10.attention.self.key.bias', 'text_encoder.encoder.layer.10.attention.self.value.weight', 'text_encoder.encoder.layer.10.attention.self.value.bias', 'text_encoder.encoder.layer.10.attention.output.dense.weight', 'text_encoder.encoder.layer.10.attention.output.dense.bias', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.crossattention.self.query.weight', 'text_encoder.encoder.layer.10.crossattention.self.query.bias', 'text_encoder.encoder.layer.10.crossattention.self.key.weight', 'text_encoder.encoder.layer.10.crossattention.self.key.bias', 'text_encoder.encoder.layer.10.crossattention.self.value.weight', 'text_encoder.encoder.layer.10.crossattention.self.value.bias', 'text_encoder.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.intermediate.dense.weight', 'text_encoder.encoder.layer.10.intermediate.dense.bias', 'text_encoder.encoder.layer.10.output.dense.weight', 'text_encoder.encoder.layer.10.output.dense.bias', 'text_encoder.encoder.layer.10.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.attention.self.query.weight', 'text_encoder.encoder.layer.11.attention.self.query.bias', 'text_encoder.encoder.layer.11.attention.self.key.weight', 'text_encoder.encoder.layer.11.attention.self.key.bias', 'text_encoder.encoder.layer.11.attention.self.value.weight', 'text_encoder.encoder.layer.11.attention.self.value.bias', 'text_encoder.encoder.layer.11.attention.output.dense.weight', 'text_encoder.encoder.layer.11.attention.output.dense.bias', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.crossattention.self.query.weight', 'text_encoder.encoder.layer.11.crossattention.self.query.bias', 'text_encoder.encoder.layer.11.crossattention.self.key.weight', 'text_encoder.encoder.layer.11.crossattention.self.key.bias', 'text_encoder.encoder.layer.11.crossattention.self.value.weight', 'text_encoder.encoder.layer.11.crossattention.self.value.bias', 'text_encoder.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.intermediate.dense.weight', 'text_encoder.encoder.layer.11.intermediate.dense.bias', 'text_encoder.encoder.layer.11.output.dense.weight', 'text_encoder.encoder.layer.11.output.dense.bias', 'text_encoder.encoder.layer.11.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.output.LayerNorm.bias', 'temporal_vision_encoder.layer.0.attention.self.query.weight', 'temporal_vision_encoder.layer.0.attention.self.query.bias', 'temporal_vision_encoder.layer.0.attention.self.key.weight', 'temporal_vision_encoder.layer.0.attention.self.key.bias', 'temporal_vision_encoder.layer.0.attention.self.value.weight', 'temporal_vision_encoder.layer.0.attention.self.value.bias', 'temporal_vision_encoder.layer.0.attention.output.dense.weight', 'temporal_vision_encoder.layer.0.attention.output.dense.bias', 'temporal_vision_encoder.layer.0.attention.output.LayerNorm.weight', 'temporal_vision_encoder.layer.0.attention.output.LayerNorm.bias', 'temporal_vision_encoder.layer.0.intermediate.dense.weight', 'temporal_vision_encoder.layer.0.intermediate.dense.bias', 'temporal_vision_encoder.layer.0.output.dense.weight', 'temporal_vision_encoder.layer.0.output.dense.bias', 'temporal_vision_encoder.layer.0.output.LayerNorm.weight', 'temporal_vision_encoder.layer.0.output.LayerNorm.bias', 'temporal_vision_encoder.layer.1.attention.self.query.weight', 'temporal_vision_encoder.layer.1.attention.self.query.bias', 'temporal_vision_encoder.layer.1.attention.self.key.weight', 'temporal_vision_encoder.layer.1.attention.self.key.bias', 'temporal_vision_encoder.layer.1.attention.self.value.weight', 'temporal_vision_encoder.layer.1.attention.self.value.bias', 'temporal_vision_encoder.layer.1.attention.output.dense.weight', 'temporal_vision_encoder.layer.1.attention.output.dense.bias', 'temporal_vision_encoder.layer.1.attention.output.LayerNorm.weight', 'temporal_vision_encoder.layer.1.attention.output.LayerNorm.bias', 'temporal_vision_encoder.layer.1.intermediate.dense.weight', 'temporal_vision_encoder.layer.1.intermediate.dense.bias', 'temporal_vision_encoder.layer.1.output.dense.weight', 'temporal_vision_encoder.layer.1.output.dense.bias', 'temporal_vision_encoder.layer.1.output.LayerNorm.weight', 'temporal_vision_encoder.layer.1.output.LayerNorm.bias', 'text_decoder.bert.embeddings.position_ids', 'text_decoder.bert.embeddings.word_embeddings.weight', 'text_decoder.bert.embeddings.position_embeddings.weight', 'text_decoder.bert.embeddings.token_type_embeddings.weight', 'text_decoder.bert.embeddings.LayerNorm.weight', 'text_decoder.bert.embeddings.LayerNorm.bias', 'text_decoder.bert.encoder.layer.0.attention.self.query.weight', 'text_decoder.bert.encoder.layer.0.attention.self.query.bias', 'text_decoder.bert.encoder.layer.0.attention.self.key.weight', 'text_decoder.bert.encoder.layer.0.attention.self.key.bias', 'text_decoder.bert.encoder.layer.0.attention.self.value.weight', 'text_decoder.bert.encoder.layer.0.attention.self.value.bias', 'text_decoder.bert.encoder.layer.0.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.0.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.0.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.0.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.0.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.0.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.0.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.0.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.0.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.0.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.0.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.0.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.0.output.dense.weight', 'text_decoder.bert.encoder.layer.0.output.dense.bias', 'text_decoder.bert.encoder.layer.0.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.1.attention.self.query.weight', 'text_decoder.bert.encoder.layer.1.attention.self.query.bias', 'text_decoder.bert.encoder.layer.1.attention.self.key.weight', 'text_decoder.bert.encoder.layer.1.attention.self.key.bias', 'text_decoder.bert.encoder.layer.1.attention.self.value.weight', 'text_decoder.bert.encoder.layer.1.attention.self.value.bias', 'text_decoder.bert.encoder.layer.1.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.1.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.1.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.1.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.1.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.1.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.1.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.1.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.1.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.1.output.dense.weight', 'text_decoder.bert.encoder.layer.1.output.dense.bias', 'text_decoder.bert.encoder.layer.1.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.1.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.attention.self.query.weight', 'text_decoder.bert.encoder.layer.2.attention.self.query.bias', 'text_decoder.bert.encoder.layer.2.attention.self.key.weight', 'text_decoder.bert.encoder.layer.2.attention.self.key.bias', 'text_decoder.bert.encoder.layer.2.attention.self.value.weight', 'text_decoder.bert.encoder.layer.2.attention.self.value.bias', 'text_decoder.bert.encoder.layer.2.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.2.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.2.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.2.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.2.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.2.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.2.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.2.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.2.output.dense.weight', 'text_decoder.bert.encoder.layer.2.output.dense.bias', 'text_decoder.bert.encoder.layer.2.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.2.output.LayerNorm.bias', 'text_decoder.cls.predictions.bias', 'text_decoder.cls.predictions.transform.dense.weight', 'text_decoder.cls.predictions.transform.dense.bias', 'text_decoder.cls.predictions.transform.LayerNorm.weight', 'text_decoder.cls.predictions.transform.LayerNorm.bias', 'text_decoder.cls.predictions.decoder.weight', 'text_decoder.cls.predictions.decoder.bias'])
[32m2023-10-19T19:58:25 | models.utils: [0mLoad temporal_embeddings, lengths: 4-->4
[32m2023-10-19T19:58:25 | models.utils: [0mLoad temporal_embeddings, lengths: 4-->4
model_without_ddp:  Singularity(
  (vision_encoder): BeitModel(
    (embeddings): BeitEmbeddings(
      (patch_embeddings): PatchEmbeddings(
        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      )
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder): BeitEncoder(
      (layer): ModuleList(
        (0): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): Identity()
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (1): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.00909090880304575)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (2): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.0181818176060915)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (3): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.027272727340459824)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (4): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.036363635212183)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (5): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.045454543083906174)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (6): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.054545458406209946)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (7): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.06363636255264282)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (8): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.0727272778749466)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (9): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.08181818574666977)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (10): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.09090909361839294)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
        (11): BeitLayer(
          (attention): BeitAttention(
            (attention): BeitSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=False)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (relative_position_bias): BeitRelativePositionBias()
            )
            (output): BeitSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): BeitIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BeitOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (drop_path): DropPath(p=0.10000000149011612)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
    (layernorm): Identity()
    (pooler): BeitPooler(
      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
    )
  )
  (vision_layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  (text_encoder): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (crossattention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (crossattention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (crossattention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (vision_proj): Linear(in_features=768, out_features=256, bias=True)
  (text_proj): Linear(in_features=768, out_features=256, bias=True)
  (itm_head): Linear(in_features=768, out_features=2, bias=True)
  (temporal_vision_encoder): BertEncoder(
    (layer): ModuleList(
      (0): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (1): BertLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
)
model_without_ddp.state_dict().keys():  odict_keys(['temp', 'temporal_embeddings', 'vision_encoder.embeddings.cls_token', 'vision_encoder.embeddings.patch_embeddings.projection.weight', 'vision_encoder.embeddings.patch_embeddings.projection.bias', 'vision_encoder.encoder.layer.0.lambda_1', 'vision_encoder.encoder.layer.0.lambda_2', 'vision_encoder.encoder.layer.0.attention.attention.query.weight', 'vision_encoder.encoder.layer.0.attention.attention.query.bias', 'vision_encoder.encoder.layer.0.attention.attention.key.weight', 'vision_encoder.encoder.layer.0.attention.attention.value.weight', 'vision_encoder.encoder.layer.0.attention.attention.value.bias', 'vision_encoder.encoder.layer.0.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.0.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.0.attention.output.dense.weight', 'vision_encoder.encoder.layer.0.attention.output.dense.bias', 'vision_encoder.encoder.layer.0.intermediate.dense.weight', 'vision_encoder.encoder.layer.0.intermediate.dense.bias', 'vision_encoder.encoder.layer.0.output.dense.weight', 'vision_encoder.encoder.layer.0.output.dense.bias', 'vision_encoder.encoder.layer.0.layernorm_before.weight', 'vision_encoder.encoder.layer.0.layernorm_before.bias', 'vision_encoder.encoder.layer.0.layernorm_after.weight', 'vision_encoder.encoder.layer.0.layernorm_after.bias', 'vision_encoder.encoder.layer.1.lambda_1', 'vision_encoder.encoder.layer.1.lambda_2', 'vision_encoder.encoder.layer.1.attention.attention.query.weight', 'vision_encoder.encoder.layer.1.attention.attention.query.bias', 'vision_encoder.encoder.layer.1.attention.attention.key.weight', 'vision_encoder.encoder.layer.1.attention.attention.value.weight', 'vision_encoder.encoder.layer.1.attention.attention.value.bias', 'vision_encoder.encoder.layer.1.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.1.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.1.attention.output.dense.weight', 'vision_encoder.encoder.layer.1.attention.output.dense.bias', 'vision_encoder.encoder.layer.1.intermediate.dense.weight', 'vision_encoder.encoder.layer.1.intermediate.dense.bias', 'vision_encoder.encoder.layer.1.output.dense.weight', 'vision_encoder.encoder.layer.1.output.dense.bias', 'vision_encoder.encoder.layer.1.layernorm_before.weight', 'vision_encoder.encoder.layer.1.layernorm_before.bias', 'vision_encoder.encoder.layer.1.layernorm_after.weight', 'vision_encoder.encoder.layer.1.layernorm_after.bias', 'vision_encoder.encoder.layer.2.lambda_1', 'vision_encoder.encoder.layer.2.lambda_2', 'vision_encoder.encoder.layer.2.attention.attention.query.weight', 'vision_encoder.encoder.layer.2.attention.attention.query.bias', 'vision_encoder.encoder.layer.2.attention.attention.key.weight', 'vision_encoder.encoder.layer.2.attention.attention.value.weight', 'vision_encoder.encoder.layer.2.attention.attention.value.bias', 'vision_encoder.encoder.layer.2.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.2.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.2.attention.output.dense.weight', 'vision_encoder.encoder.layer.2.attention.output.dense.bias', 'vision_encoder.encoder.layer.2.intermediate.dense.weight', 'vision_encoder.encoder.layer.2.intermediate.dense.bias', 'vision_encoder.encoder.layer.2.output.dense.weight', 'vision_encoder.encoder.layer.2.output.dense.bias', 'vision_encoder.encoder.layer.2.layernorm_before.weight', 'vision_encoder.encoder.layer.2.layernorm_before.bias', 'vision_encoder.encoder.layer.2.layernorm_after.weight', 'vision_encoder.encoder.layer.2.layernorm_after.bias', 'vision_encoder.encoder.layer.3.lambda_1', 'vision_encoder.encoder.layer.3.lambda_2', 'vision_encoder.encoder.layer.3.attention.attention.query.weight', 'vision_encoder.encoder.layer.3.attention.attention.query.bias', 'vision_encoder.encoder.layer.3.attention.attention.key.weight', 'vision_encoder.encoder.layer.3.attention.attention.value.weight', 'vision_encoder.encoder.layer.3.attention.attention.value.bias', 'vision_encoder.encoder.layer.3.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.3.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.3.attention.output.dense.weight', 'vision_encoder.encoder.layer.3.attention.output.dense.bias', 'vision_encoder.encoder.layer.3.intermediate.dense.weight', 'vision_encoder.encoder.layer.3.intermediate.dense.bias', 'vision_encoder.encoder.layer.3.output.dense.weight', 'vision_encoder.encoder.layer.3.output.dense.bias', 'vision_encoder.encoder.layer.3.layernorm_before.weight', 'vision_encoder.encoder.layer.3.layernorm_before.bias', 'vision_encoder.encoder.layer.3.layernorm_after.weight', 'vision_encoder.encoder.layer.3.layernorm_after.bias', 'vision_encoder.encoder.layer.4.lambda_1', 'vision_encoder.encoder.layer.4.lambda_2', 'vision_encoder.encoder.layer.4.attention.attention.query.weight', 'vision_encoder.encoder.layer.4.attention.attention.query.bias', 'vision_encoder.encoder.layer.4.attention.attention.key.weight', 'vision_encoder.encoder.layer.4.attention.attention.value.weight', 'vision_encoder.encoder.layer.4.attention.attention.value.bias', 'vision_encoder.encoder.layer.4.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.4.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.4.attention.output.dense.weight', 'vision_encoder.encoder.layer.4.attention.output.dense.bias', 'vision_encoder.encoder.layer.4.intermediate.dense.weight', 'vision_encoder.encoder.layer.4.intermediate.dense.bias', 'vision_encoder.encoder.layer.4.output.dense.weight', 'vision_encoder.encoder.layer.4.output.dense.bias', 'vision_encoder.encoder.layer.4.layernorm_before.weight', 'vision_encoder.encoder.layer.4.layernorm_before.bias', 'vision_encoder.encoder.layer.4.layernorm_after.weight', 'vision_encoder.encoder.layer.4.layernorm_after.bias', 'vision_encoder.encoder.layer.5.lambda_1', 'vision_encoder.encoder.layer.5.lambda_2', 'vision_encoder.encoder.layer.5.attention.attention.query.weight', 'vision_encoder.encoder.layer.5.attention.attention.query.bias', 'vision_encoder.encoder.layer.5.attention.attention.key.weight', 'vision_encoder.encoder.layer.5.attention.attention.value.weight', 'vision_encoder.encoder.layer.5.attention.attention.value.bias', 'vision_encoder.encoder.layer.5.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.5.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.5.attention.output.dense.weight', 'vision_encoder.encoder.layer.5.attention.output.dense.bias', 'vision_encoder.encoder.layer.5.intermediate.dense.weight', 'vision_encoder.encoder.layer.5.intermediate.dense.bias', 'vision_encoder.encoder.layer.5.output.dense.weight', 'vision_encoder.encoder.layer.5.output.dense.bias', 'vision_encoder.encoder.layer.5.layernorm_before.weight', 'vision_encoder.encoder.layer.5.layernorm_before.bias', 'vision_encoder.encoder.layer.5.layernorm_after.weight', 'vision_encoder.encoder.layer.5.layernorm_after.bias', 'vision_encoder.encoder.layer.6.lambda_1', 'vision_encoder.encoder.layer.6.lambda_2', 'vision_encoder.encoder.layer.6.attention.attention.query.weight', 'vision_encoder.encoder.layer.6.attention.attention.query.bias', 'vision_encoder.encoder.layer.6.attention.attention.key.weight', 'vision_encoder.encoder.layer.6.attention.attention.value.weight', 'vision_encoder.encoder.layer.6.attention.attention.value.bias', 'vision_encoder.encoder.layer.6.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.6.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.6.attention.output.dense.weight', 'vision_encoder.encoder.layer.6.attention.output.dense.bias', 'vision_encoder.encoder.layer.6.intermediate.dense.weight', 'vision_encoder.encoder.layer.6.intermediate.dense.bias', 'vision_encoder.encoder.layer.6.output.dense.weight', 'vision_encoder.encoder.layer.6.output.dense.bias', 'vision_encoder.encoder.layer.6.layernorm_before.weight', 'vision_encoder.encoder.layer.6.layernorm_before.bias', 'vision_encoder.encoder.layer.6.layernorm_after.weight', 'vision_encoder.encoder.layer.6.layernorm_after.bias', 'vision_encoder.encoder.layer.7.lambda_1', 'vision_encoder.encoder.layer.7.lambda_2', 'vision_encoder.encoder.layer.7.attention.attention.query.weight', 'vision_encoder.encoder.layer.7.attention.attention.query.bias', 'vision_encoder.encoder.layer.7.attention.attention.key.weight', 'vision_encoder.encoder.layer.7.attention.attention.value.weight', 'vision_encoder.encoder.layer.7.attention.attention.value.bias', 'vision_encoder.encoder.layer.7.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.7.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.7.attention.output.dense.weight', 'vision_encoder.encoder.layer.7.attention.output.dense.bias', 'vision_encoder.encoder.layer.7.intermediate.dense.weight', 'vision_encoder.encoder.layer.7.intermediate.dense.bias', 'vision_encoder.encoder.layer.7.output.dense.weight', 'vision_encoder.encoder.layer.7.output.dense.bias', 'vision_encoder.encoder.layer.7.layernorm_before.weight', 'vision_encoder.encoder.layer.7.layernorm_before.bias', 'vision_encoder.encoder.layer.7.layernorm_after.weight', 'vision_encoder.encoder.layer.7.layernorm_after.bias', 'vision_encoder.encoder.layer.8.lambda_1', 'vision_encoder.encoder.layer.8.lambda_2', 'vision_encoder.encoder.layer.8.attention.attention.query.weight', 'vision_encoder.encoder.layer.8.attention.attention.query.bias', 'vision_encoder.encoder.layer.8.attention.attention.key.weight', 'vision_encoder.encoder.layer.8.attention.attention.value.weight', 'vision_encoder.encoder.layer.8.attention.attention.value.bias', 'vision_encoder.encoder.layer.8.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.8.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.8.attention.output.dense.weight', 'vision_encoder.encoder.layer.8.attention.output.dense.bias', 'vision_encoder.encoder.layer.8.intermediate.dense.weight', 'vision_encoder.encoder.layer.8.intermediate.dense.bias', 'vision_encoder.encoder.layer.8.output.dense.weight', 'vision_encoder.encoder.layer.8.output.dense.bias', 'vision_encoder.encoder.layer.8.layernorm_before.weight', 'vision_encoder.encoder.layer.8.layernorm_before.bias', 'vision_encoder.encoder.layer.8.layernorm_after.weight', 'vision_encoder.encoder.layer.8.layernorm_after.bias', 'vision_encoder.encoder.layer.9.lambda_1', 'vision_encoder.encoder.layer.9.lambda_2', 'vision_encoder.encoder.layer.9.attention.attention.query.weight', 'vision_encoder.encoder.layer.9.attention.attention.query.bias', 'vision_encoder.encoder.layer.9.attention.attention.key.weight', 'vision_encoder.encoder.layer.9.attention.attention.value.weight', 'vision_encoder.encoder.layer.9.attention.attention.value.bias', 'vision_encoder.encoder.layer.9.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.9.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.9.attention.output.dense.weight', 'vision_encoder.encoder.layer.9.attention.output.dense.bias', 'vision_encoder.encoder.layer.9.intermediate.dense.weight', 'vision_encoder.encoder.layer.9.intermediate.dense.bias', 'vision_encoder.encoder.layer.9.output.dense.weight', 'vision_encoder.encoder.layer.9.output.dense.bias', 'vision_encoder.encoder.layer.9.layernorm_before.weight', 'vision_encoder.encoder.layer.9.layernorm_before.bias', 'vision_encoder.encoder.layer.9.layernorm_after.weight', 'vision_encoder.encoder.layer.9.layernorm_after.bias', 'vision_encoder.encoder.layer.10.lambda_1', 'vision_encoder.encoder.layer.10.lambda_2', 'vision_encoder.encoder.layer.10.attention.attention.query.weight', 'vision_encoder.encoder.layer.10.attention.attention.query.bias', 'vision_encoder.encoder.layer.10.attention.attention.key.weight', 'vision_encoder.encoder.layer.10.attention.attention.value.weight', 'vision_encoder.encoder.layer.10.attention.attention.value.bias', 'vision_encoder.encoder.layer.10.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.10.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.10.attention.output.dense.weight', 'vision_encoder.encoder.layer.10.attention.output.dense.bias', 'vision_encoder.encoder.layer.10.intermediate.dense.weight', 'vision_encoder.encoder.layer.10.intermediate.dense.bias', 'vision_encoder.encoder.layer.10.output.dense.weight', 'vision_encoder.encoder.layer.10.output.dense.bias', 'vision_encoder.encoder.layer.10.layernorm_before.weight', 'vision_encoder.encoder.layer.10.layernorm_before.bias', 'vision_encoder.encoder.layer.10.layernorm_after.weight', 'vision_encoder.encoder.layer.10.layernorm_after.bias', 'vision_encoder.encoder.layer.11.lambda_1', 'vision_encoder.encoder.layer.11.lambda_2', 'vision_encoder.encoder.layer.11.attention.attention.query.weight', 'vision_encoder.encoder.layer.11.attention.attention.query.bias', 'vision_encoder.encoder.layer.11.attention.attention.key.weight', 'vision_encoder.encoder.layer.11.attention.attention.value.weight', 'vision_encoder.encoder.layer.11.attention.attention.value.bias', 'vision_encoder.encoder.layer.11.attention.attention.relative_position_bias.relative_position_bias_table', 'vision_encoder.encoder.layer.11.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.11.attention.output.dense.weight', 'vision_encoder.encoder.layer.11.attention.output.dense.bias', 'vision_encoder.encoder.layer.11.intermediate.dense.weight', 'vision_encoder.encoder.layer.11.intermediate.dense.bias', 'vision_encoder.encoder.layer.11.output.dense.weight', 'vision_encoder.encoder.layer.11.output.dense.bias', 'vision_encoder.encoder.layer.11.layernorm_before.weight', 'vision_encoder.encoder.layer.11.layernorm_before.bias', 'vision_encoder.encoder.layer.11.layernorm_after.weight', 'vision_encoder.encoder.layer.11.layernorm_after.bias', 'vision_encoder.pooler.layernorm.weight', 'vision_encoder.pooler.layernorm.bias', 'vision_layernorm.weight', 'vision_layernorm.bias', 'text_encoder.embeddings.position_ids', 'text_encoder.embeddings.word_embeddings.weight', 'text_encoder.embeddings.position_embeddings.weight', 'text_encoder.embeddings.token_type_embeddings.weight', 'text_encoder.embeddings.LayerNorm.weight', 'text_encoder.embeddings.LayerNorm.bias', 'text_encoder.encoder.layer.0.attention.self.query.weight', 'text_encoder.encoder.layer.0.attention.self.query.bias', 'text_encoder.encoder.layer.0.attention.self.key.weight', 'text_encoder.encoder.layer.0.attention.self.key.bias', 'text_encoder.encoder.layer.0.attention.self.value.weight', 'text_encoder.encoder.layer.0.attention.self.value.bias', 'text_encoder.encoder.layer.0.attention.output.dense.weight', 'text_encoder.encoder.layer.0.attention.output.dense.bias', 'text_encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.0.intermediate.dense.weight', 'text_encoder.encoder.layer.0.intermediate.dense.bias', 'text_encoder.encoder.layer.0.output.dense.weight', 'text_encoder.encoder.layer.0.output.dense.bias', 'text_encoder.encoder.layer.0.output.LayerNorm.weight', 'text_encoder.encoder.layer.0.output.LayerNorm.bias', 'text_encoder.encoder.layer.1.attention.self.query.weight', 'text_encoder.encoder.layer.1.attention.self.query.bias', 'text_encoder.encoder.layer.1.attention.self.key.weight', 'text_encoder.encoder.layer.1.attention.self.key.bias', 'text_encoder.encoder.layer.1.attention.self.value.weight', 'text_encoder.encoder.layer.1.attention.self.value.bias', 'text_encoder.encoder.layer.1.attention.output.dense.weight', 'text_encoder.encoder.layer.1.attention.output.dense.bias', 'text_encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.1.intermediate.dense.weight', 'text_encoder.encoder.layer.1.intermediate.dense.bias', 'text_encoder.encoder.layer.1.output.dense.weight', 'text_encoder.encoder.layer.1.output.dense.bias', 'text_encoder.encoder.layer.1.output.LayerNorm.weight', 'text_encoder.encoder.layer.1.output.LayerNorm.bias', 'text_encoder.encoder.layer.2.attention.self.query.weight', 'text_encoder.encoder.layer.2.attention.self.query.bias', 'text_encoder.encoder.layer.2.attention.self.key.weight', 'text_encoder.encoder.layer.2.attention.self.key.bias', 'text_encoder.encoder.layer.2.attention.self.value.weight', 'text_encoder.encoder.layer.2.attention.self.value.bias', 'text_encoder.encoder.layer.2.attention.output.dense.weight', 'text_encoder.encoder.layer.2.attention.output.dense.bias', 'text_encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.2.intermediate.dense.weight', 'text_encoder.encoder.layer.2.intermediate.dense.bias', 'text_encoder.encoder.layer.2.output.dense.weight', 'text_encoder.encoder.layer.2.output.dense.bias', 'text_encoder.encoder.layer.2.output.LayerNorm.weight', 'text_encoder.encoder.layer.2.output.LayerNorm.bias', 'text_encoder.encoder.layer.3.attention.self.query.weight', 'text_encoder.encoder.layer.3.attention.self.query.bias', 'text_encoder.encoder.layer.3.attention.self.key.weight', 'text_encoder.encoder.layer.3.attention.self.key.bias', 'text_encoder.encoder.layer.3.attention.self.value.weight', 'text_encoder.encoder.layer.3.attention.self.value.bias', 'text_encoder.encoder.layer.3.attention.output.dense.weight', 'text_encoder.encoder.layer.3.attention.output.dense.bias', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.3.intermediate.dense.weight', 'text_encoder.encoder.layer.3.intermediate.dense.bias', 'text_encoder.encoder.layer.3.output.dense.weight', 'text_encoder.encoder.layer.3.output.dense.bias', 'text_encoder.encoder.layer.3.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.attention.self.query.weight', 'text_encoder.encoder.layer.4.attention.self.query.bias', 'text_encoder.encoder.layer.4.attention.self.key.weight', 'text_encoder.encoder.layer.4.attention.self.key.bias', 'text_encoder.encoder.layer.4.attention.self.value.weight', 'text_encoder.encoder.layer.4.attention.self.value.bias', 'text_encoder.encoder.layer.4.attention.output.dense.weight', 'text_encoder.encoder.layer.4.attention.output.dense.bias', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.intermediate.dense.weight', 'text_encoder.encoder.layer.4.intermediate.dense.bias', 'text_encoder.encoder.layer.4.output.dense.weight', 'text_encoder.encoder.layer.4.output.dense.bias', 'text_encoder.encoder.layer.4.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.attention.self.query.weight', 'text_encoder.encoder.layer.5.attention.self.query.bias', 'text_encoder.encoder.layer.5.attention.self.key.weight', 'text_encoder.encoder.layer.5.attention.self.key.bias', 'text_encoder.encoder.layer.5.attention.self.value.weight', 'text_encoder.encoder.layer.5.attention.self.value.bias', 'text_encoder.encoder.layer.5.attention.output.dense.weight', 'text_encoder.encoder.layer.5.attention.output.dense.bias', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.intermediate.dense.weight', 'text_encoder.encoder.layer.5.intermediate.dense.bias', 'text_encoder.encoder.layer.5.output.dense.weight', 'text_encoder.encoder.layer.5.output.dense.bias', 'text_encoder.encoder.layer.5.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.attention.self.query.weight', 'text_encoder.encoder.layer.6.attention.self.query.bias', 'text_encoder.encoder.layer.6.attention.self.key.weight', 'text_encoder.encoder.layer.6.attention.self.key.bias', 'text_encoder.encoder.layer.6.attention.self.value.weight', 'text_encoder.encoder.layer.6.attention.self.value.bias', 'text_encoder.encoder.layer.6.attention.output.dense.weight', 'text_encoder.encoder.layer.6.attention.output.dense.bias', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.intermediate.dense.weight', 'text_encoder.encoder.layer.6.intermediate.dense.bias', 'text_encoder.encoder.layer.6.output.dense.weight', 'text_encoder.encoder.layer.6.output.dense.bias', 'text_encoder.encoder.layer.6.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.attention.self.query.weight', 'text_encoder.encoder.layer.7.attention.self.query.bias', 'text_encoder.encoder.layer.7.attention.self.key.weight', 'text_encoder.encoder.layer.7.attention.self.key.bias', 'text_encoder.encoder.layer.7.attention.self.value.weight', 'text_encoder.encoder.layer.7.attention.self.value.bias', 'text_encoder.encoder.layer.7.attention.output.dense.weight', 'text_encoder.encoder.layer.7.attention.output.dense.bias', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.intermediate.dense.weight', 'text_encoder.encoder.layer.7.intermediate.dense.bias', 'text_encoder.encoder.layer.7.output.dense.weight', 'text_encoder.encoder.layer.7.output.dense.bias', 'text_encoder.encoder.layer.7.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.attention.self.query.weight', 'text_encoder.encoder.layer.8.attention.self.query.bias', 'text_encoder.encoder.layer.8.attention.self.key.weight', 'text_encoder.encoder.layer.8.attention.self.key.bias', 'text_encoder.encoder.layer.8.attention.self.value.weight', 'text_encoder.encoder.layer.8.attention.self.value.bias', 'text_encoder.encoder.layer.8.attention.output.dense.weight', 'text_encoder.encoder.layer.8.attention.output.dense.bias', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.intermediate.dense.weight', 'text_encoder.encoder.layer.8.intermediate.dense.bias', 'text_encoder.encoder.layer.8.output.dense.weight', 'text_encoder.encoder.layer.8.output.dense.bias', 'text_encoder.encoder.layer.8.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.attention.self.query.weight', 'text_encoder.encoder.layer.9.attention.self.query.bias', 'text_encoder.encoder.layer.9.attention.self.key.weight', 'text_encoder.encoder.layer.9.attention.self.key.bias', 'text_encoder.encoder.layer.9.attention.self.value.weight', 'text_encoder.encoder.layer.9.attention.self.value.bias', 'text_encoder.encoder.layer.9.attention.output.dense.weight', 'text_encoder.encoder.layer.9.attention.output.dense.bias', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.crossattention.self.query.weight', 'text_encoder.encoder.layer.9.crossattention.self.query.bias', 'text_encoder.encoder.layer.9.crossattention.self.key.weight', 'text_encoder.encoder.layer.9.crossattention.self.key.bias', 'text_encoder.encoder.layer.9.crossattention.self.value.weight', 'text_encoder.encoder.layer.9.crossattention.self.value.bias', 'text_encoder.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.intermediate.dense.weight', 'text_encoder.encoder.layer.9.intermediate.dense.bias', 'text_encoder.encoder.layer.9.output.dense.weight', 'text_encoder.encoder.layer.9.output.dense.bias', 'text_encoder.encoder.layer.9.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.attention.self.query.weight', 'text_encoder.encoder.layer.10.attention.self.query.bias', 'text_encoder.encoder.layer.10.attention.self.key.weight', 'text_encoder.encoder.layer.10.attention.self.key.bias', 'text_encoder.encoder.layer.10.attention.self.value.weight', 'text_encoder.encoder.layer.10.attention.self.value.bias', 'text_encoder.encoder.layer.10.attention.output.dense.weight', 'text_encoder.encoder.layer.10.attention.output.dense.bias', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.crossattention.self.query.weight', 'text_encoder.encoder.layer.10.crossattention.self.query.bias', 'text_encoder.encoder.layer.10.crossattention.self.key.weight', 'text_encoder.encoder.layer.10.crossattention.self.key.bias', 'text_encoder.encoder.layer.10.crossattention.self.value.weight', 'text_encoder.encoder.layer.10.crossattention.self.value.bias', 'text_encoder.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.intermediate.dense.weight', 'text_encoder.encoder.layer.10.intermediate.dense.bias', 'text_encoder.encoder.layer.10.output.dense.weight', 'text_encoder.encoder.layer.10.output.dense.bias', 'text_encoder.encoder.layer.10.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.attention.self.query.weight', 'text_encoder.encoder.layer.11.attention.self.query.bias', 'text_encoder.encoder.layer.11.attention.self.key.weight', 'text_encoder.encoder.layer.11.attention.self.key.bias', 'text_encoder.encoder.layer.11.attention.self.value.weight', 'text_encoder.encoder.layer.11.attention.self.value.bias', 'text_encoder.encoder.layer.11.attention.output.dense.weight', 'text_encoder.encoder.layer.11.attention.output.dense.bias', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.crossattention.self.query.weight', 'text_encoder.encoder.layer.11.crossattention.self.query.bias', 'text_encoder.encoder.layer.11.crossattention.self.key.weight', 'text_encoder.encoder.layer.11.crossattention.self.key.bias', 'text_encoder.encoder.layer.11.crossattention.self.value.weight', 'text_encoder.encoder.layer.11.crossattention.self.value.bias', 'text_encoder.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.intermediate.dense.weight', 'text_encoder.encoder.layer.11.intermediate.dense.bias', 'text_encoder.encoder.layer.11.output.dense.weight', 'text_encoder.encoder.layer.11.output.dense.bias', 'text_encoder.encoder.layer.11.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.output.LayerNorm.bias', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias', 'temporal_vision_encoder.layer.0.attention.self.query.weight', 'temporal_vision_encoder.layer.0.attention.self.query.bias', 'temporal_vision_encoder.layer.0.attention.self.key.weight', 'temporal_vision_encoder.layer.0.attention.self.key.bias', 'temporal_vision_encoder.layer.0.attention.self.value.weight', 'temporal_vision_encoder.layer.0.attention.self.value.bias', 'temporal_vision_encoder.layer.0.attention.output.dense.weight', 'temporal_vision_encoder.layer.0.attention.output.dense.bias', 'temporal_vision_encoder.layer.0.attention.output.LayerNorm.weight', 'temporal_vision_encoder.layer.0.attention.output.LayerNorm.bias', 'temporal_vision_encoder.layer.0.intermediate.dense.weight', 'temporal_vision_encoder.layer.0.intermediate.dense.bias', 'temporal_vision_encoder.layer.0.output.dense.weight', 'temporal_vision_encoder.layer.0.output.dense.bias', 'temporal_vision_encoder.layer.0.output.LayerNorm.weight', 'temporal_vision_encoder.layer.0.output.LayerNorm.bias', 'temporal_vision_encoder.layer.1.attention.self.query.weight', 'temporal_vision_encoder.layer.1.attention.self.query.bias', 'temporal_vision_encoder.layer.1.attention.self.key.weight', 'temporal_vision_encoder.layer.1.attention.self.key.bias', 'temporal_vision_encoder.layer.1.attention.self.value.weight', 'temporal_vision_encoder.layer.1.attention.self.value.bias', 'temporal_vision_encoder.layer.1.attention.output.dense.weight', 'temporal_vision_encoder.layer.1.attention.output.dense.bias', 'temporal_vision_encoder.layer.1.attention.output.LayerNorm.weight', 'temporal_vision_encoder.layer.1.attention.output.LayerNorm.bias', 'temporal_vision_encoder.layer.1.intermediate.dense.weight', 'temporal_vision_encoder.layer.1.intermediate.dense.bias', 'temporal_vision_encoder.layer.1.output.dense.weight', 'temporal_vision_encoder.layer.1.output.dense.bias', 'temporal_vision_encoder.layer.1.output.LayerNorm.weight', 'temporal_vision_encoder.layer.1.output.LayerNorm.bias'])
[32m2023-10-19T19:58:26 | tasks.shared_utils: [0m_IncompatibleKeys(missing_keys=['temp', 'vision_encoder.encoder.layer.0.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.1.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.2.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.3.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.4.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.5.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.6.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.7.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.8.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.9.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.10.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.encoder.layer.11.attention.attention.relative_position_bias.relative_position_index', 'vision_encoder.pooler.layernorm.weight', 'vision_encoder.pooler.layernorm.bias', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias'], unexpected_keys=['text_decoder.cls.predictions.bias', 'text_decoder.cls.predictions.transform.dense.weight', 'text_decoder.cls.predictions.transform.dense.bias', 'text_decoder.cls.predictions.transform.LayerNorm.weight', 'text_decoder.cls.predictions.transform.LayerNorm.bias', 'text_decoder.cls.predictions.decoder.weight', 'text_decoder.cls.predictions.decoder.bias', 'text_decoder.embeddings.position_ids', 'text_decoder.embeddings.word_embeddings.weight', 'text_decoder.embeddings.position_embeddings.weight', 'text_decoder.embeddings.token_type_embeddings.weight', 'text_decoder.embeddings.LayerNorm.weight', 'text_decoder.embeddings.LayerNorm.bias', 'text_decoder.encoder.layer.0.attention.self.query.weight', 'text_decoder.encoder.layer.0.attention.self.query.bias', 'text_decoder.encoder.layer.0.attention.self.key.weight', 'text_decoder.encoder.layer.0.attention.self.key.bias', 'text_decoder.encoder.layer.0.attention.self.value.weight', 'text_decoder.encoder.layer.0.attention.self.value.bias', 'text_decoder.encoder.layer.0.attention.output.dense.weight', 'text_decoder.encoder.layer.0.attention.output.dense.bias', 'text_decoder.encoder.layer.0.attention.output.LayerNorm.weight', 'text_decoder.encoder.layer.0.attention.output.LayerNorm.bias', 'text_decoder.encoder.layer.0.crossattention.self.query.weight', 'text_decoder.encoder.layer.0.crossattention.self.query.bias', 'text_decoder.encoder.layer.0.crossattention.self.key.weight', 'text_decoder.encoder.layer.0.crossattention.self.key.bias', 'text_decoder.encoder.layer.0.crossattention.self.value.weight', 'text_decoder.encoder.layer.0.crossattention.self.value.bias', 'text_decoder.encoder.layer.0.crossattention.output.dense.weight', 'text_decoder.encoder.layer.0.crossattention.output.dense.bias', 'text_decoder.encoder.layer.0.crossattention.output.LayerNorm.weight', 'text_decoder.encoder.layer.0.crossattention.output.LayerNorm.bias', 'text_decoder.encoder.layer.0.intermediate.dense.weight', 'text_decoder.encoder.layer.0.intermediate.dense.bias', 'text_decoder.encoder.layer.0.output.dense.weight', 'text_decoder.encoder.layer.0.output.dense.bias', 'text_decoder.encoder.layer.0.output.LayerNorm.weight', 'text_decoder.encoder.layer.0.output.LayerNorm.bias', 'text_decoder.encoder.layer.1.attention.self.query.weight', 'text_decoder.encoder.layer.1.attention.self.query.bias', 'text_decoder.encoder.layer.1.attention.self.key.weight', 'text_decoder.encoder.layer.1.attention.self.key.bias', 'text_decoder.encoder.layer.1.attention.self.value.weight', 'text_decoder.encoder.layer.1.attention.self.value.bias', 'text_decoder.encoder.layer.1.attention.output.dense.weight', 'text_decoder.encoder.layer.1.attention.output.dense.bias', 'text_decoder.encoder.layer.1.attention.output.LayerNorm.weight', 'text_decoder.encoder.layer.1.attention.output.LayerNorm.bias', 'text_decoder.encoder.layer.1.crossattention.self.query.weight', 'text_decoder.encoder.layer.1.crossattention.self.query.bias', 'text_decoder.encoder.layer.1.crossattention.self.key.weight', 'text_decoder.encoder.layer.1.crossattention.self.key.bias', 'text_decoder.encoder.layer.1.crossattention.self.value.weight', 'text_decoder.encoder.layer.1.crossattention.self.value.bias', 'text_decoder.encoder.layer.1.crossattention.output.dense.weight', 'text_decoder.encoder.layer.1.crossattention.output.dense.bias', 'text_decoder.encoder.layer.1.crossattention.output.LayerNorm.weight', 'text_decoder.encoder.layer.1.crossattention.output.LayerNorm.bias', 'text_decoder.encoder.layer.1.intermediate.dense.weight', 'text_decoder.encoder.layer.1.intermediate.dense.bias', 'text_decoder.encoder.layer.1.output.dense.weight', 'text_decoder.encoder.layer.1.output.dense.bias', 'text_decoder.encoder.layer.1.output.LayerNorm.weight', 'text_decoder.encoder.layer.1.output.LayerNorm.bias', 'text_decoder.encoder.layer.2.attention.self.query.weight', 'text_decoder.encoder.layer.2.attention.self.query.bias', 'text_decoder.encoder.layer.2.attention.self.key.weight', 'text_decoder.encoder.layer.2.attention.self.key.bias', 'text_decoder.encoder.layer.2.attention.self.value.weight', 'text_decoder.encoder.layer.2.attention.self.value.bias', 'text_decoder.encoder.layer.2.attention.output.dense.weight', 'text_decoder.encoder.layer.2.attention.output.dense.bias', 'text_decoder.encoder.layer.2.attention.output.LayerNorm.weight', 'text_decoder.encoder.layer.2.attention.output.LayerNorm.bias', 'text_decoder.encoder.layer.2.crossattention.self.query.weight', 'text_decoder.encoder.layer.2.crossattention.self.query.bias', 'text_decoder.encoder.layer.2.crossattention.self.key.weight', 'text_decoder.encoder.layer.2.crossattention.self.key.bias', 'text_decoder.encoder.layer.2.crossattention.self.value.weight', 'text_decoder.encoder.layer.2.crossattention.self.value.bias', 'text_decoder.encoder.layer.2.crossattention.output.dense.weight', 'text_decoder.encoder.layer.2.crossattention.output.dense.bias', 'text_decoder.encoder.layer.2.crossattention.output.LayerNorm.weight', 'text_decoder.encoder.layer.2.crossattention.output.LayerNorm.bias', 'text_decoder.encoder.layer.2.intermediate.dense.weight', 'text_decoder.encoder.layer.2.intermediate.dense.bias', 'text_decoder.encoder.layer.2.output.dense.weight', 'text_decoder.encoder.layer.2.output.dense.bias', 'text_decoder.encoder.layer.2.output.LayerNorm.weight', 'text_decoder.encoder.layer.2.output.LayerNorm.bias'])
[32m2023-10-19T19:58:26 | tasks.shared_utils: [0mLoaded checkpoint from /home/wiss/zhang/nfs/anetqa_train_qa_full/ckpt_best.pth
[32m2023-10-19T19:58:26 | __main__: [0mtraining
[32m2023-10-19T19:58:32 | dataset.dataloader: [0mMetaLoader has 1 dataloaders, 2288 batches in total
dataloader index=0 name=video, batch-size=4 length(#batches)=2288 
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d g o l d h a i r o n t h e b l a c k c e r a m i c r o o f', 't h e r e i s a m a n i n t h e a u d i e n c e w h o i s s i t t i n g w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a r e d h u m a n n e a r a b l u e b o t t l e', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s w a l k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
[5m[31mWARNING[0m [32m2023-10-19T19:59:01 | py.warnings: [0m/home/wiss/zhang/Jinhe/singularity/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

[5m[31mWARNING[0m [32m2023-10-19T19:59:01 | py.warnings: [0m/home/wiss/zhang/Jinhe/singularity/utils/distributed.py:18: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  builtin_warn(*args, **kwargs)

[32m2023-10-19T19:59:01 | utils.basic_utils: [0mTrain Epoch: [0]  [   0/2288]  eta: 18:05:28  lr: 0.000010  temperature: 0.0100  video-loss_ita: 2.3239  video-loss_itm: 0.7330  time: 28.4653  data: 10.1014  max mem: 5063 res mem: 5346
text in iter ['a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s s q u a t t i n g', 't h e r e i s a s h u f f l e b o a r d w h i c h i s y e l l o w p l a s t i c o n a b o a r d m a d e o f b r o w n w o o d', 'a u n i c o r n p i n a t a s w a y s i n t h e w i n d f r o m a l i n e', 'a m a n f l i e s i n t h e a i r w i t h o n a m o t o r c y c l e a m a n m a k e s a m o t o c r o s s c i r c u i t u s i n g a h e a v y m a c h i n e p e o p l e r u n s m o t o c r o s s o n a n b u m p y r o a d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s h o w s t h e y e l l o w c o l o r e d l e n s t h a t s h e h a s w o r n', 'a f a l l s o f f a s k a t e b o a r d i n a n a w k w a r d w a y', 't h e c o n t e s t a n t i s s t a n d i n g o n t h e b l u e g r o u n d a n d s h e i s a w o m a n w i t h w h i t e s k i n a n d w h i t e h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n w h o i s a p h o t o g r a p h e r a n d h e h a s b r o w n h a i r h e i s c u r r e n t l y s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n s t a n d i n g i n t h e v i c i n i t y', 'a g i r l w i t h w h i t e s k i n a n d p u r p l e h a i r i s s p e a k i n g', 't h e r e i s a w h i t e c e r a m i c s i n k i n t h e k i t c h e n w h i c h i s a l s o w h i t e', 't h e r e i s a b o y s t a n d i n g w h o h a s w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e p o t a t o i n a p o t m a d e o f s i l v e r m e t a l', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r s i t t i n g', 't h e p e r s o n d r i v i n g t h e r a f t i s a n a d u l t a n d t h e r a f t i s m a d e o f y e l l o w r u b b e r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d w h i t e h a i r w h o i s c u r r e n t l y w o r k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b u m p e r c a r i s b e i n g d r i v e n b y a m a n w i t h w h i t e s k i n a n d b l a c k h a i r t h e b u m p e r c a r i t s e l f i s m a d e o f o r a n g e m e t a l', 'a m a n w i t h w h i t e s k i n i s p l a y i n g w i t h a b l a c k d o g', 't h e r e i s a m a n s t a n d i n g w i t h w h i t e s k i n a n d b r o w n h a i r', 'a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r i s r i d i n g a b r o w n h o r s e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a c i t y m a d e o f m e t a l t h e c o l o r i s y e l l o w a f t e r a w h i l e i t s c o l o r i s g r e y', 't h e r e i s a p e r s o n g r a s p i n g a r e d f i r e w h o i s a m a n w i t h y e l l o w s k i n', 'a w h i t e s k i n n e d s p o r t s m a n w i t h b l a c k h a i r i s r a i s i n g a r e d m e t a l b a r b e l l', 'a m a n w i t h w h i t e s k i n i s p l a y i n g a b r o w n d r u m']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s d a n c i n g i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r a n d s h e i s a n i n s t r u c t o r', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s s t a n d i n g', 'a c a r w h i c h i s m a d e o f w h i t e m e t a l i s p a r k e d', 't h e k n e e i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a c o o k i s p o u r i n g a w h i t e i n g r e d i e n t', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g', 'a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i s i n t h e g r e e n y a r d', 't h e r e i s a g r e y c a t l y i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s j u m p i n g', 't h e r e i s a g r e y c e r a m i c t i l e o n t h e b r o w n w o o d f l o o r', 'a g i r l w i t h w h i t e s k i n a n d g o l d h a i r w h o i s a d a n c e r i s r u n n i n g o n t h e b l a c k s t a g e', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a y e l l o w p l a s t i c c h e m i c a l a f t e r s o m e t i m e p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b r o w n h a i r t o u c h e s t h e s i n k w h i c h i s m a d e o f s i l v e r m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n c o o k i n g i s a m a n w i t h y e l l o w s k i n', 't h e p e r s o n h o l d i n g t h e s t i c k i s a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r a n d t h e s t i c k i t s e l f i s m a d e o f b l a c k m e t a l', 'a g i r l w i t h b l a c k s k i n a n d b l a c k h a i r i s h o l d i n g a w h i t e w o o d m o p', 'a m a n f a l l s o f f i n t o t h e d i r t a m a n c o n t i n u e s d o i n g t r i c k s o n t h e s l a c k r o p e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k s q u i r r e l i s s i t t i n g o n a b e n c h m a d e o f b l a c k w o o d', 'a b a r b e r r u b s s h a v i n g c r e a m o n a m a n s b a l d h e a d t h e b a r b e r s t o p s t o c l e a n h i s h a n d s w i t h a t o w e l', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g o n a b r o w n c l o t h s o f a', 'a w h i t e s k i n n e d m a n i s r i d i n g t h e y e l l o w b i k e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s c u r r e n t l y e x e r c i s i n g', 't h e p e r s o n e x e r c i s i n g i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o h a p p e n s t o b e a s u r f e r', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g a f t e r a l i t t l e w h i l e p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b r o w n h a i r b e g i n s t o c l i m b', 't h e r e i s a m a n w i t h w h i t e s k i n s t a n d i n g a n d h e h a s b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n e l d e r l y m a n w i t h f a i r s k i n i s e x e r c i s i n g', 't h e p e r s o n w i t h y e l l o w h a i r i s a w o m a n w i t h w h i t e s k i n a n d s h e i s c u r r e n t l y s i t t i n g', 'p e r s o n 1 a w h i t e s k i n n e d m a n i s d r i v i n g t h e g r e y w o o d e n c a n o e a f t e r a w h i l e p e r s o n 2 a n o t h e r w h i t e s k i n n e d m a n t a k e s h o l d o f t h e y e l l o w w o o d e n p a d d l e', 'a m a n w i t h w h i t e s k i n i s h o l d i n g a s i l v e r m e t a l t o o l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e s k i n n e d b o y w i t h g o l d h a i r s i t t i n g i n t h e a u d i e n c e', 'a c o n t e s t a n t w h o i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s p a r t i c i p a t i n g i n a r e d r u b b e r w a t e r p o l o g a m e', 't h e r e i s a w o m a n s t a n d i n g w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a y e l l o w w o o d c r o q u e t a n d a r e d w o o d c r o q u e t n e a r t h e c r o q u e t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p i n k r u b b e r r o p e i s h a n g i n g', 'a b l a c k m e t a l e l l i p t i c a l m a c h i n e i s l o c a t e d n e a r a m a n w i t h y e l l o w s k i n a n d b r o w n h a i r', 'a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r i s r a i s i n g a g r e e n m e t a l b a r b e l l', 't h e r e i s a w h i t e p l a s t i c h o o p i n t h e b l a c k r o o m']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g r e e n m e t a l b o a t i s r u n n i n g', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s m a k i n g a w h i t e c l o t h s c a r f', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w e a r i n g s i l v e r m e t a l s t i l t s p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s r u n n i n g o n t h e g r e y s i d e w a l k', 't h e p e r s o n w e a r i n g t h e v e s t i s a w h i t e m a n w i t h b r o w n h a i r a n d t h e v e s t i t s e l f i s m a d e o f b l u e c l o t h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 a b o y w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n c l e a n i n g i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't w o p r o f e s s i o n a l b i k e r s a r e b i k i n g a t t h e p e c k h a m b m x c l u b p e o p l e b e g i n r a c i n g a t h i g h s p e e d o v e r a c u r v e d r o a d t w o m o r e b a t c h e s o f r a c e r s s t a r t t h e s a m e r a c e', 'a w h i t e s k i n n e d p e r s o n i s i n a c i t y w i t h g r e e n c e r a m i c']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r a t t h e r e d u n i v e r s i t y', 'a m a n w i t h w h i t e s k i n w h o i s a s k a t e r i s s t a n d i n g o n a g r e y w o o d e n s k a t e b o a r d', 't h e r e i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r r u n n i n g', 'a w h i t e s k i n n e d m a n i s t o u c h i n g a b r o w n h e a d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e f l o w i n g w a t e r a p p e a r s g r e e n', 'a m a n w i t h b l a c k s k i n a n d b r o w n h a i r i s p l a y i n g t h e b o n g o d r u m w h i c h i s m a d e o f b l a c k w o o d', 't h e r e i s a b l a c k d o g l y i n g d o w n', 't r a n s p a r e n t r a i n i s c o v e r i n g t h e b u s h w h i c h i s c o m p o s e d o f g r e e n w o o d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b o y w i t h w h i t e s k i n a n d y e l l o w h a i r i s s t a n d i n g', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s d a n c i n g w i t h p e r s o n 2 a m a n a l s o w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a d a n c e r', 'p e r s o n 1 a m a l e c o n t e s t a n t w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g w i t h p e r s o n 2 a n o t h e r m a l e c o n t e s t a n t w h o a l s o h a s w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n t u r n t h e b r o o m t o c o l l e c t t h e d u s t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a c h i l d w i t h f a i r s k i n w h o i s a c o n t e s t a n t i s r i d i n g a w h i t e m e t a l b i k e', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a m p i n g a g r e y r u b b e r b e a m', 't h e r e i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s e x e r c i s i n g a n d h e h a p p e n s t o b e a b a l l p l a y e r', 'a w h i t e s k i n n e d b o y i s j u m p i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a r i v e r t h e c o l o r i s g r e e n a f t e r a w h i l e i t s c o l o r i s b l u e', 'a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s s i t t i n g', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r t h e b l a c k b u i l d i n g', 'a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r i s s u r f i n g o n t h e b l u e l a k e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s s i t t i n g', 't h e w o m a n w i t h w h i t e s k i n i s p u l l i n g t h e s n o w c i r c l e w h i c h i s m a d e o f r e d r u b b e r', 'p e r s o n 1 a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s c u r r e n t l y p l a y i n g w i t h t h e g r e e n b i l l i a r d b a l l s a f t e r s o m e t i m e p e r s o n 2 w h o a l s o h a s b l a c k s k i n a n d b l a c k h a i r a n d i s a p r e s i d e n t c h a n g e s i n t o a w h i t e c o s t u m e', 't h e r e i s a t r a n s p a r e n t w a t e r n e a r a p e r s o n a m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p i ñ a t a h a n g i n g i s r e d', 't h e p e r s o n i s a w h i t e s k i n n e d w o m a n w h o i s a p a i n t e r a n d h e r h a n d i s a p a r t o f h e r', 'p e o p l e a r e s i t t i n g a r o u n d a c a m p f i r e a m a n i n a h a t s t a n d s u p a n d c h o p s w o o d', 'o n t h e s t a g e s t a n d s a w o m a n w h o i s a d a n c e r w i t h w h i t e s k i n a n d b l a c k h a i r t h e s t a g e i t s e l f i s b l a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g r o u p o f p e o p l e g a t h e r o n a t a r m a c p e o p l e a r e i n a n a i r p o r t t h e n d r i v i n g d o w n t h e r o a d p e o p l e g o s u r f i n g i n t h e l a r g e w a v e s', 't h e f o o t w h i c h i s w h i t e b e l o n g s t o a p e r s o n w h o i s a w h i t e m a n w i t h b r o w n h a i r', 'a w o m a n t a l k s i n a b a c k y a r d w e a r i n g l o o s e c l o t h e s t h e w o m a n e x e r c i s e s t e p p i n g o n t h e m a t', 'a m a n w a l k s w i t h a l e a f b l o w e r t h e p e r s o n b l o w s l e a v e s o n t h e g r o u n d t h e l e a v e s m o v e a g a i n s t t h e a s p h a l t t h e m a n b l o w s a n o t h e r m a n w i t h t h e b l o w e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d w o m a n i s w a l k i n g', 't h e b l a c k s h o v e l i s t o u c h i n g t h e y e l l o w m i x t u r e', 'a m a n i s p l a y i n g a g a m e o f s h u f f l e b o a r d a m a n f a l l s d o w n o n t o t h e s h u f f l e b o a r d a d i s c i s d r o p p e d o n t o t h e g r o u n d', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s b r u s h i n g h e r b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c r e d i t s o f t h e c l i p a r e s h o w n p e o p l e a r e i n t e r a c t i n g i n a n i n s i d e c o u r t t w o t e a m s a r e p l a y i n g d o d g e b a l l', 'a b l a c k b u l l i s l y i n g d o w n', 't h e p e r s o n h o l d i n g t h e s h o v e l i s a m a n w i t h y e l l o w s k i n a n d g r e y h a i r w h i l e t h e s h o v e l i t s e l f i s m a d e o f p u r p l e p l a s t i c', 'a w h i t e s k i n n e d w o m a n b a l l p l a y e r i s i n t h e b l u e p o o l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e t a t t o o i s b l a c k', 't h e d a d s k a t e b o a r d s a n d h o l d s t h e b o y', 't h e p e r s o n k n e e l i n g i s a f e m a l e s t u d e n t w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e u n i f o r m c o l o r i s b l a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r o n t h e w h i t e m a t', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s i n s i d e a b r o w n w o o d e n s a u n a', 't h e w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s r i d i n g a b r o w n c a m e l f o l l o w i n g t h e m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a p h o t o g r a p h e r h o l d i n g a b l a c k m e t a l c a m e r a', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g a n d a f t e r a w h i l e h e s t a r t s c h o p p i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a r e f e r e e i s s t a n d i n g c l o s e t o t h e m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s a n i n s t r u c t o r', 'p e r s o n 1 a n a d u l t w i t h w h i t e s k i n a n d b l a c k h a i r i s l o c a t e d n e a r p e r s o n 2 w h o i s a b l a c k s k i n n e d m a n a n d a b a l l p l a y e r', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g o n a b r o w n w o o d e n b e a m s h e i s a s p o r t s m a n', 'p e r s o n 1 i s a w o m a n w i t h f a i r s k i n a n d b l a c k h a i r c u r r e n t l y w e a r i n g a y e l l o w m e t a l b l a d e a f t e r s o m e t i m e p e r s o n 2 a b o y w i t h f a i r s k i n i s s e e n h o l d i n g a w h i t e m e t a l s t i c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r r i d i n g a g r e e n m e t a l m o t o r b i k e', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s i t t i n g', 't h e p e r s o n s t a n d i n g i s a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a p e r s o n s i t t i n g a n d t h i s p e r s o n h a s y e l l o w s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w a l k i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a b l a c k m e t a l b i k e o n t h e b r o w n s a n d t r a c k', 't h e h a n d w h i c h i s w h i t e b e l o n g s t o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a p e r s o n w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w e a r i n g b l a c k e q u i p m e n t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l a c k m a n s t a n d i n g w i t h b l a c k s k i n a n d b l a c k h a i r', 't h e k i t e c o n s i s t s o f a y e l l o w p l a s t i c t a i l a n d a g r e e n b o d y', 'a w h i t e c e r a m i c t i l e i s p a r t o f t h e b a t h r o o m a n d t h e b a t h r o o m i t s e l f i s a l s o m a d e o f w h i t e c e r a m i c', 'a b r o w n p l a s t i c t o y i s f i g h t i n g w i t h a n o t h e r t o y']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a l e s u m o w r e s t l e r w i t h y e l l o w s k i n a n d b l a c k h a i r i s i n a f i g h t w i t h p e r s o n 2 w h o i s a l s o a m a l e s u m o w r e s t l e r w i t h y e l l o w s k i n a n d b l a c k h a i r', 'a v i d e o i s s h o w n h o w t o c h a n g e a s p a r e t i r e', 't h e r e i s a n a n i m a t i o n o n t h e o p e n i n g t i t l e s c r e e n a p e r s o n w a s h e s a n d p e e l s a p o t a t o t h e p e r s o n d i c e s t h e p o t a t o t h e r e i s t h e e n d i n g t i t l e s c r e e n', 't h e s a i l i s w h i t e a n d f l o a t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s r o l l e r b l a d i n g o u t s i d e i n a p a r k i n g l o t t h e p e r s o n d o e s s e v e r a l t r i c k s o n h i s r o l l e r b l a d e s t h e p e r s o n d o e s a c a r t w h e e l o n t h e g r o u n d', 't h e r e i s a g o l d e n s u n n e a r t h e s m o k e', 'a m a n i n y e l l o w a n d b l a c k s u i t w e l d s a s t e e l t h e p e r s o n s t o p s t h e w e l d i n g j o b t h e p e r s o n m o v e s a w a y a n d i n s p e c t t h e o b j e c t', 'a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h a n d o f t h e c o n t e s t a n t w h o i s a w h i t e m a n w i t h b r o w n h a i r i s a p a r t o f h i m', 't h e m a n s t a n d s a n d l e a v e t h e c o u r t s e v e r a l m e n p r a c t i c e b a s k e t b a l l i n a c o u r t', 't h e p e r s o n s p e a k i n g i s a b l a c k s k i n n e d m a n', 't h e r e i s a r e d m e t a l p a i n t n e a r b y a n d n e x t t o i t s t a n d s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n w i t h f a i r w h i t e s k i n i s i n i t i a l l y s t a n d i n g o n a w h i t e m e t a l b a r a n d l a t e r m o v e s t o s t a n d i n g o n a w h i t e m e t a l v e h i c l e', 'p e r s o n 1 a m a l e w o r k e r i s i n c o n v e r s a t i o n w i t h p e r s o n 2 a l s o a m a l e w o r k e r', 'p e r s o n 1 w h o h a s y e l l o w s k i n a n d b l a c k h a i r i s t a k i n g a p i c t u r e o f p e r s o n 2 p e r s o n 2 w h o i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s t h e r e f e r e e', 't h e p e r s o n d r i v i n g i s a c h i l d w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n i s p l a y i n g t w o d r u m s i n f r o n t o f h i m t h e p e r s o n s t o p s p l a y i n g t h e m a n d s i t s u p s t r a i g h t', 't h e r e i s a y e l l o w b i l l b o a r d o n a b l a c k w a l l', 't h e p e r s o n s i t t i n g i s a b o y w i t h f a i r s k i n a n d b l a c k h a i r', 'a c h i l d w i t h w h i t e s k i n i s w a l k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b e f o r e a n d a f t e r p i c t u r e o f a s i n k i s s h o w n t h e c l e a n i n g p r o d u c t s a n d t h e c l e a n s i n k a r e t h e n s h o w n', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r s i t t i n g', 'a b l a c k m e t a l m o w e r i s c u r r e n t l y r u n n i n g', 'a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s s q u a t t i n g', 'a d u l t s s k i b e h i n d t h e c h i l d', 'a y e l l o w m e t a l b u s i s p a r k e d', 't h e c u s t o m e r r i d i n g i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s t o u c h i n g t h e y e l l o w t h a t c h h a y', 't h e r e i s a y e l l o w p o t a t o i n t h e p o t w h i c h i s m a d e o f s i l v e r m e t a l', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g a v i o l i n m a d e o f b r o w n w o o d', 't h e p u m p k i n i s o r a n g e a n d i t g l o w s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c h e s t i s w h i t e', 'a h a n d t h e n c o v e r s t h e c a m e r a', 't h e p e r s o n w e a r i n g t h e h e l m e t h a s w h i t e s k i n b r o w n h a i r a n d t h e h e l m e t i t s e l f i s m a d e o f r e d b l a c k a n d w h i t e p l a s t i c', 'a l i t t l e g i r l s t a n d s o n a d i v i n g b o a r d p e o p l e a r e i n t h e s w i m m i n g p o o l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s l y i n g h a s w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a p e r s o n w i t h w h i t e s k i n w h o i s s t a n d i n g', 't h e p e r s o n w h o i s w o r k i n g a s a w h i t e s k i n n e d w e l d e r i s a n a d u l t', 'p e r s o n 1 a n o l d m a n w i t h w h i t e s k i n a n d w h i t e h a i r i s s t a n d i n g w h i l e p e r s o n 2 a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s p e a k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a b o y w i t h w h i t e s k i n a n d y e l l o w h a i r i s d a n c i n g w i t h p e r s o n 2 a m a n w h o i s a l s o a d a n c e r a n d h a s w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n r u n n i n g i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s i t t i n g', 'a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s s t a n d i n g n e a r a b l a c k c o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s p l a y i n g w i t h p e r s o n 2 w h o i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r', 'a w h i t e s k i n n e d b o y w i t h b r o w n h a i r w h o i s a s t u d e n t i s s t a n d i n g', 't h e p e r s o n h a s a w h i t e s h o u l d e r a n d t h e y a r e a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a m a n s t a n d i n g w h o i s a w h i t e s k i n n e d i n s t r u c t o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p u l l i n g a g r e y r o p e', 't h e h a n d w h i c h i s w h i t e b e l o n g s t o t h e p e r s o n w h o i s a w h i t e s k i n n e d m a n', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a b a l l p l a y e r i s i n c o n f l i c t w i t h p e r s o n 2 a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a b a l l p l a y e r', 't h e r e i s a y e l l o w b u s r u n n i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g i r l w i t h w h i t e s k i n a n d g o l d e n h a i r w h o i s a p e r f o r m e r i s s t a n d i n g', 't h e p e r s o n s i t t i n g i s a w h i t e s k i n n e d w o m a n w h o i s a p e r f o r m e r', 't h e g i r l w h o h a s y e l l o w s k i n a n d b l a c k h a i r i s a s p o r t s w o m a n s h e i s s t a n d i n g o n a b l a c k b o a r d f o l l o w i n g h e r t h e w o m a n w h o a l s o h a s y e l l o w s k i n a n d b l a c k h a i r i s a p h o t o g r a p h e r s h e i s h o l d i n g a b l a c k c a m e r a', 't h e r o o m i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g', 't h e p e r s o n d o i n g h o u s e w o r k i s a w h i t e s k i n n e d b o y w i t h b r o w n h a i r', 't h e p e r s o n s h o w s d r e s s i n g b e i n g p o u r e d o n t o a c a b b a g e s a l a d', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w a l k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 a b o y w i t h w h i t e s k i n a n d b r o w n h a i r', 'i s t r a d i t i o n a l l y s m o k e d i n m i d d l e e a s t e r n c o u n t r i e s w h e r e i t i s a p o p u l a r s o c i a l a c t i v i t y a m o n g f r i e n d s t h e c o l o r i s w h i t e a f t e r a w h i l e i t s c o l o r i s g o l d', 't h e l i p s t i c k i s b e i n g w i p e d o f f b y a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r t h e l i p s t i c k i t s e l f i s s i l v e r', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a b l a c k c l o t h s h o e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w o r k i n g w h o h a s w h i t e s k i n b r o w n h a i r a n d i s a b r i c k l a y e r', 'a p e r s o n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s w i m m e r i s e x e r c i s i n g', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g w e a r i n g a b o a t e r h a t', 'a t e n n i s b a l l m a d e o f w h i t e w o o d i s f l y i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s r u n n i n g', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 w h o i s a b l a c k s k i n n e d s p o r t s m a n w i t h b r o w n h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n s t a n d i n g', 'm a n i s s t a n d i n g i n a n i c e t r a c k t a l k i n g t o t h e c a m e r a p e o p l e a r e p l a y i n g c u r l i n g i n a n i c e c o u r t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c u p i s b e i n g h e l d b y a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r t h e c u p i t s e l f i s m a d e o f t r a n s p a r e n t g l a s s', 't h e r e i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r s t a n d i n g', 'a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r w h o i s a s t u d e n t i s h i t t i n g t h e r e d l e a t h e r p u n c h b a g', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s e m b r a c i n g p e r s o n 2 a n o t h e r w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h i l e b o t h o f t h e m a r e a t h l e t e s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e o p l e a p p e a r t o b e r i d i n g i n s i d e a t r a i n', 't h e r e i s y e l l o w f o o d o n t h e w h i t e c e r a m i c p l a t e', 't h e a r m i s w h i t e', 't h e h a i r o f a w o m a n w i t h w h i t e s k i n i s b r o w n w h i c h i s a p a r t o f h e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n i s s t a n d i n g w i t h a b a l l o n a s t r i n g t h e p e r s o n i s i n a c o m p e t i t i o n f o r a t h l e t i c s', 't h e c h i l d r e n d o j u m p s a n d m a k e f a s t t u r n s a n o n b o a r d c a m e r a c a p t u r e s a l l o f t h e f u n', 'a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s s l i d i n g o n t h e w h i t e s n o w a f t e r a w h i l e a n a d u l t w i t h w h i t e s k i n s l i d e s o n t h e b l a c k r u b b e r p i p e', 'a s k a t e r w i t h w h i t e s k i n a n d w h i t e h a i r i s w a l k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n h o l d i n g t h e b l a c k m e t a l b a t o n w h o h a p p e n s t o b e a w h i t e s k i n n e d d a n c e r w i t h b l a c k h a i r', 'p e r s o n 1 a m a l e c o n t e s t a n t w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g w i t h p e r s o n 2 a f e m a l e c o n t e s t a n t w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n s p e a k i n g i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s a n i n s t r u c t o r', 'a w o m a n w i t h w h i t e s k i n i s s p e a k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r p l a y i n g o n a g r e y h o p s c o t c h', 't h e b l a c k m e t a l s t e n c i l i s t o u c h i n g t h e y e l l o w p u m p k i n', 'a w h i t e p l a s t i c s u r f b o a r d i s o n t h e t r a n s p a r e n t w a t e r', 't h e p e r s o n s p e a k i n g i s a m a n w i t h a f a i r c o m p l e x i o n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n s h a n d s a r e s h o w n p l a y i n g p i a n o a c l o s e u p o f a t r u m p e t s h o w s a m a n p l a y i n g t h e v i d e o f a d e s t o t h e p e o p l e p l a y i n g o n s t a g e t h e c a m e r a z o o m s i n o n t h e t r u m p e t p l a y e r a g i r l i s s h o w n p l a y i n g p i a n o t h e d u o c o n t i n u e p l a y i n g u n t i l t h e s o n g e n d s', 'a s i l v e r m e t a l k n i f e i s c u t t i n g a g r e e n c u c u m b e r', 't h e c a r d i s r e d', 't h e r e i s a y e l l o w l i g h t i n s i d e a p u m p k i n a n d b o t h t h e l i g h t a n d t h e p u m p k i n a r e y e l l o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n p u s h i n g t h e m o w e r i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r a n d t h e m o w e r i t s e l f i s m a d e o f b l a c k m e t a l', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r s t a n d i n g o n t h e r e d p l a s t i c t r a c k i n f r o n t o f t h e a u d i e n c e', 't h e i n g r e d i e n t i s w h i t e', 't h e p e r s o n s t a n d i n g i n t h e a u d i e n c e h a s f a i r s k i n a n d b r o w n h a i r s h e i s a w o m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n s p e a k i n g w i t h w h i t e s k i n a n d b l a c k h a i r', 'a c o m p a n y l o g i s o n t h e s c r e e n a b o a t i s f l o a t i n g o n t h e w a t e r t h e c a m e r a i s s c a n n i n g t h e b o a t a w o m a n i s t a k i n g a s e l f i e w h i l e o n t h e b o a t t h e p e r s o n l e t g o o f t h e l i n e a n d f l o a t e d f r e e l y', 't h e p e r s o n t h r o w i n g t h e f r i s b e e i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a l s o a d o g t r a i n e r t h e f r i s b e e i t s e l f i s m a d e o f w h i t e p l a s t i c', 'a m a n i s s i t t i n g o n a c o u c h d r i n k i n g a b e e r t h e p e r s o n s t a n d s u p a n d w a l k s o u t t h e d o o r s o m e o n e i s w a l k i n g i n t o a k i t c h e n p e o p l e o p e n t h e f r i d g e a n d g e t a b e e r p e o p l e b r i n g t h e o b j e c t t o t h e m a n i n b e d t h e p e r s o n s i t s u p a n d s t a r t s d r i n k i n g t h e b e e r a p e r s o n p i c k s u p a c e l l p h o n e o n a b e d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r i s r a i s i n g h e r w h i t e a r m', 'a m a n w i t h g r e y h a i r i s s i n g i n g', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a w h i t e p l a s t i c s c r a p e r w h i l e p e r s o n 2 a l s o a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a b l u e r a g', 't h e h a m m e r i s b e i n g t h r o w n b y a s p o r t s m a n w h o i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d t h e h a m m e r i t s e l f i s m a d e o f b l a c k m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a c o n t e s t a n t i s r u n n i n g o n t h e r e d p l a s t i c f i e l d', 't h e r e i s a w o m a n w i t h f a i r w h i t e s k i n a n d b r o w n h a i r s t a n d i n g', 't h e p e r s o n d r i v i n g i s a m a n w i t h b l a c k h a i r a n d f a i r s k i n', 'a w o m a n w i t h w h i t e s k i n b r o w n h a i r a n d y e l l o w h a i r i s h a v i n g h e r h a i r t o u c h e d b y a h a i r s t y l i s t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w o m a n p e e k s o u t f r o m b e h i n d a w a l l t h e w o m a n l o o k s a t a l a p t o p s c r e e n w i t h a m a n', 't h e r e i s a w h i t e n y l o n r o p e o n t h e g r e e n h i l l', 'o n t h e r o o f i s a g r e y w o o d e n t i l e a n d t h e r o o f i t s e l f i s a l s o g r e y', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o w o r k s a s a c o o k i s s p e a k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a f e m a l e n e w s r e p o r t e r i s t a l k i n g i n a n e w s r o o m t h e p e o p l e a r e h i t t i n g b a g s w i t h s t i c k s a s t h e y r i d e', 't h e p e r s o n s t a r t s p a i n t i n g t h e d e s k w h i t e w i t h a p a i n t b r u s h t h e p e r s o n s t a r t s p a i n t i n g t w o o f t h e d r a w e r s o r a n g e', 'p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 p e r s o n 2 w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s a c o n t e s t a n t i n t h e a u d i e n c e', 't h e r e i s a w o m a n w i t h b l a c k s k i n a n d b l a c k h a i r w h o i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e a r m i s b l a c k', 't h e t a t t o o w h i c h i s b l a c k i s a n a t u r a l p a r t o f t h e p e r s o n w h o i s a w h i t e m a n w i t h b l a c k h a i r', 't h e c u s t o m e r w i t h w h i t e s k i n w h o i s l y i n g i s a m a n', 't h e p e r s o n p u l l i n g t h e y e l l o w l i n e n r o p e h a s w h i t e s k i n a n d b l a c k h a i r a n d h a p p e n s t o b e a b o y']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a p e r f o r m e r i s p r e s e n t i n t h e b l a c k p a r k', 't h e p e r s o n s t a n d i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o h a p p e n s t o b e a s u r f e r', 'p e o p l e d a n c e a n d d a n c e w o r k i n g v e r y w e l l t o g e t h e r', 't h e r e i s a m a n s i t t i n g w h o i s a r e f e r e e w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s p e a k i n g i s a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r', 't h e r e i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a d a n c e r o n t h e w h i t e s t a g e', 'p e r s o n 1 w h o i s a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r i s n e a r p e r s o n 2 w h o i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r', 't h e p e r s o n s i t t i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e k i t e i s b e i n g t o u c h e d b y a p e r s o n w h o i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r a n d t h e k i t e i t s e l f i s g r e e n', 't h e p e r s o n w h o i s s q u a t t i n g h a s y e l l o w s k i n a n d b l a c k h a i r', 't h e h o r s e i s b r o w n a n d c u r r e n t l y s t a n d i n g', 'a w h i t e s k i n n e d s o l d i e r w h o i s a m a n i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h a i r s t y l i s t w h o i s a w h i t e m a n w i t h b r o w n h a i r i s t o u c h i n g t h e c u s t o m e r w h o i s a w h i t e w o m a n w i t h y e l l o w h a i r', 't h e r e i s t r a n s p a r e n t s y r u p i n t h e s i l v e r m e t a l s h a k e r', 't h e r e i s a w h i t e s k i n n e d b o y s t a n d i n g w i t h b r o w n h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n w h o i s a c o n t e s t a n t n e a r t h e g o a l w h i c h i s m a d e o f w h i t e m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a n a d u l t w i t h w h i t e s k i n i s s t a n d i n g c l o s e t o p e r s o n 2 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a s p o r t s m a n w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w a l k i n g o n t h e g r e e n g r o u n d', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g w h o i s a c o n t e s t a n t', 't h e r e i s a n e g g o n a w h i t e c e r a m i c p l a t e t h a t i s y e l l o w i n c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s w a l k i n g u p a l a d d e r t o a r o o f a p e r s o n i s s t a n d i n g i n f r o n t o f a h o u s e t a l k i n g m e n a r e p u t t i n g n e w s h i n g l e s o n t o a r o o f', 't h e p e r s o n e x e r c i s i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o h a p p e n s t o b e a b a l l p l a y e r i s o n a b r o w n b e a c h', 't h e r e i s a w h i t e g l o v e o n t h e b r o w n p l a s t i c m u l c h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s i t t i n g h a s b r o w n h a i r a n d a y e l l o w s k i n c o m p l e x i o n a s h e i s a b o y', 'a s p o r t s m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s r u n n i n g o n t h e y e l l o w p l a s t i c t r a c k', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g', 't h e r e i s a b o y w i t h w h i t e s k i n a n d y e l l o w h a i r s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s i t t i n g', 'i n t h e b a c k g r o u n d t h e r e i s a p e r s o n w h o i s a w h i t e m a n w i t h b r o w n h a i r a n d t h e b a c k g r o u n d i t s e l f i s a l s o b r o w n', 'p e r s o n 1 a w h i t e s k i n n e d b o y w i t h b l a c k h a i r i s e n g a g e d i n a f i g h t w i t h p e r s o n 2 a n o t h e r w h i t e s k i n n e d b o y w i t h b r o w n h a i r a f t e r s o m e t i m e p e r s o n 2 a w h i t e s k i n n e d b o y b e g i n s p l a y i n g w i t h a n o t h e r b o y w h o a l s o h a s w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n w h o i s s m i l i n g h a s w h i t e s k i n a n d y e l l o w h a i r a n d s h e i s a g i r l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n a d u l t i s s t a n d i n g', 'a w o m a n w i t h w h i t e s k i n i s h o l d i n g a s t r i n g m a d e o f g o l d e n c l o t h', 't h e f l o o r i s m a d e o f c e r a m i c t h e c o l o r i s b l a c k a f t e r a w h i l e i t s c o l o r i s w h i t e', 'a n o r a n g e f i r e i s b u r n i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r p e r s o n 2 a w o m a n w h o i s a c h e e r l e a d e r w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i n t h e b l u e g y m', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s o n a b r o w n f i e l d', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s s t a n d i n g n e a r p e r s o n 2 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r t h e y b o t h h a v e a n a u d i e n c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s p e a k i n g w i t h p e r s o n 2 a n o l d m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a b r o w n h o r s e s t a n d i n g', 't h e r e i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i n t h e b l a c k r i v e r', 't h e p e r s o n s p e a k i n g i s a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r w h o w o r k s a s a b a r t e n d e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w o m a n w h o h a s w h i t e s k i n a n d b r o w n h a i r a n d i s a r e p o r t e r i s s t a n d i n g w h i l e t h e b o y w h o h a s w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g', 'o n t h e y e l l o w f i e l d s t a n d s a b o y w h o i s a b a l l p l a y e r h a v i n g w h i t e s k i n a n d b l a c k h a i r', 'a y e l l o w c a t t l e i s s t a n d i n g w h i l e a g r e y e l e p h a n t i s w a l k i n g', 't h e r e i s a p e r s o n s t a n d i n g w h o i s a b l a c k h a i r e d m a n a n d a r e f e r e e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d r e d h a i r i s h o l d i n g a w h i t e c o t t o n t o w e l', 'a w h i t e s k i n n e d p e r s o n w h o w e a r s a b o a t e r h a t t h e h a i r _ c o l o r i s b r o w n a f t e r a w h i l e h i s h a i r _ c o l o r i s y e l l o w', 't h e r e i s a m a n s t a n d i n g o n t h e b l u e m e t a l p l a t f o r m h e h a s w h i t e s k i n b r o w n h a i r a n d a p p e a r s t o b e a s p o r t s m a n', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g w h o i s a b a r b e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n i n t h e a u d i e n c e i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r a n d h e i s s t a n d i n g', 't h e r e i s a b o y s t a n d i n g w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e f l u t e i s b e i n g p l a y e d b y a g i r l w h o h a s y e l l o w s k i n a n d b r o w n h a i r t h e p e r f o r m e r h a s a g o l d m e t a l f l u t e', 'p e r s o n 1 a m a l e p h o t o g r a p h e r w i t h w h i t e s k i n a n d b l a c k h a i r i s c a p t u r i n g a p i c t u r e o f p e r s o n 2 a f e m a l e c h e e r l e a d e r w i t h w h i t e s k i n a n d g o l d e n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d g o l d e n h a i r i s h o l d i n g a p i n k p l a s t i c h o o p', 't h e b l a c k s h o e i s c o v e r e d i n g r e y d i r t', 't h e r e i s a m a n s i t t i n g w h o h a s b l a c k s k i n a n d b l a c k h a i r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g o n a b r o w n w o o d f l o o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l u e l i n e f l o a t i n g', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a p e r f o r m e r i s s i t t i n g', 't h e r e i s a b r o w n t r e e n e a r t h e y e l l o w p o k e m o n', 'a w h i t e s k i n n e d m a n i s h o l d i n g a y e l l o w m e t a l d r i l l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a s p o r t s m a n a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s s t a n d i n g o n a r e d w o o d e n b e a m', 'a s i l v e r t r i m m e r m a d e o f m e t a l a n d a g r e e n t r e e m a d e o f w o o d', 'w a t e r i s f l o w i n g a n d i t i s t r a n s p a r e n t', 't h e r e i s a w o m a n s t a n d i n g w h o h a s w h i t e s k i n y e l l o w h a i r a n d i s a d o c t o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a n o p e n i n g t i t l e s c r e e n t h e r e i s t h e c l o s i n g t i t l e s c r e e n', 't h e r e i s a m a n s i t t i n g w h o i s a v i o l i n i s t w i t h b l a c k h a i r a n d w h i t e s k i n', 'a m a n w i t h w h i t e s k i n i s s i t t i n g o n a b r o w n w o o d e n c h a i r', 't h e r e i s a f l o a t i n g p o l i s h t h a t i s r e d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n i s g e t t i n g t h e i r l e g s w a x e d o n a t a b l e p e o p l e r u b s o m e l o t i o n o n t o t h e i r l e g s p e o p l e s h o w t h e i r c l e a n w a x e d l e g s', 't h e a r m b e l o n g s t o a p e r s o n w h o i s a w h i t e b o y w i t h b l a c k h a i r a n d h e i s a d a n c e r', 'j o u r n a l i s t s s u r r o u n d t h e a t h l e t e s w i t h c a m e r a s m o r e d i s c u s t h r o w p e r f o r m a n c e s a r e s h o w n a c a m e r a c r e w f o c u s e s o n a s w e a t y s e a t e d a t h l e t e a n o t h e r p e r f o r m a n c e o f d i s c u s t h r o w i s s h o w n t h r e e p e o p l e s i t t a l k i n g i n f r o n t o f a n a u d i e n c e', 't h e r e i s a r u n n i n g s a n d e r t h a t i s m a d e o f b l u e m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b i k e w h i c h i s m a d e o f m e t a l i s b l a c k a n d i n w o r k i n g c o n d i t i o n', 'a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s s p e a k i n g', 'a n a d u l t p e r s o n w i t h w h i t e s k i n i s r i d i n g', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 w h o i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r s h e i s a d o g t r a i n e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n i n g r e d i e n t w h i c h i s y e l l o w i s l o c a t e d n e a r a n o t h e r i n g r e d i e n t a l s o y e l l o w', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s s i t t i n g a m o n g t h e a u d i e n c e', 'a w h i t e h o r s e i s w a l k i n g', 'a n a d u l t w i t h w h i t e s k i n i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e l i g h t a n d a y e l l o w l i g h t n e a r b y', 't h e p o r c h i s a w h i t e w o o d e n s t r u c t u r e', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g', 't h e r e i s a b l u e w o o d b a r n e a r t h e p e r s o n w h o i s a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r a n d i s a l s o a r e f e r e e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a r e d c a r a n d a b l a c k c a r n e a r t h e c a r', 't h e p e r s o n l e t s g o o f t h e d i s c a n d w a t c h e s i t f l y p e o p l e a r e s h o w n o n e a t a t i m e t h r o w i n g t h e d i s c s', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g w h o i s a c o o k', 'a w o m a n w i t h w h i t e s k i n i s h o l d i n g a p i n k p l a s t i c r a z o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w r a p s s e v e r a l c h r i s t m a s g i f t s t h e w o m a n p l a c e s a t e d d y b e a r i n a b o w l a w o m a n p l a c e s a j e w e l r y b o x i n a b o x t h e w o m a n p r e s e n t s a g o l d b o w l t h e w o m a n h o l d s o u t s t a c k e d w r a p p e d g i f t s w i t h h e r h a n d s', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r o n t h e b l u e s e a', 't h e p e r s o n i s a m a n w i t h w h i t e s k i n g r a y h a i r a n d a b o d y t h a t i s p a r t o f h i m h e i s a l s o a m u s i c i a n', 'a b o y w i t h y e l l o w s k i n a n d b l a c k h a i r i s h o l d i n g a w h i t e p l a s t i c b o t t l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s s i t t i n g n e x t t o s e v e r a l s m a l l t r e e s t h e p e r s o n p u l l s s o m e l e a v e s o f f o f t h e t r e e s t h e p e r s o n t a k e s s c i s s o r s a n d c u t s s o m e l e a v e s o f f t h e t r e e', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s w a l k i n g', 't h e p e r s o n s p e a k i n g i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s t h e p r e s e n t e r', 'a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r i s h o l d i n g a v i o l i n m a d e o f b r o w n w o o d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s w i m m i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a d i v e r', 't h e b u s w h i c h i s g r e e n a n d m a d e o f m e t a l i s r u n n i n g', 't h e p e r s o n s q u a t t i n g i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o a l s o h a p p e n s t o b e a r e f e r e e', 'a p e r s o n s h a k e s t h e g l a s s a n d s e t s i t d o w n a p e r s o n h o l d s u p t h e d r i n k w h i l e t a l k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n b e g i n s j u m p i n g i n f r o n t o f a t a b l e o f j u d g e s t h e p e r s o n h o p s s p i n s a n d f l i p s w i t h t h e r o p e', 'a g r i n d e r m a c h i n e i s s h o w n o n a p a t i o t h e p e r s o n t h e n d e m o n s t r a t e s h o w t h e m a c h i n e i s u s e d', 'a p l a y e r s c o r e s a n d t h e t e a m s c o n t i n u e p l a y i n g', 'a w h i t e n e c k i s a p a r t o f a p e r s o n w h o i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r a n d i s a s p o r t s m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g o n a b r o w n b e a c h', 'a w h i t e s k i n n e d m a n i s p l a y i n g a y e l l o w w o o d b o n g o d r u m', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i n t h e b r o w n r o o m', 'a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r i s p e r f o r m i n g a s a p e r f o r m e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h o l d i n g t h e s t i c k i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d t h e s t i c k i t s e l f i s b l a c k', 't h e p e r s o n i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r s h e i s l y i n g', 't h e p e r s o n s q u a t t i n g i s a c a u c a s i a n m a l e p h o t o g r a p h e r', 'a k i t e i s s h o w n i n t h e s k y b y a t r e e a b o y c h a s e s a f t e r t h e k i t e a n d c a t c h e s i s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s s t a n d i n g o n a b r o w n f i e l d', 't h e f i n g e r i s a p a r t o f t h e p e r s o n s p e c i f i c a l l y a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r', 'a p e r s o n w i t h f a i r s k i n a n d g o l d e n h a i r i s w a s h i n g a p i n k c e r a m i c d i s h w h i l e l e a n i n g o n a w h i t e s i n k', 't h e p e r s o n w e a r i n g t h e p i n k v e s t i s a w o m a n w i t h w h i t e s k i n b r o w n h a i r a n d a n a c t o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a y o u n g m a n i s s h o w n o n a r o a d w e a r i n g s t i l t s t h e p e r s o n w a l k s o v e r t o t h e s i d e o f t h e r o a d', 't h e m a n w h o h a s w h i t e s k i n a n d b r o w n h a i r i s l y i n g o n a y e l l o w r u b b e r s w i m r i n g w h i l e t h e w o m a n w h o a l s o h a s w h i t e s k i n a n d b r o w n h a i r i s h a v i n g a c o n v e r s a t i o n w i t h a n o t h e r w o m a n w h o h a s w h i t e s k i n a n d b l a c k h a i r', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s s i t t i n g', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o h a s y e l l o w s k i n a n d b l a c k h a i r i s d r i n k i n g a l c o h o l f r o m a b r o w n g l a s s a f t e r s o m e t i m e p e r s o n 2 w h o a l s o h a s y e l l o w s k i n a n d b l a c k h a i r f o l l o w s s u i t a n d d r i n k s f r o m t h e s a m e b r o w n g l a s s', 't h e r e i s a b o y w i t h w h i t e s k i n a n d y e l l o w h a i r s t a n d i n g n e a r a t r a n s p a r e n t m e t a l b a s k e t', 'a n e l d e r l y m a n w i t h w h i t e h a i r a n d w h i t e s k i n i s s q u a t t i n g o n t h e b r o w n s a n d', 'a s h u f f l e b o a r d i s s h o w n i n a r o o m a g l a s s o f b e e r i s s h o w n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s i t t i n g i s a w o m a n w i t h f a i r s k i n a n d b r o w n h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g w h o i s a c u s t o m e r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w h o i s e x e r c i s i n g', 'p e r s o n 1 a b o y w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g w i t h p e r s o n 2 a n o t h e r b o y w h o a l s o h a s w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a s p o r t s m a n i s h o l d i n g o n t o t h e w h i t e w o o d e n p a r a l l e l b a r s', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g', 't h e w o m a n w i t h w h i t e s k i n i s e x e r c i s i n g s h e h a s b l a c k h a i r', 'p e r s o n 1 a b o y w i t h y e l l o w s k i n a n d b l a c k h a i r i s w a l k i n g o n t h e g r e y s i d e w a l k w h i l e p e r s o n 2 a l s o a b o y w i t h y e l l o w s k i n a n d b l a c k h a i r i s d o i n g t h e s a m e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s t a n d i n g i s a g i r l w i t h y e l l o w h a i r a n d w h i t e s k i n', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n e x e r c i s i n g i s a w h i t e s k i n n e d b o y w i t h b l a c k h a i r w h o i s a l s o a c o n t e s t a n t', 'a g i r l w i t h f a i r s k i n a n d b r o w n h a i r i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m e t a l s t a i r c a s e t h e c o l o r i s b r o w n a f t e r a w h i l e i t s c o l o r i s y e l l o w', 't h e p e r s o n w h o i s c o o k i n g i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r a n d s h e i s a l s o a b a r t e n d e r', 't h e r e i s a p e r s o n h o l d i n g a n o r a n g e m e t a l m o w e r t h e p e r s o n i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a w h i t e s k i n n e d b r o w n h a i r e d g i r l w h o i s a s p o r t s e n t h u s i a s t i s s t a n d i n g o n t h e b r o w n w o o d e n b e a m']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
[32m2023-10-19T20:00:18 | utils.basic_utils: [0mTrain Epoch: [0]  [ 100/2288]  eta: 0:38:14  lr: 0.000010  temperature: 0.0108  video-loss_ita: 2.7030  video-loss_itm: 0.6255  time: 0.7366  data: 0.0114  max mem: 7604 res mem: 7876
text in iter ['t h e m a n i s s h o w n t r i c k i n g t h e b u l l', 't h e l e a f i s y e l l o w', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 a l s o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i n f r o n t o f t h e a u d i e n c e', 'p e r s o n 1 a w h i t e m a n w i t h b l a c k h a i r i s r a i s i n g p e r s o n 2 a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r w h o i s a p e r f o r m e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s p l a y i n g t h e b l a c k a c c o r d i o n w h i c h i s a n o r g a n', 't h e p e r s o n h o l d i n g t h e d r i n k i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r w h o a l s o h a p p e n s t o b e t h e b a r t e n d e r a n d t h e d r i n k i t s e l f i s s e r v e d i n a w h i t e g l a s s', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i n t h e g r e y g y m', 't h e p e r s o n r u n n i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n d r i v i n g i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a s i l v e r m e t a l k n i f e i s s l i d i n g', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s t o u c h i n g a b r o w n c a t a f t e r a w h i l e s h e s t a r t s t o p l a y w i t h t h e s a m e b r o w n c a t', 't h e r e i s a y e l l o w d o g s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h a n d i s a p a r t o f a w h i t e s k i n n e d m a n w i t h w h i t e h a i r', 'a w h i t e s k i n n e d g o l d e n h a i r e d s p o r t s m a n w h o i s p l a y i n g t a b l e t e n n i s s t r i k e s a y e l l o w p l a s t i c b a l l', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g', 't h e r o t a t i n g t i r e i s m a d e o f b l a c k r u b b e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a v i o l i n i s t i s w a l k i n g o n t h e g r e y s t o n e g r o u n d', 'p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s t o u c h i n g p e r s o n 2 w h o i s a f e m a l e c u s t o m e r w i t h w h i t e s k i n a n d b r o w n h a i r', 'a w o m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s s c r a p i n g h e r b l a c k l e g', 't h e p e r s o n i n t h e a u d i e n c e i s a m a n w i t h w h i t e s k i n a n d h e i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a n o r a n g e p u m p k i n', 'p e r s o n 1 w h o i s a b o y w i t h b l a c k s k i n a n d b l a c k h a i r i s s t a n d i n g n e a r p e r s o n 2 w h o i s a l s o a b o y w i t h b l a c k s k i n a n d b l a c k h a i r', 't h e p e r s o n i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r a n d o n e o f h i s b o d y p a r t s i s a w h i t e h a n d', 't h e r e i s a m a n w i t h w h i t e s k i n w h o i s a b a k e r w o r k i n g a t t h e g r e y b a k e r y']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l a c k m e t a l g u n o n a g r e e n t r a c k', 't h e p e r s o n s i t t i n g i s a m a n w i t h w h i t e s k i n b l a c k h a i r a n d i s a t a t t o o a r t i s t', 't h e p e r s o n c h e e r i n g i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o h a p p e n s t o b e a s p o r t s m a n', 't h e r e i s a s i l v e r g l a s s t a b l e n e a r a w o m a n w h o h a s w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a b o y w i t h w h i t e s k i n i s s i t u a t e d c l o s e t o p e r s o n 2 w h o i s a l s o a b o y w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n h o l d i n g t h e f l u t e i s a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r t h e f l u t e i t s e l f i s m a d e o f y e l l o w w o o d', 't h e p e r f o r m e r w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g t h e b l a c k p i a n o f o l l o w i n g h i m t h e a u d i e n c e m e m b e r w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a b l a c k w h i t e a n d t r a n s p a r e n t p h o n e', 'p e r s o n 1 w h o i s a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r i s p u l l i n g p e r s o n 2 w h o i s a w h i t e s k i n n e d c h i l d a n d a d a n c e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n i s h a m m e r i n g n a i l s i n t o a r o o f', 't h e p e r s o n i s s h o w n m i x i n g t h e i n g r e d i e n t s t h e p e r s o n t a k e s t h e c o o k i e s o u t w h e n t h e y r e d o n e', 't h e p e r s o n w a l k i n g i s a w o m a n w i t h w h i t e s k i n', 'w o m e n a r e d a n c i n g o n a s t a g e p e o p l e a r e s w i n g i n g t h e i r h i p s f r o m s i d e t o s i d e t h e d a n c e i s s u p p o s e d t o b e s e x y p e o p l e f o r m a l i n e a s t h e y d a n c e p e o p l e t u r n t h e i r b a c k s t o t h e a u d i e n c e a n d d a n c e t h e l i g h t s g o d o w n t h e d a n c e i s o v e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w o m a n w i t h f a i r s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 a m a n a l s o w i t h f a i r s k i n a n d b l a c k h a i r', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s h o l d i n g a b r o w n w o o d e n s t i c k', 't h e b o a t i s b l u e a n d i t i s c u r r e n t l y r u n n i n g', 'a w h i t e s k i n n e d m a n i s h o l d i n g a b l a c k m e t a l a r r o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s p l a y i n g t h e b l a c k m e t a l e l e c t r o n i c k e y b o a r d', 't h e r e i s a m a n i n t h e a u d i e n c e w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s s i t t i n g', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s p l a y i n g h o c k e y t h e h o c k e y i s m a d e o f w h i t e p l a s t i c', 't h e p e r s o n h o l d i n g t h e g u n i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h i l e t h e g u n i t s e l f i s m a d e o f w h i t e m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e a r e t w o o p e n i n g s c r e e n s f o r p o k e r a t a c a s i n o t h e r e i s t h e d e a l e r s p e a k a n d d e a l c a r d s t h e r e i s a l a r g e j a c k p o t s i g n t h e r e i s t h e d e a l e r s h u f f l e t h e c a r d s t h e r e i s t h e m a n p e e k a t h i s c a r d s t h e m a n p e e k s a t h i s c a r d s a g a i n t h e d e a l e r t u r n s o v e r t h e p l a y e r s c a r d s t h e r e i s t h e c l o s i n g s c r e e n f o r t h e c a s i n o', 't h e r e i s a s i l v e r m e t a l p o t a n d a b l a c k m e t a l p o t n e a r t h e p o t', 't h e a d u l t c u s t o m e r w i t h w h i t e s k i n i s t o u c h i n g t h e p u r p l e w o o d t a b l e', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r o n a w h i t e r o o f w o r k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r s q u a t t i n g o n t h e g r e y s i d e w a l k', 'a m a n s i t s b e h i n d a d e s k t w o p e o p l e a r e s i t t i n g o n a b e a n b a g c h a i r a m a n i s d r i n k i n g f r o m a m u g', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r a n d a n a t h l e t i c b u i l d i s s t a n d i n g c l o s e t o p e r s o n 2 a n o t h e r m a n w h o h a s w h i t e s k i n a n d b l a c k h a i r a l s o a n a t h l e t e', 't h e r e i s a s i l v e r m e t a l f a u c e t o n t h e s i n k a n d t h e s i n k i s a l s o m a d e o f s i l v e r m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s l y i n g i s a w h i t e s k i n n e d m a n', 'p e r s o n 1 a m a n w i t h b l a c k s k i n b l a c k h a i r a n d b o o t b l a c k a t t i r e i s w o r k i n g w h i l e p e r s o n 2 a n o l d m a n w i t h w h i t e s k i n a n d w h i t e h a i r i s s i t t i n g', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s t a l k i n g t o p e r s o n 2 a s t u d e n t w h o i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r', 'a p e r s o n w h o i s a c h i l d w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g a s i l v e r m e t a l f o r k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b i k e t h a t i s b l a c k w h i t e b l u e i s i n m o t i o n', 'a m a n w i t h w h i t e s k i n a n d w h i t e h a i r i s s i t t i n g h e i s a p e r f o r m e r', 't h e c r o w d a p p l a u d t h e b o y h o l d i n g b r i t i s h f l a g s', 't h e p e r s o n w h o h a s a w h i t e b a c k i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e a n d b l a c k c e r a m i c t i l e i s a p a r t o f t h e w h i t e b a t h r o o m', 't h e h a i r s t y l i s t a g i r l w i t h y e l l o w s k i n a n d b l a c k h a i r i s t o u c h i n g t h e o t h e r g i r l w h o a l s o h a s y e l l o w s k i n a n d b l a c k h a i r', 't h e s p o r t s m a n a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s t o u c h i n g t h e b r o w n w o o d e n b e a m', 'a b o y w i t h b l a c k s k i n a n d b l a c k h a i r i s h o l d i n g a g r e e n c l o t h k i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n p e r f o r m i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n w h o i s j u m p i n g i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a g i r l w i t h y e l l o w s k i n w h o i s k n e e l i n g', 'p e r s o n 1 w h o i s a w h i t e s k i n n e d m a n i s n e a r p e r s o n 2 w h o i s a l s o a w h i t e s k i n n e d m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s t o u c h i n g a b l u e c e r a m i c b o w l', 't h e p e r s o n i s a w o m a n w i t h w h i t e s k i n w h o h a s y e l l o w h a i r w h i c h i s a l s o p a r t o f h e r', 't h e m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s p e a k i n g', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s e n g a g e d i n a d i s p u t e w i t h p e r s o n 2 a n o t h e r m a n w h o i s w h i t e s k i n n e d a n d h a s b l a c k h a i r b o t h i n d i v i d u a l s a r e b a l l p l a y e r s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n e x e r c i s i n g i s a w h i t e s k i n n e d c o n t e s t a n t', 'a p i l e o f k i n d l i n g f l a n k e d b y r o c k s i s s h o w n t h e k i n d l i n g i s l i t w i t h a t o r c h', 'a b l a c k h a i r e d w o m a n w i t h b l a c k s k i n i s c u r r e n t l y p l a y i n g s q u a s h u s i n g a b l u e r u b b e r b a l l', 't h e p e r s o n s t a n d i n g i s a s p o r t s m a n w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n o l d m a n w i t h w h i t e s k i n a n d w h i t e h a i r w h o i s a b a r b e r i s t o u c h i n g b r o w n h a i r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s i t t i n g o n t h e t u b e w h i c h i s m a d e o f r e d r u b b e r', 't h e c e i l i n g h a s a y e l l o w c o l o r', 't h e c a t h a s a w h i t e p a w w h i l e t h e c a t i t s e l f i s b l a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s r u n n i n g i s a b l a c k s k i n n e d w o m a n', 't h e p e r s o n a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s n e a r a b l a c k p l a s t i c n e t', 't h e r e i s a m a n s t a n d i n g w i t h y e l l o w s k i n a n d b l a c k h a i r', 'a m a n w i t h w h i t e h a i r i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n e x e r c i s i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s p o r t s m a n', 'w a t e r f l o w s a n d i s t r a n s p a r e n t', 't h e r e i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r o n t h e b l u e p l a s t i c s l i d e', 't h e p e r s o n e x e r c i s i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g i r l a n d a d o g i s i n t h e f i e l d', 't h e r e i s a w h i t e w o o d e n c a b i n e t n e a r t h e o t h e r c a b i n e t', 't h e w e l d i n g g u n w h i c h i s m a d e o f m e t a l i s b l a c k i n c o l o r a n d c u r r e n t l y o p e r a t i o n a l', 't h e p e r s o n p u t s o n a l a r g e n e o n s h i r t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s w o r k i n g', 'a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s a w o r k e r i s s p e a k i n g', 'a r e d p l a s t i c d a r t i s o n a b l a c k d a r t b o a r d', 't h e p e r s o n s t a n d i n g h a s w h i t e s k i n a n d b r o w n h a i r a n d i s a b o y']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l a c k p o l e o n t h e t r a n s p a r e n t i c e', 'i n d i v i d u a l s b o w l a t t h e i r l a n e s a n d k n o c k d o w n p i n s', 't h e d o g i s s t a n d i n g a n d i t i s b r o w n', 'a m a n i s r i d i n g o n a s u r f b o a r d i n t h e o c e a n t h e p e r s o n d o e s a b i g f l i p l a n d i n g b a c k i n t h e w a v e t h e f l i p i s r e p e a t e d i n s l o w m o t i o n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n w i t h w h i t e s k i n a n d b r o w n h a i r i s w i p i n g o f f t h e g o l d l i p s t i c k', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a s p o r t s m a n i s w a l k i n g o n t h e g r e e n f i e l d', 'a p e r s o n w i t h b l a c k s k i n a n d b l a c k h a i r i s t o u c h i n g t h e b l a c k c a r', 'a p h o n e m a d e o f w h i t e m e t a l i s c u r r e n t l y r u n n i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r a n d h e i s w a l k i n g', 'p e r s o n 1 a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s w i p i n g t h e b l a c k l e a t h e r b o o t w h i l e p e r s o n 2 a l s o a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r h o l d s a w h i t e t i s s u e', 'p e r s o n 1 a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s s t a n d i n g n e a r p e r s o n 2 a m a n w i t h b r o w n h a i r', 't h e b o w l w h i c h i s m a d e o f c e r a m i c i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a l s o a s t u d e n t', 'a b l a c k m e t a l r o l l e r i s p l a c e d o n b l a c k h a i r', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r s i t t i n g a s a c u s t o m e r', 't h e m e t a l d r u m s e t c o m e s i n b o t h r e d a n d g r e y c o l o r s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h a s b l a c k h a i r a n d b l a c k s k i n w i t h t h e h a i r b e i n g a n a t u r a l p a r t o f t h e i r a p p e a r a n c e a s a w o m a n', 't h e r e i s a y e l l o w b o a r d h a n g i n g', 't h e p e r s o n s p e a k i n g i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n w h o i s w a l k i n g h a s f a i r s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a y e l l o w g a r m e n t n e a r a w o m a n w h o h a s b l a c k s k i n a n d b r o w n h a i r', 't h e p e r s o n s p a r e s w i t h a m a n i n b l a c k t h e w o m a n k i c k s a n d h i t s a t t h e m a n t h e p e r s o n d o e s s e v e r a l d i f f e r e n t e x e r c i s e s', 'a m a n s h u r g s a t t h e c a m e r a a s a g a m e c o m m e n c e s', 't h e v e s t i s r e d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a r e d p l a s t i c s h u f f l e b o a r d i s p l a c e d o n a b r o w n w o o d e n f l o o r', 'p e o p l e j o k e t o t h e c a m e r a', 't h e p e r s o n s t a n d i n g t h e r e i s a w o m a n w i t h b l a c k h a i r a n d y e l l o w s k i n', 't h e r e i s a m a n i n t h e b l u e s t a d i u m w h o i s a b a l l p l a y e r a n d h a s w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s i n c l o s e p r o x i m i t y t o p e r s o n 2 p e r s o n 2 a w o m a n w i t h b l a c k s k i n a n d b l a c k h a i r', 'm o t o r c y c l e r i d e r s r a c e a r o u n d a d i r t t r a c k d u r i n g a c o m p e t i t i o n t h e o t h e r r i d e r s l o w s d o w n a n d p u l l s o f f t h e t r a c k t h e r i d e r i s s e e n c r a s h i n g i n s l o w m o t i o n', 't h e r a b b i t i s b l a c k a n d e a t i n g', 'i n s i d e o f a f e n c e m e n a r e s i t t i n g u p o n h o r s e s w a i t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d m a r t i a l a r t s e x p e r t i s e i s e n g a g e d i n a f i g h t w i t h p e r s o n 2 a n o t h e r w h i t e s k i n n e d m a r t i a l a r t i s t', 'a m a n s h o w i n g i m b a l d w o r d s i s a b o v e h i s h e a d t h e b o y s s e p a r a t e a s q u e s t i o n m a r k s a p p e a r o v e r t h e i r h e a d s a d e s c r i p t i o n o f t h e v i d e o i s s h o w n t h e b o y s c o n t i n u e t o s p a r a c r o s s t h e s t a g e', 'a m a n w i t h b r o w n h a i r i s k n e e l i n g', 't h e r o o m i s c o l o r e d i n b r o w n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k m a n w i t h b l a c k h a i r i s p e r f o r m i n g a s a d r u m m e r', 't h e r e i s a n i n g r e d i e n t i n t h e p l a s t i c t h e i n g r e d i e n t i s y e l l o w a n d t h e p l a s t i c i s t r a n s p a r e n t', 't h e r e i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r w a l k i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i n s i d e a g r e y s h o p']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h o l d i n g t h e e x e r c i s e b a l l i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h i l e t h e e x e r c i s e b a l l i s m a d e o f b l a c k l e a t h e r', 't h e m a n s i t t i n g i s f a i r s k i n n e d', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a p e r f o r m e r i s s t a n d i n g o n t h e r e d w o o d e n s t a g e', 'a l a r g e b l a c k d o g i s w a l k i n g d o w n t h e s t r e e t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g i r l w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s a c o n t e s t a n t i s s t a n d i n g', 't h e r o w i n g m a c h i n e h a s a b l a c k p a n e l m a d e o f b l a c k m e t a l', 't h e r e i s a n o p e n i n g t i t l e s c r e e n a s m i l i n g m a n i n s u n g l a s s e s o p e n s m o u t h w a s h a n d g a r g l e s t h e m a n s p i t s i n a c u p a l a d y r e m o v e s a p l a q u e f r o m t h e w a l l t h e r e i s a c l o s i n g s c r e e n', 'a y o u n g g i r l g y m n a s t t a l k i n g t o t h e c a m e r a t h e r e i s a t i t l e s c r e e n t h e g i r l p e r f o r m f l i p s t h e g i r l f l i p s o n a t r a m p o l i n e t h e p e r s o n j u m p s a n d d o e s a s p l i t i n t h e a i r t h e r e i s a n e n d i n g s c r e e n s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s p e a k i n g i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r', 'a p e r s o n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a d a n c e r t h e h a i r _ s t y l e i s s t r a i g h t a f t e r a w h i l e h i s h a i r _ s t y l e i s c u r l y', 't h e f i e l d a p p e a r s t o b e g r e y', 'p e r s o n 1 a f e m a l e c u s t o m e r w i t h y e l l o w s k i n a n d b l a c k h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 w h o a l s o h a s y e l l o w s k i n a n d b l a c k h a i r a n d i s a l s o a c u s t o m e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s r u n n i n g', 't h e m a n p l a c e s t h e h o s e b a c k a n d s t a r t s t o l e a v e', 't h e p e r s o n s t a n d i n g h a s w h i t e s k i n a n d b r o w n h a i r', 't h e p e r f o r m e r a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w e a r i n g b l a c k g l a s s e s a f t e r s o m e t i m e h e s t a r t s p l a y i n g t h e d r u m w h i c h i s m a d e o f b r o w n w o o d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a s i l v e r m e t a l k n i f e i s s l i d i n g a n d a f t e r a w h i l e a w h i t e o v e n i s o p e n e d', 't h e r e i s a n o l d w h i t e s k i n n e d m a n w i t h w h i t e h a i r i n t h e y e l l o w r o o m w h o i s a d o c t o r', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s w a l k i n g o n a g r e y s t a i r c a s e', 'i n t h e w h i t e b e d r o o m t h e r e i s a p e r s o n w h o i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b l a c k h a i r e d m a n w i t h w h i t e s k i n h a s a b e a r d t h a t i s p a r t o f h i s a p p e a r a n c e', 't h e r e i s a m a n s t a n d i n g o n t h e g r e e n c o u r t w i t h w h i t e s k i n a n d b l a c k h a i r', 'p e r s o n 1 a s p o r t s m a n h a s w h i t e s k i n a n d b l a c k h a i r h e i s w e a r i n g a g r e e n s h i r t p e r s o n 2 a l s o a s p o r t s m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s h o l d i n g a w h i t e r a c k e t', 'p e r s o n 1 w h o i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 w h o i s a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n w i t h w h i t e s k i n a n d b l a c k h a i r i s w a l k i n g', 't h e r e i s a m a n s t a n d i n g w i t h w h i t e s k i n', 't h e p e r s o n w e a r i n g t h e b l a c k s h i r t h a s y e l l o w s k i n a n d b l a c k h a i r', 'a p e r s o n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a y e l l o w s p o n g e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s t h e o n e w h o i s j u m p i n g', 'i n t h e p a n t h e r e i s r e d p a s t a a n d t h e p a n i t s e l f i s m a d e o f b l a c k m e t a l', 'a w h i t e s k i n n e d g i r l i s j u m p i n g o n t h e w h i t e h o p s c o t c h', 't h e b a r b e l l p i e c e i s a r e d m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k s k i n n e d w o m a n w i t h b l a c k h a i r i s s i t t i n g', 'i n t h e r o o m t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r b o t h t h e p e r s o n a n d t h e r o o m a r e w h i t e i n c o l o r', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p e r f o r m i n g a s a p e r f o r m e r', 'p e r s o n 1 w h o i s a c o n t e s t a n t w i t h w h i t e s k i n a n d y e l l o w h a i r i s s t a n d i n g n e a r p e r s o n 2 a n o t h e r c o n t e s t a n t w h o a l s o h a s w h i t e s k i n a n d y e l l o w h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b o y w i t h w h i t e s k i n i s o p e n i n g a m o u s e', 'a m a n w i t h y e l l o w s k i n i s f i s h i n g f o r a b l a c k f i s h', 't w o m e n a r e s t a n d i n g o n a b a s k e t b a l l g o a l', 't h e r e i s w h i t e b a b y p o w d e r i n t h e w h i t e c e r a m i c b o w l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r i n a w h i t e b a t h r o o m', 'a w h i t e s k i n n e d m a n i s h o l d i n g a y e l l o w c o o k i e', 't h e c r o w d c h e e r s a t t h e e n d a n d c l a p s h a n d s', 'a h a r m o n i c a m a d e o f m e t a l t h e c o l o r i s g r e y a f t e r a w h i l e i t s c o l o r i s b l a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a s u r f e r w i t h w h i t e s k i n a n d g o l d e n h a i r i s s q u a t t i n g o n t h e b l u e s u r f b o a r d', 'a w h i t e s k i n n e d m a n i s s e a t e d', 'a t r a n s p a r e n t w a v e i s f l o w i n g', 't h e r e i s a p e r s o n s i t t i n g a n d t h e y h a v e w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s s t a n d i n g', 'a p e r s o n w i t h w h i t e s k i n a n d b l a c k h a i r i s b o w i n g i n f r o n t o f t h e a u d i e n c e', 't h e w h i t e c e r a m i c p l a t e i s n e a r t h e b l a c k m e t a l p a n', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s d a n c i n g w i t h p e r s o n 2 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r b o t h o f t h e m a r e d a n c e r s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e o p l e i s p l a y i n g b l a c k j a c k a r o u n d a t a b l e m a n s t a n d s f r o m a t a b l e a n d w a l k s i n a r o o m', 't h e r e i s a w h i t e d a r t b o a r d i n t h e r o o m a n d t h e r o o m i t s e l f i s a l s o w h i t e', 't h e c a m e r a c a p t u r e s t h e m a n f r o m s e v e r a l a n g l e s', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r s i t t i n g o n a b l a c k s e a t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n i s o n a y e l l o w s t a g e', 'a w o m a n n a m e d s a p n a a p p e a r s i n a p h o t o t h e p e r s o n j u m p s f o r w a r d a n d b a c k a n d s i d e t o s i d e', 't h e p e r s o n i s a m a n w h o h a s w h i t e s k i n a n d b r o w n h a i r a n d h e i s c u r r e n t l y k n e e l i n g', 't h e p l a t e h o l d s a y e l l o w c a k e a n d i t i s m a d e o f b r o w n m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l u e c l o t h i n t h e b u c k e t a n d t h e b u c k e t i s m a d e o f w h i t e p l a s t i c', 't h e p e r s o n s i t t i n g i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r', 't h e p e r s o n i n t h e a u d i e n c e w i t h w h i t e s k i n i s a m a n w i t h b r o w n h a i r w h o i s s i t t i n g', 't h e p e r s o n p e r f o r m i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n i s w i n d s u r f i n g o u t o n a l a k e o t h e r w i n d s u r f e r s p a s s b e h i n d t h e p e r s o n', 'a n i n t r o s t a r t s e n t i t l e d h o w t o c u t t h e g r a s s', 't h e r e i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s s i t t i n g', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r p e r s o n 2 a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c h o c o l a t e i s b e i n g e a t e n b y a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r a n d t h e c h o c o l a t e i t s e l f i s b r o w n', 't h e m a n f i n a l l y s p l i t s t h e l o g b e l o w h i s f e e t', 't h e r e i s a b l u e b o a t o n t h e b l a c k w a t e r', 't h e c o l o r o f t h e l i q u i d i s b l u e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g', 't h e r e i s a m a n s t a n d i n g w h o h a s w h i t e s k i n a n d b r o w n h a i r', 't h e s e a t m a d e o f b l a c k l e a t h e r i s a c o m p o n e n t o f t h e m o t o r b i k e w h i c h i s c o m p o s e d o f b l a c k m e t a l', 't h e r e i s a w h i t e m e t a l o v e n n e a r a b o y w i t h w h i t e s k i n a n d y e l l o w h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n a d u l t p e r s o n w i t h w h i t e s k i n a n d b l a c k h a i r i s p r e s e n t i n a w h i t e g y m', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s i n c l o s e p r o x i m i t y t o p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s p l a y i n g w i t h p e r s o n 2 a b o y w i t h g o l d e n h a i r', 'a t h l e t e s a r e b o a r d i n g w h i t e b u s e s t h e b u s e s m o v e d o w n t h e r o a d a p e r s o n s t a c k s t e e s h i r t s a t h l e t e s w a i t a t t h e s t a r t l i n e a t h l e t e s a r e r u n n i n g d o w n t h e r o a d a t h l e t e s c r o s s t h e f i n i s h l i n e t h e c r e d i t s o f t h e c l i p a r e s h o w n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o i s a m a l e c o n t e s t a n t i s s t a n d i n g n e a r p e r s o n 2 w h o i s a n a u d i e n c e m e m b e r w i t h w h i t e s k i n a n d b l a c k h a i r', 'a b o y i s p l a y i n g w i t h a w h i t e w o o d e n s k a t e b o a r d', 't h e b o y s h o o t s t h e a r r o w s t r e t c h e s a n d s h o o t s m o r e a r r o w s', 't h e r e i s a p e r s o n i n t h e g y m s h e i s a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r t h e g y m i t s e l f i s r e d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n p l a y i n g t h e t a b l e h a s y e l l o w s k i n a n d b l a c k h a i r a n d t h e t a b l e i t s e l f i s m a d e o f g r e e n w o o d', 't h e r e i s a p e r s o n s t a n d i n g w h o i s a w h i t e m a n w i t h w h i t e h a i r', 't h e p e r s o n w e l d i n g w h o i s a w h i t e m a n w i t h b l a c k h a i r h o l d s a b l a c k m e t a l w e l d i n g g u n', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s r u n n i n g o n a y e l l o w s t a g e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s t h r o w i n g a b l a c k r u b b e r b o w l i n g b a l l', 't h e r e i s a y e l l o w w h i s k e y s o u r n e a r t h e y e l l o w w h i s k e y s o u r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s p u s h i n g t h e g r e e n m e t a l d o o r', 't h e c a r i s t h e c o l o r y e l l o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s i t t i n g o n t h e b l a c k m e t a l c a b l e c a r', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s p o s i t i o n e d c l o s e t o p e r s o n 2 w h o i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d p a r t o f t h e a u d i e n c e', 't h e r e i s a r u n n i n g r a z o r m a d e o f b l a c k m e t a l', 'a y o u n g g i r l s h o w s h i s l o n g h a i r u n t i l t h e w a i s t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e a r m i s w h i t e', 't h e r e i s a m a n w i t h w h i t e s k i n s i t t i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s i t t i n g a m o n g t h e a u d i e n c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s i t t i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a l s o a s t u d e n t', 'a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r i s s p e a k i n g', 'a n a d u l t p e r s o n w i t h f a i r s k i n i s h o l d i n g a y e l l o w p l a s t i c b o t t l e', 'a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w h o i s a w r e s t l e r i s r a i s i n g h i s w h i t e h a n d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e t o o t h i s y e l l o w', 't h e r e i s a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r w h o i s s q u a t t i n g', 't h e r e i s a r a k e o n t h e g r e e n w o o d t r e e a n d t h e r a k e i s b l a c k w h i t e a n d y e l l o w', 't h e r o o m i s b l a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['i s a p l a c e w h e r e r a c e s t a k e p l a c e t h e c o l o r i s y e l l o w a f t e r a w h i l e i t s c o l o r i s g r e y', 't h e r e i s a w h i t e d o g s t a n d i n g', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g o n a b l u e r u b b e r i n f l a t a b l e b o a t w h i c h h e i s b o a t i n g i n', 'a w o m a n p u t s i c e i n a g l a s s t h e p e r s o n d u m p s a b o t t l e i n t o t h e g l a s s a n d a d d s j u i c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n i s h o l d i n g a b r o w n p l a s t i c d o l l', 't h e c o l o r o f t h e g u i t a r i s b r o w n', 'a l i t t l e b o y i s p l a y i n g h o p s c o t c h o n t h e p a v e m e n t t h e r e i s a t r u c k b e h i n d t h e p e r s o n t h e p e r s o n d o e s n t r e a l l y p l a y t h e o b j e c t r i g h t t h e p e r s o n j u m p s o n a l l o f t h e n u m b e r s t h e p e r s o n k i n d o f r u n s t h r o u g h t h e g a m e', 't h e r e i s a p e r s o n s m o k i n g a b l a c k r u b b e r h o s e w h o h a p p e n s t o b e a w h i t e s k i n n e d m a n w i t h b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a h a n d w h i c h i s w h i t e i s p a r t o f a p e r s o n w h o i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e w a t e r i s b e i n g t o u c h e d b y a r e d p l a s t i c p a d d l e a n d t h e w a t e r i t s e l f i s t r a n s p a r e n t', 't h e p e r s o n s t a n d i n g i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d a s p o r t s m a n i s s t a n d i n g c l o s e t o p e r s o n 2 w h o i s a l s o a w h i t e s k i n n e d m a n w i t h b l a c k h a i r', 'a w o m a n w e a r i n g a b r a i s s t a n d i n g i n a r o o m t h e p e r s o n t h r o w s a d a r t a c r o s s t h e r o o m a m a n w i t h a h a t s t a n d s n e x t t o t h e p e r s o n', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s s i t t i n g', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s w a l k i n g o n a w h i t e c l o t h r o p e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d a n a t h l e t e i s s t a n d i n g u p s i d e d o w n w h i l e p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s i t t i n g', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o h a p p e n s t o b e a b a r t e n d e r i s s t a n d i n g', 'a k i d i n a b l u e s h i r t i s l o n g b o a r d i n g t h e p e r s o n f a l l s o f f a n d o n t o t h e s t r e e t t h e p e r s o n k e e p s g o i n g d o w n t h e s t r e e t o n h i s l o n g b o a r d', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a b a l l p l a y e r i s t o u c h i n g p e r s o n 2 a n o t h e r w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a l s o a b a l l p l a y e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e a r m i s b l a c k', 't h e g i r l w i t h y e l l o w h a i r w h o i s s t a n d i n g i s a p e r s o n w i t h w h i t e s k i n', 't h e r o a d i s c o v e r e d i n w h i t e s n o w', 't h e s h o u l d e r o f t h e p e r s o n w h o i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r a n d i s a l s o a v i o l i n i s t i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c a r i s d r i v e n i n s i d e o f a s h o p t h e p e r s o n s p r a y p a i n t s p a r t s o f t h e c a r', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w a l k i n g', 't h e m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a w o r k e r i s s e e n b o w i n g', 't h e v o l l e y b a l l t h a t i s f l y i n g i s w h i t e a n d m a d e o f r u b b e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s s t a n d i n g o n a b r o w n w o o d e n b o a r d', 't h e t a b l e i s w h i t e', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s l o c a t e d i n c l o s e p r o x i m i t y t o p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a b l a c k s k i n n e d g i r l s t a n d i n g w i t h b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s c l i m b i n g t h e b l a c k w o o d e n s t a i r s', 't h e p e r s o n s w i m m i n g h a s a d u l t y e l l o w s k i n a n d b l a c k h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w h o i s r u n n i n g', 't h e p e r s o n s t a n d i n g i s a w o m a n w i t h y e l l o w h a i r w h o h a s w h i t e s k i n a n d i s a s p o r t s m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e g y m i s c o l o r e d i n w h i t e', 't h e i n s t r u c t o r a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s k n e e l i n g', 'a m a n i s s t a n d i n g o u t s i d e w i t h a p a i n t p a n t h e p e r s o n t a l k s a s h e d e m o n s t r a t e s h o w t o p a i n t o u t d o o r w o o d t h e p e r s o n s h o w s o f f a p a i n t r o l l e r t h e p e r s o n c o n t i n u e s t a l k i n g a b o u t t h e p r o c e s s a s h e s t a n d s t h e r e', 's e v e r a l i m a g e s o f d o g s a r e s h o w n o u t s i d e i n t h e f i e l d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c r e d i t s o f t h e c l i p s a r e s h o w n g u y s p l a y p o l o s p o r t o n a d i r t a r e n a t h e c r e d i t s o f t h e v i d e o a r e s h o w n', 't h e p e r s o n t o u c h i n g t h e s i n k i s a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r w h i l e t h e s i n k i t s e l f i s m a d e o f w h i t e c e r a m i c', 't h e p e r s o n s t a n d i n g i n t h e a u d i e n c e i s a n a d u l t w i t h w h i t e s k i n', 'a b l a c k e l e p h a n t i s p l a y i n g w i t h a r e d r u b b e r b a l l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s s m i l i n g i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e b l a c k j a c k a t t e n d a n t p l a c e s c a r d s o n t h e t a b l e', 't h e p e r s o n b o w i n g h a s w h i t e s k i n a n d b l a c k h a i r a n d i s a b o y', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e f e n c e i n t h e y a r d i s m a d e o f b r o w n w o o d j u s t l i k e t h e y a r d i t s e l f', 'a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r t h e u p p e r _ c l o t h e s _ c o l o r i s w h i t e a f t e r a w h i l e h e r u p p e r _ c l o t h e s _ c o l o r i s b l u e', 'a w h i t e h a n d i s t o u c h i n g a g r e e n g r o u n d', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a n w i t h w h i t e s k i n w h o i s w a l k i n g h a s b l a c k h a i r', 't h e p e r f o r m e r i s a m a n w i t h b l a c k h a i r w h o h a s w h i t e s k i n a n d h e i s c u r r e n t l y p e r f o r m i n g', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s k n e e l i n g o n a r e d r u b b e r e x e r c i s e b a l l', 't h e r e i s a m a n o f y e l l o w s k i n a n d b r o w n h a i r w h o i s a w o r k e r h o l d i n g a b r o w n m e t a l g u n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 w h o i s t h e r e f e r e e a n d a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'i n t h e h o u s e t h e r e i s a s i l v e r m e t a l t r o p h y a n d t h e h o u s e i t s e l f i s g r e y', 't h e p e r s o n w h o i s b o w i n g h a s w h i t e s k i n a n d y e l l o w h a i r a n d s h e i s a w o m a n', 't h e t i r e o n t h e b i k e i s m a d e o f b l a c k r u b b e r w h i l e t h e b i k e i t s e l f i s c o m p o s e d o f s i l v e r m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h o l d i n g t h e s i l v e r m e t a l s a x o p h o n e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a p e r f o r m e r w i t h w h i t e s k i n a n d b r o w n h a i r t h e h a i r _ s t y l e i s s t r a i g h t a f t e r a w h i l e h i s h a i r _ s t y l e i s c u r l y', 't h e c o l o r o f w a t e r i s b l u e', 'a y e l l o w s k i n n e d s u m o w r e s t l e r r a i s e s h i s y e l l o w a r m b e f o r e e v e n t u a l l y s q u a t t i n g o n a b l u e m a t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a n i n g r e d i e n t i n t h e r e s t a u r a n t a n d t h a t i n g r e d i e n t i s g r e e n t h e r e s t a u r a n t i t s e l f i s w h i t e', 't h e p e r s o n w e a r i n g t h e b l a c k s h o r t s i s a s p o r t s m a n w h o i s a w h i t e m a n w i t h b r o w n h a i r', 't h e r e a r e o t h e r s e t s o f d r u m s t o t h e p e r s o n s l e f t', 'g r e e n w a t e r i s f l o w i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d b o y w i t h b l a c k h a i r i s s i t t i n g', 'a m a n i s s t a n d i n g o n a s k a t e b o a r d t h e p e r s o n p u t s t h e s k a t e b o a r d b a c k d o w n a n d c o n t i n u e s s k a t e b o a r d i n g', 't h e k n i f e i s m a d e o f s i l v e r', 'a b o y w i t h w h i t e s k i n i s w a r m i n g u p']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['i n t h e r o o m t h e r e i s a w h i t e p l a s t i c b u c k e t w h i l e t h e r o o m i t s e l f i s g r e y', 'a n a d u l t p e r s o n w i t h y e l l o w h a i r a n d w h i t e s k i n i s s i t t i n g o n a b l u e r u b b e r r a f t', 't h e r e i s a n o p e n i n g t i t l e s c r e e n t h e r e i s a l a d y w a s h i n g c l o t h e s b y h a n d o u t d o o r s t h e l a d y p o u r s w a t e r o n t h e c l o t h e s f r o m a b o w l t h e l a d y p u s h e s h e r h a i r b a c k t h e l a d y p o u r s m o r e w a t e r o n t h e c l o t h e s t h e r e i s t h e c l o s i n g t i t l e s c r e e n', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s d r i v i n g a r e d c a r m a d e o f m e t a l', 't h e r e i s a w h i t e m e t a l r o w i n g m a c h i n e i n o p e r a t i o n', 't h e r e i s a p e r s o n s t a n d i n g a n d h e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e m u l c h i s b e i n g t o u c h e d b y a p e r s o n w h o i s a w h i t e m a n w i t h b l a c k h a i r w h i l e t h e m u l c h i t s e l f i s b r o w n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r s i t t i n g', 't h e f i e l d c o n s i s t s o f a b r o w n c i r c l e w i t h i n a g r e e n f i e l d', 't h e p e r s o n c o o k i n g i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r w h o w o r k s a s a b a r t e n d e r', 't h e j u i c e h a s a g r e e n c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a y e l l o w w o o d e n s k i i s o n t h e w h i t e s n o w', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s c o o k i n g i n t h e r e d k i t c h e n', 't h e p e r s o n s t a n d i n g t h e r e i s a m a n w i t h b r o w n h a i r a n d w h i t e s k i n', 't h e p e r s o n w h o i s f l y i n g i s a n a d u l t w i t h f a i r s k i n a n d b l a c k h a i r a n d t h e y a r e a l s o a c l i m b e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g a m o n g s t t h e a u d i e n c e', 'a m a n i s r i d i n g a b l a c k m e t a l m o t o r b i k e w h i c h h e u s e s f o r c r o s s c o u n t r y d r i v i n g', 't h e r e i s a w h i t e a r m o n t h e b e d a l o n g s i d e a b e d m a d e o f w h i t e m e t a l', 'p e r s o n 1 a w o m a n w i t h b l a c k s k i n a n d b r o w n h a i r i s n e a r p e r s o n 2 w h o i s a p e r s o n w i t h b l a c k s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s e a t e d o n a b r o w n w o o d e n c h a i r w h o h a p p e n s t o b e a c u s t o m e r', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r s q u a t t i n g o n t h e g r e y g r o u n d', 't h e r e i s a b r o w n c o o k i e o n a w h i t e c e r a m i c p l a t e', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s w e e p i n g t h e b r o w n c e r a m i c f l o o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h i s w o m a n i s s h o w n p l a y i n g t h e b l a c k h a r m o n i c a', 'a w h i t e m o u t h i s t o u c h i n g a b l u e p l a s t i c f r i s b e e', 't h e p e r s o n w e a r i n g t h e d i v i n g g e a r i s a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r a n d t h e d i v i n g g e a r i t s e l f i s m a d e o f b l a c k r u b b e r', 'a w h i t e s k i n n e d m a n w h o i s a c o n t e s t a n t i s r u n n i n g o n t h e g r e e n f i e l d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b o y w i t h w h i t e s k i n a n d g o l d e n h a i r o n t h e g r e e n p l a y g r o u n d', 't h e r e i s a p e r s o n s t a n d i n g w h o i s a c h i l d w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n s q u a t t i n g i s a w o m a n w i t h f a i r s k i n a n d y e l l o w h a i r', 'a n o l d l a d y s t o p s k n i t t i n g a n d t a l k s c o n t i n u o u s l y t h e o l d l a d y k n i t s a g a i n a n d e x a m i n e s h e r c r e a t i o n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g o n a w h i t e r u b b e r b o a t a f t e r s o m e t i m e p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a r t s h o l d i n g a w h i t e p l a s t i c p a d d l e', 't h e m a n t h r o w s t h e d i s c u s r e a l l y h a r d t h e m a n t h r o w s d i s c u s a n d w a t c h e s a h e a d', 't h e p e r s o n i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r a n d h e i s w a l k i n g', 'a m a n w i t h w h i t e s k i n i s p e r f o r m i n g a s a d a n c e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s t h e p e r s o n w h o i s b o w i n g', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a b l a c k m e t a l r a z o r h e a d', 't h e s p e a k e r i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r', 'a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r w h o i s a s p o r t s w o m a n i s h o l d i n g a w h i t e p o l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a c o n t e s t a n t a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s s t a n d i n g', 'a w h i t e s k i n n e d b a l l p l a y e r w h o i s a m a n i s i n t h e g r e e n c o u r t', 't h e r e i s a m a n s p e a k i n g w h o h a s w h i t e s k i n a n d b r o w n h a i r a n d h e i s t h e p r e s e n t e r', 't h e t i r e m a d e o f p i n k r u b b e r i s b e i n g t o u c h e d b y a b l a c k m e t a l l o c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e d a n c e r i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s c u r r e n t l y d a n c i n g', 'p e r s o n 1 w h o i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r i s e n g a g e d i n a c o n v e r s a t i o n w i t h p e r s o n 2 w h o i s a l s o a b o y w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e b a n n e r i s w h i t e', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s c l o s e t o p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i n t h e a u d i e n c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d w h i t e h a i r e d w o r k e r i s s t a n d i n g', 't h e r e i s a p e r s o n s t a n d i n g w h o i s a w h i t e s k i n n e d b o y w i t h b r o w n h a i r', 'a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r i s p e r f o r m i n g a s a d a n c e r', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a s p o r t s m a n i s h o l d i n g a w h i t e p o l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h a n d b e l o n g s t o t h e p e r s o n w h o i s a w h i t e b o y w i t h y e l l o w h a i r a n d w h i t e s k i n', 't h e c o m b o n t h e b l a c k b r a i d i s m a d e o f y e l l o w w o o d', 't h e p e r s o n e x e r c i s i n g i s a b o y w i t h b l a c k h a i r a n d h e h a s y e l l o w s k i n', 'p e r s o n 1 w h o h a s w h i t e s k i n a n d b r o w n h a i r i s p l a y i n g w i t h p e r s o n 2 w h o a l s o h a s w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n w i t h w h i t e s k i n a n d b l a c k h a i r t h e a g e & s e x i s c h i l d a f t e r a w h i l e a g e & s e x i s b o y', 't h e w h i t e b a k i n g s o d a i s l o c a t e d n e a r t h e b r o w n v a n i l l a e x t r a c t', 'p e r s o n 1 a w o m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 a m a n w i t h b l a c k s k i n w h o c o o k s', 't h e b l a c k s k i n n e d m a n w i t h b l a c k h a i r w h o i s r u n n i n g i s a b a l l p l a y e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e i n d i v i d u a l s k i i n g i s a w h i t e s k i n n e d m a n', 't h e r e i s a s i l v e r p o l e r e s t i n g o n a g r e e n c l o t h p a d', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 a b o y w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a p e r f o r m e r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a r e f e r e e i n t h e r e d s t a d i u m']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l a c k c o l l i e s t a n d i n g', 't h e p e r s o n s p e a k i n g h a s w h i t e s k i n a n d b r o w n h a i r a n d i s a m a n', 't h e m a n w i t h y e l l o w s k i n s t a n d i n g h a s b l a c k h a i r', 'p e o p l e t a k e t u r n s p l a y i n g d i f f e r e n t p o s i t i o n s a n d d o i n g a l a y u p']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a n w i t h b l a c k h a i r i n t h e a u d i e n c e i s r o a r i n g', 't h e r e i s a p e r s o n s t a n d i n g w h o i s a w h i t e s k i n n e d b o y w i t h b r o w n h a i r w o r k i n g', 't h e p e r s o n s p e a k i n g i s a w h i t e w o m a n w i t h b r o w n h a i r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s p l a y i n g a b l a c k p l a s t i c k e y b o a r d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n i n w h i t e r u n s t o w a r d s f i r s t b a s e p l a y i n g k i c k b a l l t h e m a n i s t a g g e d o u t b y a w o m a n w e a r i n g r e d', 't h e m a n h e a r s h i s s c o r e a n d s m i l e s p l e a s i n g l y', 't h e r e i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s s m i l i n g', 't h e r e i s a p e r s o n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s e x e r c i s i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n i s o f w h i t e c o m p l e x i o n a w o m a n w i t h w h i t e h a i r a n d s h e i s c u r r e n t l y s i t t i n g', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n s t a n d i n g i s a m a n w i t h w h i t e s k i n', 't h e p e r s o n h o l d i n g t h e o b j e c t i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h i l e t h e o b j e c t i t s e l f i s m a d e o f w h i t e n y l o n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n i n t h e w h i t e r o o m w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n w h o i s a w o m a n i s s t a n d i n g a s a d a n c e r', 'a m a n w i t h b l a c k s k i n i s w a l k i n g o n t h e b r o w n s i d e w a l k', 'a n i n s t r u c t o r w i t h f a i r s k i n a n d b l a c k h a i r t h e a g e & s e x i s w o m a n a f t e r a w h i l e h e r a g e & s e x i s m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
[32m2023-10-19T20:01:37 | utils.basic_utils: [0mTrain Epoch: [0]  [ 200/2288]  eta: 0:32:03  lr: 0.000010  temperature: 0.0115  video-loss_ita: 1.7286  video-loss_itm: 0.6332  time: 0.7663  data: 0.0107  max mem: 7604 res mem: 7876
text in iter ['a w h i t e d o g i s s t a n d i n g o n a g r e e n f i e l d', 't h e b l a c k e y e l a s h i s b e i n g t o u c h e d b y a y e l l o w p l a s t i c m a s c a r a', 't h e w o m a n w a l k i n g h a s w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s e x e r c i s i n g a s a s k a t e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e d o o r o f t h e s h e d i s m a d e o f b r o w n w o o d j u s t l i k e t h e r e s t o f t h e s h e d', 't h e r e i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i n t h e c o u r t w h i c h i s m a d e o f b r o w n w o o d s u r r o u n d e d b y a n a u d i e n c e', 'a w o m a n s t a n d s i n a k i t c h e n s t a r i n g a t t h e c a m e r a t h e w o m a n s c o o p s t h e c o o k i e s o f f t h e t r a y l o o s e n i n g t h e m', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a b a l l p l a y e r o n t h e y e l l o w f i e l d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o h a s w h i t e h a i r i s s p e a k i n g w i t h p e r s o n 2 a m a n w i t h b l a c k h a i r', 't h e p e r s o n h a s a w h i t e f o o t a n d h e i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e g y m s c o l o r i s b l u e', 'a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s s t a n d i n g o n t h e g r e e n l a w n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n s t a n d i n g w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n w h o i s d r y i n g h a s w h i t e s k i n a n d b r o w n h a i r a n d t h e y a r e a w o m a n', 'h o c k e y p l a y e r s a r e p l a y i n g a h o c k e y g a m e o n t h e i c e a c r o w d i s w a t c h i n g p e o p l e p l a y a m a n i n y e l l o w f a l l s o n t h e i c e a m a n i n a s u i t i s t a l k i n g t o h o c k e y p l a y e r s', 't h e p e r s o n n e a r m e h a s t r a n s p a r e n t f r o s t i n g a n d s h e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n i s t o u c h i n g a s i l v e r m e t a l t a b l e', 't h e c o l o r o f t h e s e a i s g r e e n', 't h e p e r s o n k n i t t i n g i s a w h i t e s k i n n e d g i r l w i t h y e l l o w h a i r', 'p e r s o n 1 a g i r l w i t h f a i r w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g o n t h e g r e e n f i e l d a f t e r s o m e t i m e p e r s o n 2 a w o m a n w i t h f a i r w h i t e s k i n a n d b l a c k h a i r w h o i s a l s o a s p o r t s m a n s t a r t s f i g h t i n g w i t h p e r s o n 1 w h o i s a g i r l w i t h f a i r w h i t e s k i n a n d i s a l s o a s p o r t s m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a e n v e l o p e w i t h a k e y o n i t i s s h o w n a w o m a n w r a p s a b o o k i n b r o w n p a p e r a w o m a n i n a g r a y s w e a t e r i s t a l k i n g a w o m a n w a v e s a t t h e c a m e r a t h e w o r d s t h a n k y o u i s s t a m p e d i n s i d e a b o o k', 't h e r e i s a w h i t e a t t a c h m e n t o n t h e o r a n g e s c a r f', 't h e w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s p o r t s m a n i s w a l k i n g', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a n i n s t r u c t o r i s s i t t i n g o n t h e w h i t e e x e r c i s e m a c h i n e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w h o i s s i t t i n g a n d s h e i s a s u r f e r', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d a d a n c e r i s t o u c h i n g p e r s o n 2 a n o l d w h i t e s k i n n e d m a n w i t h w h i t e h a i r w h o i s a p r i e s t', 't h e f a u c e t w h i c h i s m a d e o f s i l v e r m e t a l i s o p e n e d', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s w a l k i n g a n d h e i s a w o r k e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n i s w a l k i n g i n a w h i t e a r e a', 't h e p e r s o n h o l d i n g t h e g r i n d s t o n e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r t h e g r i n d s t o n e i t s e l f i s m a d e o f b l a c k m e t a l', 's i t t i n g b e f o r e u s i s a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e s h o t b e i n g h e l d i s a g r a y m e t a l o n e a n d t h e p e r s o n h o l d i n g i t i s a s p o r t s m a n w h o i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w h o i s a c o n t e s t a n t i s s t a n d i n g o n t h e w h i t e p l a t f o r m', 't h e w a l l h a s a t r a n s p a r e n t a p p e a r a n c e', 't h e r e i s a r e d b l a c k a n d s i l v e r d r u m n e a r a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s s t a n d i n g i n f r o n t o f a n a u d i e n c e', 't h e p e r s o n w h o i s l y i n g h a s w h i t e s k i n a n d y e l l o w h a i r a n d s h e i s a w o m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r i s w a s h i n g a t r a n s p a r e n t p l a s t i c b o w l', 'a w h i t e s k i n n e d w o m a n w i t h g o l d h a i r i s l e a d i n g a b r o w n c a m e l', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r p r e s e n t i n t h e w h i t e c o u r t', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r n e a r a s i l v e r m e t a l b o w l w h o i s c o o k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n s t a n d i n g', 't h e r e i s a m a n s t a n d i n g w h o h a s w h i t e s k i n a n d b r o w n h a i r', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a n a c t o r i s s i t t i n g o n a b l a c k c h a i r', 't h e p e r s o n d r i v i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n c u r r e n t l y s q u a t t i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n s t a n d i n g i s a w o m a n w i t h f a i r s k i n a n d b l a c k h a i r w h o h a p p e n s t o b e a d a n c e r', 't h e r e i s a p e r s o n n e a r a l e m o n w h o i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r w h i l e t h e l e m o n i t s e l f i s y e l l o w', 't h e r e i s a b o y w i t h w h i t e s k i n w h o i s w a l k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m u s i c i a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a g r e y h a r m o n i c a a n d p l a y i n g i t l a t e r s w i t c h i n g t o a b l a c k h a r m o n i c a', 't h e c o u r t i s r e d i n c o l o r w h i l e t h e b a s k e t i s m a d e o f m e t a l a n d i s o r a n g e i n c o l o r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w h o i s s p e a k i n g a n d h e i s a s p o r t s m a n', 't h e c o l o r o f s a n d i s b r o w n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e e y e i s a p a r t o f t h e p e r s o n a n d i t i s b l a c k t h e p e r s o n i s a w h i t e w o m a n w i t h b r o w n h a i r', 'a s p o r t s m a n w h o i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s s t a n d i n g o n t h e g r e e n f i e l d', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w a l k i n g', 't h e p e r s o n w h o i s e x e r c i s i n g h a s w h i t e s k i n a n d b l a c k h a i r a n d h e i s a b o y']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e s p e a k e r i s a w h i t e s k i n n e d g i r l w i t h y e l l o w h a i r', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r t h e u p p e r _ c l o t h e s _ c o l o r i s w h i t e a f t e r a w h i l e h e r u p p e r _ c l o t h e s _ c o l o r i s b l a c k', 't h e r e i s w h i t e w a x a n d p u r p l e w a x n e a r t h e w a x', 'p e r s o n 1 a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i s p l a y i n g w i t h p e r s o n 2 a l s o a b o y w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k s k i n n e d b o y w i t h b r o w n h a i r w h o i s a s w i m m e r i s k n e e l i n g o n t h e w h i t e p o o l', 't h e r e i s a r e d p i g m e n t a n d a g r e e n p i g m e n t t h a t a r e s i t u a t e d c l o s e t o e a c h o t h e r', 'a w h i t e s k i n n e d w o m a n i s c o o k i n g', 't h e p e r f o r m e r a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s r a i s i n g h e r a r m']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a n w i t h b l a c k s k i n a n d b l a c k h a i r w h o i s a d r i v e r i s s t e e r i n g t h e y e l l o w w o o d e n k a y a k a f t e r s o m e t i m e a n o t h e r m a n w i t h b l a c k s k i n a n d b l a c k h a i r r a i s e s h i s b l a c k a r m', 't e e n c o m p e t e s k a t e b o a r d d o w n t h e r o a d v e r y f a s t a n o t h e r t e e n f a l l s o n t h e r o a d', 't h e h o o p t h a t i s r o t a t i n g i s m a d e o f y e l l o w p l a s t i c', 't h e c o l o r o f c o r a l i s y e l l o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e a l b u m f e a t u r e s a w h i t e s k i n n e d w o m a n w i t h g o l d e n h a i r w h o i s a s i n g e r', 'i n t h e b l a c k w o o d e n b o w l t h e r e i s a y e l l o w d o g', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s h o l d i n g t h e b l a c k r a c k e t', 'a w h i t e s k i n n e d m a n w i t h o r a n g e h a i r i s p e r f o r m i n g a s a p e r f o r m e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n a d u l t p e r s o n w i t h w h i t e s k i n a n d b l a c k h a i r i s w a l k i n g d o w n a b l a c k s t r e e t', 't h e r e i s a m a n s t a n d i n g w h o h a s w h i t e s k i n a n d y e l l o w h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n s t a n d i n g', 't h e g i r l h a s w h i t e s k i n a n d b l a c k h a i r a n d s h e i s h o l d i n g a w h i t e p l a s t i c d e c o r a t i o n a f t e r a w h i l e s h e t o u c h e s t h e w h i t e p l a s t i c d e c o r a t i o n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w e b a d d r e s s i s d i s p l a y e d o n t h e s l i d e t h e n a m e o f a s u n s c r e e n i s s h o w n t h e s u n s c r e e n b o t t l e i s s h o w n t h e p r i c e o f t h e s u n s c r e e n i s s h o w n t h e s u n s c r e e n b o t t l e i s p r e s e n t e d a n i n f o r m a t i o n g u i d e l i n e i s s h o w n', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a p e r f o r m e r i s s t a n d i n g o n a b l a c k s t a g e', 't h e p e r s o n w h o i s w e a r i n g t h e s h i r t h a s w h i t e s k i n a n d b r o w n h a i r t h e s h i r t t h e y a r e w e a r i n g i s m a d e o f b l u e c l o t h', 'a w h i t e r u b b e r f o o t b a l l i s r o l l i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r l y i n g o n a f l o o r m a d e o f y e l l o w w o o d', 't h e p e r s o n w e a r i n g t h e c o a t i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r t h e c o a t i t s e l f i s w h i t e', 't h e r e i s a b r o w n e g g i n t h e t r a n s p a r e n t w a t e r', 'a c h i l d a l m o s t f a l l s o n t h e l e f t t h e r e i s t h e c r o w d e d e s c a l a t o r f r o m a d i s t a n c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r o n a b l a c k r i v e r', 'a b l a c k b u l l s t a n d s o n t h e b r o w n g r o u n d', 't h e r e i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i n a w h i t e r o o m', 't h e c o n t a i n e r i s m a d e o f p l a s t i c a n d h a s a b l u e c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e m e t a l b o a t o n t h e g r e e n o c e a n', 't h e r e i s a g i r l w i t h y e l l o w s k i n a n d b l a c k h a i r s i t t i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s c l i m b i n g', 'a n o l d m a n w i t h w h i t e s k i n a n d g r e y h a i r i s p l a y i n g t h e b l a c k p i a n o']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s s w e e p i n g a g r e e n l e a f', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r p e r s o n 2 w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e m a n w i t h w h i t e s k i n w h o i s s p e a k i n g h a s b l a c k h a i r', 'a w o m a n w i t h w h i t e s k i n a n d g o l d h a i r w h o i s a p e r f o r m e r i s h o l d i n g a b l a c k c o t t o n h a t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i n t h e y e l l o w r o o m', 't h e r e i s a y o u n g m a n s p e a k i n g i n a n e w s s t u d i o t h e r e i s t h e m a n w o r k i n g o u t a g a i n t h e r e a r e t h r e e n e w s c a s t e r s i n t h e s t u d i o', 't h e p e r s o n s p e a k i n g h a s w h i t e s k i n a n d b r o w n h a i r a n d s h e i s a w o m a n', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h g o l d e n h a i r w h o i s a s u r f e r i s s t a n d i n g', 'a m a n w r i t i n g o n t h e w a l l t h e m a n w r i t e s o n t h e w a l l a g a i n t h e p e r s o n b e g i n s t o a p p l y p r o d u c t t h e p e r s o n w r i t e s o n t h e w a l l t h e p e r s o n b e g i n s t o l a y o u t t o o l s t h e p e r s o n m e a s u r e s a n d l e v e l s t h e w a l l t h e p e r s o n w r i t e s o n t h e w a l l a g a i n a d o g j u m p s i n f r o n t o f a w a l l t h e p e r s o n w r i t e s a g a i n o n t h e w a l l l e t t e r i n g a p p e a r s o n t h e s c r e e n f o r t h e p r o d u c t', 't h e w o m a n w i t h w h i t e s k i n h a s b r o w n h a i r a n d s h e i s s t a n d i n g', 't h e s e a a p p e a r s g r e e n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s c u r r e n t l y e x e r c i s i n g', 'i n t h e f o r e s t t h e r e i s a s i l v e r m e t a l a x e a n d t h e f o r e s t i t s e l f i s m a d e o f b r o w n w o o d', 'c h e e s e h a s a y e l l o w c o l o r', 'm a n y t r e e s a n d d e e p w a t e r f r o m a r i v e r i s s h o w n a m a n i s s t a n d i n g o n t h e b a c k o f a s p e e d b o a t t h e p e r s o n p e r f o r m s s e v e r a l t r i c k s a s t h e p e r s o n s k i s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n c u t t h e p o t a t o i n s q u a r e s', 't h e m a c h i n e i s i d l e a n d g r a y', 't h e r e i s a d o g n e a r a m a n w h o h a s w h i t e s k i n a n d b r o w n h a i r a n d t h e d o g h a p p e n s t o b e o r a n g e i n c o l o r', 't h e h a n d i s b l a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a p e r s o n i n t h e b e d r o o m w h o i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r t h e b e d r o o m i t s e l f i s w h i t e', 'a k i t e i s f l y i n g a b o v e a b e a c h s e v e r a l p e o p l e s i t o n t h e b e a c h t h e k i t e s o a r s t h r o u g h t h e s k y s e v e r a l p e o p l e a r e i n t h e w a t e r', 't h e p e r s o n l y i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o h a p p e n s t o b e a s w i m m e r', 't h e s p e a k e r i s a w h i t e s k i n n e d i n d i v i d u a l w i t h y e l l o w h a i r w h o i s m a l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w e a r i n g t h e b l u e p l a s t i c h e l m e t i s a m a l e c o n t e s t a n t w i t h w h i t e s k i n a n d y e l l o w h a i r', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d g o l d e n h a i r s i t t i n g', 't h e p e r s o n w i t h y e l l o w h a i r i s n e a r a n o c e a n w h i c h h a p p e n s t o b e t r a n s p a r e n t a n d t h e p e r s o n i s o l d', 't h e p e r s o n s p e a k i n g i s a w h i t e w o m a n w i t h b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['i n t h e k i t c h e n t h e r e i s a s i l v e r m e t a l s i n k a n d t h e k i t c h e n i t s e l f i s w h i t e', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r s t a n d i n g n e a r t h e w h i t e m e t a l o v e n', 't h e r e i s a b r o w n h o r s e s t a n d i n g', 'a b l a c k h o r s e i s w a l k i n g o n t h e y e l l o w s t o n e b e a c h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n e x e r c i s i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o h a p p e n s t o b e a s u r f e r', 'a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s s t a n d i n g', 't h e p e r s o n b o w i n g h a s w h i t e s k i n a n d b l a c k h a i r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s w a s h i n g a b r o w n d o g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n e x e r c i s i n g i s a c o n t e s t a n t w i t h b l a c k h a i r a n d w h i t e s k i n', 'a g r e e n p l a s t i c t r e e i s l i g h t i n g u p w h i l e a b r o w n d o g s t a n d s n e a r b y', 't h e b a g p i p e i s b l a c k', 't h e p e r s o n e x e r c i s i n g h a s b l a c k s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n f i n i s h e s p l a y i n g t h e s o n g a n d s m i l e s t o t h e c a m e r a', 'a w o m a n w i t h y e l l o w s k i n a n d b r o w n h a i r i s s i t t i n g n e a r a t a b l e m a d e o f g r e e n w o o d', 't h e h a n d w h i c h i s w h i t e b e l o n g s t o t h e p e r s o n a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a l s o a m u s i c i a n', 't h e m a n r i d i n g i s w h i t e s k i n n e d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s t a n d i n g i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w h o h a p p e n s t o b e a s p o r t s m a n', 't h e s p e a k e r i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'm e t a l r e m a i n s m e t a l', 'a w h i t e s k i n n e d b o y w i t h b r o w n h a i r i s p l a y i n g c u r l i n g w i t h a r e d s t o n e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i n t h e y e l l o w s h o p s h e i s a c u s t o m e r', 'a g i r l w i t h w h i t e s k i n i s h o l d i n g a b l a c k m e t a l l e a f b l o w e r', 't h e h e a d i s w h i t e', 't h e c r e d i t s o f t h e c l i p a r e s h o w n a p l a y e r k i c k s a b a l l o v e r a g u y s h e a d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r u b b e r r a f t c o l o r e d b l u e f l o a t s o n t r a n s p a r e n t w a t e r', 'a w h i t e s k i n n e d m a n i s p l a y i n g a g u i t a r m a d e o f b r o w n w o o d', 't h e w o m a n w i t h y e l l o w s k i n w h o h a s b l a c k h a i r i s s m i l i n g', 't h e r e i s a w h i t e c i g a r e t t e b u r n i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n s t a n d i n g w h o h a s b l a c k s k i n', 't h e p e r s o n s t a n d i n g i s a w o m a n w i t h b r o w n h a i r a n d w h i t e s k i n', 't h e p e r s o n s t a n d i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o w o r k s a s a c o o k', 'a l a r g e a u d i e n c e w a t c h e s f r o m n e a r b y t h e m a n t h r o w s t h e s t i c k b e h i n d t h e b a n d t h e m a n p l a y s s t a n d i n g f o r a m o m e n t a n d t h e n b o w s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o e n g a g e s i n b u n g e e j u m p i n g i s s p e a k i n g', 't h e p e r s o n w h o i s a m a n i s s i t t i n g a n d h a s w h i t e s k i n', 't h e p e r s o n j u m p i n g i s a c h i l d w i t h f a i r s k i n', 't h e m a n d o e s p u l l u p s o n o n e o f t h e b a r s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a p e r f o r m e r i s h o l d i n g a s a x o p h o n e m a d e o f g o l d m e t a l', 't h e r o c k i s y e l l o w', 't h e r e i s a y e l l o w f o o t i n t h e w h i t e r o o m', 'a p e r s o n i s s h a r p e n i n g a k n i f e b e h i n d a t a b l e p e o p l e a r e s t a n d i n g i n f r o n t o f t h e t a b l e w a t c h i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l a c k b u l l c h a s i n g a r e d b l a n k e t', 't h e p e r s o n s t a n d i n g i s a w h i t e s k i n n e d m a n', 'a w h i t e s k i n n e d m a l e s p o r t s m a n i s r u n n i n g o n t h e g r e e n f i e l d', 't h e d o g i s b l a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e f i s h i s y e l l o w', 't h e f i r s t p e r s o n a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r i s h o l d i n g a w h i t e c i g a r e t t e a f t e r s o m e t i m e t h e s e c o n d p e r s o n a l s o a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r s t a r t s w e a r i n g w h i t e r o l l e r b l a d e s m a d e o f m e t a l', 'p e r s o n 1 w h o i s a b l a c k m a n a n d a b a l l p l a y e r i s n e a r p e r s o n 2 w h o i s a n a d u l t w i t h w h i t e s k i n', 't h e r e i s a w o m a n w i t h a w h i t e c o m p l e x i o n a n d g o l d e n h a i r w h o i s w a l k i n g a n d i s a s p o r t s e n t h u s i a s t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n w i t h b l a c k s k i n t o u c h e s t h e w h i t e c e r a m i c s i n k a n d a f t e r a w h i l e t h e y w i p e i t w i t h a y e l l o w c o t t o n r a g', 't h e r e i s t h e f r o n t o f t h e h o u s e t h e r e i s t h e p h o n e n u m b e r o f t h e p r e s s u r e w a s h e r s', 't h e m e n h i t t h e b a l l b a c k a n d f o r t h t h e w i n n e r r a i s e s h i s h a n d s a s t h e c r o w d c h e e r s t h e s c e n e i s r e p l a y e d o f t h e p e r s o n s s u c c e s s f u l h i t', 't h e h a i r b e l o n g i n g t o a w h i t e s k i n n e d w o m a n i s b r o w n i n c o l o r a n d i t i s p a r t o f h e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g i n t h e g a t e w h i c h i s m a d e o f b l u e m e t a l', 't h e h a t h a s g l a s s e s o n i t w i t h t r a n s p a r e n t g l a s s f o r t h e g l a s s e s a n d g r e y c o l o r f o r t h e h a t', 'a r u b b e r v o l l e y b a l l t h e c o l o r i s b l u e a f t e r a w h i l e i t s c o l o r i s y e l l o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d w h i t e h a i r i s h o l d i n g a w h i t e m e t a l t o o l', 't h e r e i s a w i n d o w l o c a t e d n e a r a m a n w i t h w h i t e s k i n a n d g o l d h a i r t h e w i n d o w i s t r a n s p a r e n t', 'a w h i t e s k i n n e d m a n i s s t a n d i n g', 't h e r e i s a b r o w n w o o d e n f e n c e n e a r a m a n w i t h w h i t e s k i n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s d r i v i n g t h e w h i t e m e t a l b o a t w h i l e p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n i s s i t t i n g o n t h e s a m e b o a t', 't h e g r e e n r u b b e r b o w l i n g b a l l i s r o l l i n g', 't h e s i l v e r m e t a l p o t h a s a s i l v e r m e t a l l i d', 'a w o m a n i s s t a n d i n g n e x t t o a v a c u u m t h e p e r s o n d u m p s s o m e t h i n g o n t o t h e f l o o r t h e p e r s o n t a k e s t h e v a c u u m a n d v a c u u m s u p t h e m e s s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w h i t e s k i n n e d m a n i s p l a y i n g a y e l l o w w o o d e n d r u m w h i l e p e r s o n 2 a n o t h e r w h i t e s k i n n e d m a n a l s o p l a y s a y e l l o w w o o d e n d r u m', 'a w h i t e s k i n n e d b o y i s s t a n d i n g', 't h e a r e a a p p e a r s b r o w n', 't h e p e r s o n i s p l a y i n g t h e b e a t l e s s o n g y e s t e r d a y o n h i s g u i t a r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d b o y w i t h b l a c k h a i r i s s l i d i n g d o w n a g r e y p l a s t i c s l i d e', 'a w h i t e s k i n n e d m a n i s h o l d i n g a b l a c k r o p e', 't h e p e r s o n s p e a k i n g i s a n o l d m a n w i t h y e l l o w s k i n', 't h e s p e a k e r i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a r e f e r e e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a c h i n e i s b l a c k a n d c u r r e n t l y r u n n i n g', 'p e r s o n 1 a w o m a n w i t h b l a c k s k i n a n d b r o w n h a i r i s i n c l o s e p r o x i m i t y t o p e r s o n 2 a m a l e a r t i s t w i t h y e l l o w s k i n a n d b l a c k h a i r', 'a p r e s e n t e r i s i n f r o n t o f a b u l l d o g i n t h e t v t h e v e t e r i n a r i a n s a r e f i t t i n g t h e d o g w i t h p r o s t h e t i c l e g s t h e d o g i s s h o w n w i t h h i s n e w l e g s t h e d o g i s w a l k i n g a l o n g w i t h a l e a s h e d p i g', 't h e r e i s a b o y w i t h w h i t e s k i n a n d g o l d e n h a i r w h o i s a p e r f o r m e r p l a y i n g a b l a c k d r u m']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g s h u f f l e b o a r d o n a b l a c k p l a s t i c c o u r t', 't h e h a n d i s p a r t o f a w o m a n w h o h a s w h i t e s k i n a n d b r o w n h a i r', 'a w o m a n u s e s a n o r d i c t r a c k e x e r c i s e m a c h i n e t h e e x e r c i s e m a c h i n e i s s h o w n b y i t s e l f t h e w o m a n u s e s t h e m a c h i n e a g a i n t h e m a c h i n e s d i g i t a l d i s p l a y c o n t r o l s a r e s h o w n t h e w o m a n e x e r c i s e s o n t h e m a c h i n e a g a i n', 'a m a n t h r o w s a b a l l o n t o t h e s i d e w a l k t h e p e r s o n p l a y s h o p s c o t c h t o p i c k t h e o b j e c t u p a l i t t l e k i d r u n s a r o u n d i n f r o n t o f t h e p e r s o n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w o m a n p e r f o r m e r w h o h a s w h i t e s k i n a n d y e l l o w h a i r i s p l a y i n g w i t h t h e b l a c k d o g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s s t a n d i n g', 't h e r e i s a m a n i n t h e f o r e g r o u n d w i t h w h i t e s k i n a n d b l a c k h a i r a n d t h e f o r e g r o u n d i s b l u e', 'a m a n i s o u t s i d e w i t h a l a r g e m e t a l b o x p e o p l e t h e n s a n d t h e f l o o r s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d s h e h a s a t r a n s p a r e n t n a i l', 't h e p e r s o n s i t t i n g i s a n a d u l t w i t h y e l l o w s k i n a n d b l a c k h a i r', 't h e t a t t o o w h i c h i s b l a c k b e l o n g s t o a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d i t i s a n i n t e g r a l p a r t o f h e r', 't h e s e n t e n c e c o u l d b e r e w r i t t e n a s t h e p e r s o n h o l d i n g p e r s o n 2 i s a w h i t e s k i n n e d b r o w n h a i r e d s p o r t s m a n w h i l e p e r s o n 2 i s a w h i t e s k i n n e d i n d i v i d u a l w i t h y e l l o w h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w o m a n w i t h w h i t e s k i n a n d g o l d h a i r w h o i s s t a n d i n g i s a d a n c e r', 'a w h i t e d o g i s i n a w h i t e c e r a m i c b a t h t u b', 't h e c a r i s p a r k e d a n d i t i s r e d', 'a p e r s o n w i t h f a i r s k i n w h o i s a b o y t h e h a i r _ c o l o r i s b l a c k a f t e r a w h i l e h i s h a i r _ c o l o r i s b r o w n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h o l d i n g t h e s t i c k i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r t h e s t i c k i t s e l f i s m a d e o f r e d p l a s t i c', 't h e b e l l y i s p a r t o f a p e r s o n w h o i s a w h i t e m a n w i t h b r o w n h a i r a n d t h e b e l l y i t s e l f i s w h i t e a s w e l l', 't h e p e r s o n s p e a k i n g i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w e a r i n g w h i t e t r o u s e r s m a d e o f c l o t h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h e a d o f t h e p e r s o n i s w h i t e a n d t h e p e r s o n i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r h e i s a c u s t o m e r', 't h e r e i s a g r e e n m e t a l m o w e r o n t h e g r e e n y a r d', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s t h e o n e s p e a k i n g', 't h e r e i s a r e d p l a s t i c c a s i n o n e a r a p e r s o n w h o i s a w h i t e s k i n n e d m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a p e r s o n s t a n d i n g w h o i s a w h i t e s k i n n e d b o y w i t h b r o w n h a i r', 'a w o m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s s t a n d i n g w h o i s a w o r k e r', 't h e w o m a n t o u c h e s t h e s t r a w b e r r i e s a n d a p p l e s t h e w o m a n s p r i n k l e s l i t t l e b e r r i e s o n t o t h e o t h e r f r u i t', 't h e r e i s a w h i t e s k i n n e d m a n s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w o m a n w i t h b l a c k h a i r w h o h a s w h i t e s k i n i s c u r r e n t l y e x e r c i s i n g', 't h e a r m w h i c h b e l o n g s t o a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s a p a r t o f t h e p e r s o n', 'a g i r l w i t h y e l l o w s k i n a n d b l a c k h a i r i s w a l k i n g', 't h e p e r s o n w h o i s k n e e l i n g i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s l o c a t e d i n c l o s e p r o x i m i t y t o p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s i n a b a t h r o o m w h i c h i s m a d e o f w h i t e c e r a m i c', 't h e r e i s a p e r s o n s q u a t t i n g w h o i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r', 's e v e r a l d i f f e r e n t c a k e p o p s a r e b e i n g s h o w n i n g r e d i e n t s a r e d i s p l a y e d n e x t t o a c t i o n s m i x i n g i n g r e d i e n t s t h e p e r s o n d e c o r a t e s t h e c a k e b a l l i n t h e f i n a l s t a g e s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s s t a n d i n g', 't h e p e r s o n s i t t i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n h o l d i n g t h e i c e c r e a m h a s w h i t e s k i n a n d t h e i c e c r e a m i t s e l f i s b r o w n', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d a n i n s t r u c t o r i s s p e a k i n g w i t h p e r s o n 2 a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d a s p o r t s m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['o n t h e s t a g e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a d a n c e r t h e s t a g e i t s e l f i s m a d e o f w h i t e w o o d', 'p e r s o n 1 a m a l e s p o r t s m a n i s e n g a g e d i n a f i g h t w i t h p e r s o n 2 a l s o a m a l e s p o r t s m a n', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g w h o i s a b a l l p l a y e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g o n t h e w h i t e h i l l', 'p e r s o n 1 a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 w h o i s a l s o a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e e y e i s a p a r t o f t h e p e r s o n s p e c i f i c a l l y a w h i t e e y e b e l o n g i n g t o a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r', 'a w o m a n w i t h w h i t e s k i n a n d r e d h a i r i s p u s h i n g a b l a c k m e t a l m o w e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n r a i s i n g t h e i r a r m i s a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r w h o i s a d a n c e r a n d h e r a r m i s a l s o w h i t e', 't h e r e i s a b r o w n d o g s t a n d i n g', 't h e p e r s o n s p e a k i n g i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o w o r k s a s a n i n s t r u c t o r', 't h e a r m w h i c h i s w h i t e i s p a r t o f a m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n s t a n d i n g w h o h a p p e n s t o b e a r e f e r e e', 'p e r s o n 1 a w h i t e m a n w i t h b r o w n h a i r i s n e a r p e r s o n 2 a w h i t e w o m a n w i t h b r o w n h a i r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a n i n s t r u c t o r i s s p e a k i n g', 'a w h i t e s k i n n e d b o y w i t h g o l d h a i r i s t o u c h i n g t h e g r e y r u b b e r e x e r c i s e b a l l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s e e n b r u s h i n g a b r o w n w o o d e n f e n c e', 't h e r e i s a b l a c k w o o d t a b l e n e a r a m a n w i t h b r o w n h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s i t t i n g', 't h e r e i s a p e r s o n s t a n d i n g w h o i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d i s a m u s i c i a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w h i t e s k i n n e d b a l l p l a y e r w h o i s a m a n i s e n g a g e d i n a f i g h t w i t h p e r s o n 2 a n o t h e r w h i t e s k i n n e d b a l l p l a y e r w h o h a s b r o w n h a i r', 't h e p e r s o n t h r o w s a l l t h e p l a t e s o n e b y o n e v e r y f a s t t h e p e r s o n p u s h e s t h e m a l l d o w n i n t o t h e w a t e r', 'p e r s o n 1 a n e l d e r l y m a n w i t h w h i t e h a i r a n d f a i r s k i n i s p h y s i c a l l y t o u c h i n g p e r s o n 2 a n e l d e r l y w o m a n w i t h w h i t e h a i r a n d f a i r s k i n', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a c o n t e s t a n t i s w a l k i n g o n t h e b r o w n r u b b e r a r e n a']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b l a c k p a w i s a p a r t o f t h e b l a c k d o g', 'a l a d y p l a y s w i t h h e r h a i r t h e l a d y b r u s h e s h e r h a i r', 't h e p e r s o n s i t t i n g i s a p e r f o r m e r a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a g i r l w i t h b l a c k s k i n a n d b l a c k h a i r i s h o l d i n g a p u r p l e p l a s t i c b r u s h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s t a n d i n g i s a b l a c k s k i n n e d w o m a n', 't h e m a n t r a i n s a n o t h e r c h i l d w h i l e s h o w i n g m o v e m e n t s', 't h e d i s h h a s a r e d g a r n i s h m e n t a n d a g r e e n d i s h', 't h e f i r s t w o m a n w h o h a s w h i t e s k i n a n d b r o w n h a i r i s w e a r i n g y e l l o w r u b b e r g l o v e s a f t e r a w h i l e t h e s e c o n d w o m a n w h o a l s o h a s w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a p r o d u c t m a d e o f w h i t e p l a s t i c']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s p e a k i n g i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a r u n n e r', 'a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r i s s t a n d i n g w h o i s a b a l l p l a y e r', 't h e r e i s a w o m a n w i t h f a i r s k i n a n d y e l l o w h a i r s t a n d i n g', 't h e r e i s a m a n a p e r f o r m e r w i t h w h i t e s k i n w h o i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s s t a n d i n g', 'a w h i t e c a t i s l y i n g d o w n', 't h e r e i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i n t h e g r e e n b a c k y a r d', 'a s i l v e r m e t a l s w i n g i s c u r r e n t l y s w i n g i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n s f a c e i s a n i n t e g r a l p a r t o f t h e i r i d e n t i t y p a r t i c u l a r l y f o r g i r l s w i t h w h i t e s k i n a n d y e l l o w h a i r', 's o m e p e o p l e a r e s e e n o n w a t e r s k i s i n t h e l a k e s e v e r a l m o v e s a n d p o s i t i o n s a r e s h o w n a s t h e p e r s o n t a l k s', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g o n a b l a c k r o c k', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s p e a k i n g h a s w h i t e s k i n a n d b l a c k h a i r a n d i s a m a n', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s c l o s e t o p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r a c t i n g a s a j u d g e', 't h e r e i s a m a n w i t h w h i t e s k i n a n d g r e y h a i r s i t t i n g', 't h e r e i s a b l a c k m e t a l c a r i n t h e y e l l o w c a r w a s h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l a c k d o g s t a n d i n g', 't h e v i d e o b e g i n s w i t h a t i t l e s e q u e n c e s e v e r a l c l i p s o f b a s e b a l l p l a y e r s a r e s h o w n p l a y i n g t h e g a m e t h e v i d e o e n d s w i t h a n o t h e r t i t l e s e q u e n c e', 't h e w h i t e h a n d b e l o n g s t o a m a n w h o i s a b a l l p l a y e r a n d h a s w h i t e s k i n a n d b r o w n h a i r', 't h e l i q u i d w h i c h i s b l u e i s f l o w i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c o l o r o f m u l c h i s g r e e n', 't h e m a n w i t h w h i t e s k i n w h o i s a w o r k e r h a s b r o w n h a i r a n d i s s q u a t t i n g', 't h e p e r s o n w h o i s s m i l i n g h a s w h i t e s k i n a n d b r o w n h a i r a n d i s a g i r l', 't h e p e r s o n m o v e s t o w a r d s w h e r e h i s w h i t e v a n i s p a r k e d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n w h o i s s p e a k i n g', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a w o m a n a n d m a n a r e r a k i n g l e a v e s o u t s i d e t h e i r h o m e p e o p l e m o v e t h e l e a v e s i n t o a f i r e p i t b u r n i n g t h e m', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o h a p p e n s t o b e a s u m o w r e s t l e r i s w a l k i n g o n t h e b r o w n r i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n e x e r c i s i n g i s a n a d u l t s u r f e r', 't h e r e i s a b l a c k h a i r e d m a n w i t h b l a c k s k i n w h o i s a s p o r t s m a n o n t h e p i n k p l a s t i c t r a c k', 'a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s e x e r c i s i n g', 'p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s n e a r p e r s o n 2 w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s s e a t e d i n f r o n t o f a c a n v a s t h e m a n i s u s i n g a p a l e t t e t o p a i n t a n o m b r e s c e n e', 'a m a n t a l k s t o t h e c a m e r a t h e y o u t u b e l o o k a l i k e p a g e w i t h a v i d e o i s s h o w n a g a i n', 't h e p e r s o n d r i v i n g h a s w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n s k i i n g i s a m a n w i t h w h i t e s k i n w h o e n j o y s s l i d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r a g o l d m e t a l s a x o p h o n e', 't h e h a n d i s a p a r t o f t h e p e r s o n s p e c i f i c a l l y a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r', 'i n t h e y a r d t h e r e i s a b l u e p l a s t i c t r a s h c a n a n d t h e y a r d i t s e l f i s g r e e n', 't h e r e i s a g a m e o f h o c k e y b e i n g p l a y e d t h e p l a y e r s r u s h t h e f i e l d a n d s t a r t f i g h t i n g a p e r s o n p u n c h e s s o m e o n e i n t h e h e a d t h e c o a c h i s t r y i n g t o f i g h t a n o t h e r c o a c h a m a n c l i m b s o v e r t h e b a l c o n y t o t r y a n d f i g h t t h e r e d t e a m g a t h e r s a n d h u g s e a c h o t h e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r o o f o f t h e h o u s e i s m a d e o f w h i t e t h a t c h w h i l e t h e h o u s e i t s e l f i s c o n s t r u c t e d f r o m w h i t e w o o d', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g', 't h e c u p i s w h i t e', 't h e h a i r w h i c h i s b r o w n b e l o n g s t o a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d a b a r b e r i s r e s p o n s i b l e f o r i t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p l a y e r j u m p e d a n d c a r t w h e e l h i g h', 't h e p e r s o n h o l d i n g t h e s t i c k i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h i l e t h e s t i c k i t s e l f i s m a d e o f g o l d m e t a l', 't h e r e i s a y e l l o w w o o d e n c h a i r n e a r a w h i t e s k i n n e d b o y w i t h y e l l o w h a i r', 'a p e r s o n w i t h b l a c k s k i n a n d b r o w n h a i r i s p l a y i n g a r e d c a r d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b o y w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s w e a r i n g a b l a c k c l o t h s h i r t', 'p e o p l e a r e p l a y i n g i n s t r u m e n t s m a r c h i n g d o w n a s t r e e t p e o p l e s t a r t m a r c h i n g i n a c i r c l e i n a r o o m', 't h e r e i s a s u g a r o n t h e p l a t e w i t h t h e s u g a r b e i n g w h i t e a n d t h e p l a t e b e i n g m a d e o f w h i t e p l a s t i c', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s r a i s i n g a y e l l o w m e t a l b a r b e l l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a g i r l w i t h b l a c k s k i n a n d b l a c k h a i r i s l o c a t e d c l o s e t o p e r s o n 2 w h o i s a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a y e l l o w m e t a l r u n n i n g w h i c h i s a s a n d e r', 'a n o l d m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s c u t t i n g a y e l l o w p u m p k i n', 'a b l a c k h a i r e d m a n w i t h d a r k s k i n i s p l a y i n g a y e l l o w w o o d e n c o n g a']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g', 't h e r e i s a p e r s o n h o l d i n g a g r e y p l a s t i c s h a v e r w h o i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s s q u a t t i n g', 't h e c o l o r o f t h e g r o u n d i s y e l l o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b o y w i t h f a i r s k i n w h o i s a s k a t e r o n t h e g r e y s t r e e t', 't h e r e i s a m a n w i t h w h i t e s k i n a n d g r e y h a i r s t a n d i n g n e a r a y e l l o w p e a r', 't h e p e r s o n w h o i s b o w i n g h a s w h i t e s k i n a n d b l a c k h a i r', 'a d o g i s g e t t i n g a b a t h o u t s i d e s o a p i s w o r k e d t h r o u g h t h e c o a t a n d t h e n w a s h e d o f f']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['s e v e r a l a t h l e t e s c o m p e t e f o r t h e j a v e l i n w o r l d c h a m p i o n s h i p s t h e r u s s i a d i m i t r i i s 3 r d b r o n z e m e d a l i n t h e c o m p e t i t i o n t h e j a p a n e s e j e n k i i s s i l v e r m e d a l g e r m a n y w o n t h e g o l d m e d a l', 't h e p e r s o n s m o k i n g i s a w o m a n w i t h f a i r s k i n a n d g o l d e n h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s i t t i n g w h o i s a r a c e r', 't h e r e i s a p e r s o n s p e a k i n g w h o i s a w h i t e s k i n n e d b o y w i t h b r o w n h a i r a n d w o r k s a s a b a r t e n d e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a p e r s o n i n t h e b a r w h o i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d t h e b a r i t s e l f i s g r e e n', 't h e g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s d r i n k i n g f r o m t h e w h i t e p l a s t i c c u p', 't h e h o r s e i s b r o w n', 'r a g i s a w h i t e c l o t h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l a c k g l a s s w i n d o w p o s i t i o n e d n e a r a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e w o m a n w i t h w h i t e s k i n w h o i s e x e r c i s i n g h a s b l a c k h a i r', 't h e c a r s t o p s a t a n i n t e r s e c t i o n t h e c a r m a k e s a u t u r n t h e m a n d r i v e s i n t o a c a r w a s h a n d g e t s o u t t h e m a n s h o w s h i s w e t c a r', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w e a r i n g a r e d c l o t h t s h i r t w h i l e p e r s o n 2 a l s o a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w e a r i n g b l u e c l o t h s h o r t s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b o y w i t h b l a c k s k i n a n d b l a c k h a i r i s j u m p i n g o n t h e g r e y l a n e', 't h e p e r f o r m e r i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r a n d s h e i s c u r r e n t l y p e r f o r m i n g', 'a w h i t e s k i n n e d b o y w i t h b l a c k h a i r w h o i s a b a l l p l a y e r i s h o l d i n g a b l a c k r u b b e r d o d g e b a l l', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a b a r b e r i s c u t t i n g b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['w a t e r f l o w s a n d i t i s t r a n s p a r e n t', 't h e p e r s o n s i t t i n g h a s b r o w n h a i r a n d s h e i s a g i r l w i t h w h i t e s k i n', 't h e r e i s a p e r s o n p e r f o r m i n g w h o h a s w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a m a n s t a n d i n g w h o h a s y e l l o w s k i n b l a c k h a i r a n d i s a m a r t i a l a r t i s t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s s m i l i n g i s a w h i t e s k i n n e d y e l l o w h a i r e d w o m a n w h o i s a l s o a v i o l i n i s t', 'a m a n w i t h w h i t e s k i n i s t o u c h i n g t h e t a b l e w h i c h i s m a d e o f g r e e n w o o d', 'a y e l l o w r u b b e r b a l l i s r o l l i n g i n c r o q u e t', 't h e p e r s o n t o u c h i n g t h e h a i r i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k s k i n n e d m a n i s s p e a k i n g w h o i s t h e p r e s e n t e r', 't h e p e r s o n h o l d i n g t h e g r e e n n y l o n r o p e h a s f a i r s k i n g o l d e n h a i r a n d i s a g i r l', 't h e r e i s a w o m a n s t a n d i n g h a v i n g w h i t e s k i n a n d b l a c k h a i r', 't h e m a n t h e n b l o w s s m o k e i n t o t h e c a m e r a l e n s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a m u s i c i a n i s p e r f o r m i n g', 't h e r o a d a p p e a r s t o b e y e l l o w', 't h e p e r s o n s t a n d i n g h a s w h i t e s k i n a n d b l a c k h a i r', 't h e b o x w h i c h i s w h i t e i s b e i n g t o u c h e d b y a r e d p a p e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s s i t t i n g h a s w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a m a n i n t h e a u d i e n c e w h o i s s i t t i n g a n d h a s w h i t e s k i n a n d b l a c k h a i r', 'a p e r s o n w i t h f a i r s k i n a n d b l a c k h a i r i s s i t t i n g o n a b r o w n r o p e w h i l e t o u c h i n g a w h i t e l e g', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a s p o r t s m a n i s s t a n d i n g o n t h e r e d p l a s t i c t r a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s w i m m e r i s w e a r i n g a r e d c l o t h s w i m s u i t', 'a m a n w i t h w h i t e s k i n i s s i t t i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d g r e y h a i r w a l k i n g', 'a t r a n s p a r e n t g l a s s b o t t l e i s o p e n e d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a s i l v e r w o o d e n d r u m i s r e s t i n g o n t h e w h i t e s n o w', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r w a l k i n g o n t h e b l u e p o o l s h e i s a d i v e r', 'w a t e r i s b l u e i n c o l o r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i n t h e s i l v e r m a l l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p a p e r i s w h i t e', 'a p e r s o n w i t h w h i t e s k i n i s s w e e p i n g a w h i t e m e t a l c a r a n d l a t e r h e c o n t i n u e s t o s w e e p t h e w h i t e s n o w', 't h e g r o u n d i s b l a c k', 't h e r e i s a m a n s t a n d i n g w h o h a s b l a c k s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s t h e b l e a c h e r a n s p e c t a t o r s t h e m a n i n g r a y b a c k s u p a n d w i p e s s w e a t t h e r e i s t h e e n d i n g t i t l e s c r e e n', 'a p e r s o n w h o i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i s p l a y i n g k i c k b a l l w i t h a r e d r u b b e r b a l l', 't h e p e r s o n w h o i s a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r i s w i p i n g h e r w h i t e h a n d', 't h e p e r s o n w h o i s e x e r c i s i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r a n d h e i s a s w i m m e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['m a n s c r a p s t h e i c e f r o m h i s w i n d s h i e l d m a n p o u r s h o t w a t e r m i x t u r e o n h i s c o l d w i n d s h i e l d', 't h e p e r s o n w e a r i n g t h e h a t i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r t h e h a t i t s e l f i s m a d e o f b r o w n c l o t h', 't h e r e i s t h e m a n i l l u s t r a t i n g b r e a k d a n c e m o v e s t h e m a n i s t a l k i n g a n d s i t t i n g s t i l l t h e m a n d a n c e f a s t t h e m a n p e r f o r m a l e g s w e e p m o v e a n a n i m a t e d c l o s e s c e n e a n d a s u b s c r i b e p a g e', 't h e r e i s a t i t l e c a r d a n d a p a i n e d d r e s s e r a l a d y s i t s o n t h e f l o o r a n d d i s c u s s e s p a i n t i n g t h e l a d y p a i n t s t h e d r e s s e r w h i l e t a l k i n g a b o u t i t t h e r e i s a p a i n t e d e n d p r o d u c t t h e r e i s a n e n d c a r d s f o r t h e v i d e o']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g v o l l e y b a l l w i t h a y e l l o w r u b b e r b a l l w h i l e p e r s o n 2 w h o i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s a l s o p l a y i n g w i t h t h e s a m e y e l l o w r u b b e r b a l l', 'p e r s o n 1 a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s w e a r i n g b l a c k d i v i n g g e a r a f t e r a w h i l e p e r s o n 2 a l s o a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r p u t s o n r e d s u n g l a s s e s', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g o n a s i l v e r m e t a l s l i d e', 't h e r e i s a w o m a n s i t t i n g s h e h a s w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n m o v e s b a c k a n d f o r w a r d i n h i s c a r t h e p e r s o n l o o k s l o n e l y a s h e f i n a l l y c o m e s t o a s t o p', 't h e l a d y s c r u b s a g a r m e n t o n a w o o d e n b o a r d', 't h e p e r s o n w h o i s w e a r i n g b l a c k c l o t h u n d e r w e a r i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n s p e a k i n g h a s b l a c k h a i r a n d w h i t e s k i n a n d h e i s a m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a n a d u l t p e r s o n s t a n d i n g w h o h a s w h i t e s k i n', 'm a n w e a r i n g a p u r p l e s h i r t i s h o l d i n g a g a s p i p e m a n i s s t a n d i n g o u t s i d e a h o u s e l i g h t i n g u p a w o o d f i r e', 'a b o y w i t h w h i t e s k i n a n d y e l l o w h a i r i s t o u c h i n g a b r o w n w o o d e n t a b l e', 'a p l a s t i c c o m b t h e c o l o r i s b r o w n a f t e r a w h i l e i t s c o l o r i s g r e y']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
[32m2023-10-19T20:02:53 | utils.basic_utils: [0mTrain Epoch: [0]  [ 300/2288]  eta: 0:28:45  lr: 0.000010  temperature: 0.0119  video-loss_ita: 1.5777  video-loss_itm: 0.6238  time: 0.7580  data: 0.0132  max mem: 7604 res mem: 7876
text in iter ['t h e r e i s a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s d a n c i n g', 't h e r e i s a m a n s t a n d i n g w i t h w h i t e s k i n a n d b r o w n h a i r', 'a n i n d i v i d u a l w i t h f a i r s k i n i s c u t t i n g a y e l l o w l e m o n a n d a f t e r a w h i l e t h e y a r e h o l d i n g y e l l o w s u g a r', 'a m a n c h o p s w o o d w i t h a n a x o n t h e s n o w a p e r s o n s t a n d s b e h i n d t h e m a n a p e r s o n h a n d l e s t h e s p l i c e d f i r e w o o d t o a m a n t h e m a n c o n t i n u e s c h o p p i n g f i r e w o o d w i t h t h e a x']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s s k a t i n g i s a w h i t e s k i n n e d b o y w i t h b l a c k h a i r', 'a c h i l d w i t h w h i t e s k i n w h o i s a b a l l p l a y e r i s e x e r c i s i n g', 't h e o t h e r b i k e r s r a c e o f f', 'p e r s o n 1 a b o y w i t h y e l l o w s k i n a n d b l a c k h a i r i s t o u c h i n g t h e p e r s o n w h o a l s o h a s y e l l o w s k i n a n d b l a c k h a i r a t t h e s a m e t i m e p e r s o n 2 a n o t h e r b o y w i t h y e l l o w s k i n a n d b l a c k h a i r i s t o u c h i n g t h e b l u e w o o d e n t a b l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a g i r l s t a n d i n g w h o h a s w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n w o r k i n g a s a b a r b e r i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a n o l d m a n w i t h w h i t e s k i n a n d g r e y h a i r s i t t i n g', 'a w h i t e s k i n n e d m a n i s t o u c h i n g a s i l v e r m e t a l s i n k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e s h o r t s a r e b l a c k', 't h e c o l o r o f f o o d i s b r o w n', 'a c o n t e s t a n t w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s a m a n i s p u l l i n g t h e y e l l o w l i n e n r o p e', 't h e p a t h i s g r a y a n d i t i s f l o w i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e d o c u m e n t a r y f o c u s e s o n a f a m o u s p l a y e r', 'a m a n w i t h w h i t e s k i n i s h o l d i n g t h e y e l l o w a r r o w', 'a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s o n t h e l i n e w h i c h i s m a d e o f b l a c k n y l o n', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a s k a t e r i s s q u a t t i n g o n a b l a c k w o o d e n s k a t e b o a r d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l u e s a i l b o a r d o n t h e b l u e s e a', 'a b r o w n r u b b e r b a s k e t b a l l i s f l y i n g', 'p e r s o n 1 w h o i s a w h i t e w o m a n i s t o u c h i n g t h e o r a n g e c l o t h w h i l e p e r s o n 2 a l s o a w h i t e w o m a n i s h o l d i n g t h e w h i t e m e t a l i r o n', 't h e r e i s a m a n s t a n d i n g w h o h a s w h i t e s k i n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e s o a p i s b e i n g h e l d b y a m a n w i t h y e l l o w s k i n a n d b r o w n h a i r w h o i s i n p o s s e s s i o n o f i t t h e s o a p i t s e l f i s b r o w n i n c o l o r', 't h e r e i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r s t a n d i n g w h o i s a s p o r t s m a n', 't h e p e r s o n i s p a i n t i n g o n e o f t h e h o u s e s w i t h b l u e p a i n t t h e p e r s o n i s h o l d i n g a b u c k e t o f p a i n t', 't h e r e i s a m a n w i t h w h i t e s k i n a p e r f o r m e r i n a b l a c k r o o m']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b a t o n i s b e i n g h e l d b y a p e r s o n w h o i s a w h i t e s k i n n e d b o y w i t h a b a n d a n d t h e b a t o n i t s e l f i s m a d e o f w h i t e m e t a l', 't h e m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s e x e r c i s i n g', 't h e h a n d w h i c h b e l o n g s t o a p e r s o n d e s c r i b e d a s a w h i t e m a n w i t h b l a c k h a i r i s a n a t u r a l p a r t o f h i m', 't h e p e r s o n w h o h a s w h i t e s k i n a n d b r o w n h a i r t o u c h e s t h e b r o w n w o o d e n s h u f f l e b o a r d a f t e r s o m e t i m e h e p r o c e e d s t o t o u c h t h e b o a r d w h i c h i s a l s o m a d e o f b r o w n w o o d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s t a n d i n g i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r w h o a c t s a s t h e r e f e r e e', 't h e r e i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s s t a n d i n g', 't h e r e i s a p e r s o n s i t t i n g c h a r a c t e r i z e d b y w h i t e s k i n a n d y e l l o w h a i r', 't h e n a i l i s b l u e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d g o l d h a i r w h o i s j u m p i n g', 't h e p e r s o n s t a r t s d a n c i n g f o r t h e c a m e r a t h e p e r s o n s h o w s s e v e r a l d a n c e m o v e s a s s h e d o e s t h e m', 'a w a l l i s p a i n t e d b y t w o m e n', 'a w h i t e h o r s e i s n e a r t h e b a g a n d t h e b a g i s m a d e o f p i n k c l o t h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e m e t a l c a r o n a g r a y r o a d', 't h e r e i s a m a n w i t h w h i t e s k i n w h o i s a m a t a d o r r i d i n g a b r o w n h o r s e', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w o r k s a s a c u s t o m e r p e r s o n 2 a l s o a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w o r k s a s a h a i r s t y l i s t', 't h e r e i s a n a d u l t p e r s o n i n t h e y e l l o w r o o m w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g a b l a c k w o o d e n a c c o r d i o n', 't h e m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a b a r b e r i s t o u c h i n g t h e c u s t o m e r w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a w h i t e c l o t h s h o e i n t h e s i l v e r m e t a l s i n k', 't h e r e i s a n a d u l t p e r s o n w i t h y e l l o w s k i n a n d b l a c k h a i r i n t h e b l u e p o o l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w e a r e r o f t h e m a s k i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d t h e m a s k i t s e l f i s m a d e o f g r a y m e t a l', 'a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s r u n n i n g', 't h e r e i s a w h i t e s k i n n e d b o y w i t h y e l l o w h a i r w h o i s s m i l i n g', 't h e p e r s o n h o l d i n g t h e m o w e r i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d t h e m o w e r i t s e l f i s m a d e o f b l a c k m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a b o y w i t h w h i t e s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r', 't h e c o l o r o f t h e l o t i o n i s w h i t e', 't h e p e r s o n s p e a k i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a w o r k e r w i t h b l a c k s k i n a n d b l a c k h a i r i s h o l d i n g a p i e c e o f w h i t e f a b r i c']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s l e a n i n g a g a i n s t a r e d w a l l', 'a b o y w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g w i t h a r e d p l a s t i c r u b i k s c u b e', 'a b a n d i s g a t h e r e d o u t s i d e a b u i l d i n g a l e a d e r i s u s i n g a b a t o n t o i n s t r u c t p e o p l e p e o p l e a r e p l a y i n g t h e d r u m s f o r a s m a l l a u d i e n c e', 'a m a n w i t h b l a c k s k i n a n d b l a c k h a i r w h o i s a n i n s t r u c t o r i s r i d i n g t h e b i k e w h i c h i s m a d e o f o r a n g e m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n e x e r c i s i n g i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r w h o h a p p e n s t o b e a s u r f e r', 't h e b i k e i n c l u d e s a b l a c k h a n d l e a n d i s b r o w n', 't h e p r e s e n t e r w h o i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s w e a r i n g a g r e e n d r e s s', 't h e p e r s o n w h o i s d r a w i n g i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r a n d s h e i s a p a i n t e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s t a n d i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a l s o t h e p r e s e n t e r', 'a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r i s r a i s i n g a b l a c k m e t a l d u m b b e l l', 'a b o y w i t h w h i t e s k i n a n d b l a c k h a i r i s e x e r c i s i n g', 'a g u y w a v e s a n d t h e n s p e a k s a m a l e a p p r o a c h e s a n d g r a b s a p l a t e t h e m a l e t a k e s t h e p l a t e t o t h e s i n k t h e m a l e r i n s e s t h e w a s h e d p l a t e t h e m a l e g i v e s a t h u m b s u p']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a g r e y p l a s t i c v a c u u m i s c u r r e n t l y r u n n i n g', 't h e p e r s o n w h o i s w o r k i n g i s a t a t t o o a r t i s t a n d h e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'p e o p l e a r e d r i v i n g a c a r w i t h r a f t s o n t h e b a c k p e o p l e g o t o a h o t d o g s t a n d a n d g e t f o o d p e o p l e c o n t i n u e r a f t i n g d o w n t h e r i v e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h b l a c k s k i n s t a n d i n g', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a n a t h l e t e s t a n d i n g o n t h e g r e e n g r o u n d', 't h e r e i s a n a d u l t w i t h y e l l o w s k i n s t a n d i n g', 'a y e l l o w h o r s e w a l k s a s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r s i t s n e a r b y']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h o l d i n g t h e t o o t h b r u s h h a s y e l l o w s k i n b r o w n h a i r a n d t h e t o o t h b r u s h i t s e l f i s m a d e o f w h i t e p l a s t i c', 't h e m a n i s r i d i n g a w h i t e m e t a l b i k e w h i c h h e u s e s f o r c r o s s c o u n t r y d r i v i n g', 't h e s c r e e n s h o w s c o m p a n y s p o n s o r s f o r a w i n t e r c l u b e v e n t a b l u e c o n v e r t i b l e d r i v e s p a s t t h e n o r t h s h o r e w i n t e r c l u b s e v e r a l p e o p l e a r e e n t e r i n g t h e c u r l i n g r o o m i n s i d e t h e c l u b t h e c o a c h t a l k s t o t h e p l a y e r s w h i l e t h e y p r e p a r e t h e m s e l v e s', 'a p e r s o n w h o h a s w h i t e s k i n a n d b l a c k h a i r i s r e p a i r i n g s o m e t h i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e t r a c k o p e n s a g a i n a n d t h e y s t a r t a n o t h e r r a c e', 't h e p e r s o n s e p a r a t e s h e r h a i r i n t o s e c t i o n s', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n i s s i t u a t e d c l o s e t o p e r s o n 2 a m a n w i t h w h i t e s k i n', 't h e d o l l h a s g o l d e n h a i r a n d i t s c o l o r i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n h o l d i n g a b l a c k b u c k e t i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n b e g i n s s h a v i n g h e r l e g w i t h a r a z o r t h e p e r s o n l o o k s a t t h e b o t t o m o f t h e r a z o r', 't h e r u n n i n g l e a f b l o w e r i s r e d', 't h e p e r s o n s t a n d i n g i s a w h i t e s k i n n e d m a n w i t h w h i t e h a i r w h o i s s e r v i n g a s t h e p r e s e n t e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n b o w i n g h a s w h i t e s k i n a n d b r o w n h a i r w h o i s t h i s p e r s o n', 't h e p e r s o n s p e a k i n g i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a w h i t e s k i n n e d m a l e c o n t e s t a n t w h o i s a p e r s o n i s w a l k i n g o n t h e g r e e n f i e l d', 't h e p e r s o n s t a n d i n g i s a m a n w i t h w h i t e s k i n a n d h e i s a r u n n e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a s i l v e r c a r i s p a r k e d i n t h e s t r e e t a m a n p o w e r w a s h e s t h e c a r i n t h e s t r e e t t h e p e r s o n t h e n d r i e s t h e o b j e c t o f f t h e c a r i s n o w c o m p l e t e l y c l e a n', 't h e w o m a n i n w h i t e s w e a t e r i s t a l k i n g t o t h e c a m e r a t h e w o m a n i s h o l d i n g a v i o l i n a n d s t i c k', 't h e r e i s a w h i t e d o g o n a g r e e n m e t a l m o w e r', 'a b l a c k s k i n n e d m a n w i t h b l a c k h a i r i s t o u c h i n g a w o o d e n t a b l e t h a t i s g r e e n i n c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h b r o w n h a i r i s s l i d i n g o n t h e w h i t e r o a d', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d s w h o i s a c o n t e s t a n t', 'p e r s o n 1 w h o i s a n a d u l t r e f e r e e w i t h b l a c k s k i n i s p o s i t i o n e d n e a r p e r s o n 2 w h o i s a l s o a m a n w i t h b l a c k s k i n a n d i s a r e f e r e e', 't h e o c e a n i s a v a s t b o d y o f w a t e r t h e c o l o r i s w h i t e a f t e r a w h i l e i t s c o l o r i s t r a n s p a r e n t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a n w i t h b r o w n h a i r i s p u l l i n g t h e w h i t e r o p e', 'a w h i t e s k i n n e d b o y w i t h b l a c k h a i r i s s t a n d i n g', 'a w o m a n w i t h w h i t e s k i n a n d g o l d e n h a i r i s s t a n d i n g', 't h e c o l o r o f t h e s e a i s b l u e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s b r u s h i n g h e r b r o w n h a i r', 't h e h a n d o f t h e p e r s o n i s w h i t e t h e p e r s o n i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d h e i s a s p o r t s m a n', 't h e r e i s a g r e e n w o o d e n s u r f b o a r d f l o a t i n g', 'p e r s o n 1 a n e l d e r l y w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n e x e r c i s i n g i s a w o m a n w i t h w h i t e s k i n a n d g o l d e n h a i r', 't h e b l a c k w o o d e n s k i i s c u r r e n t l y a t t h e w h i t e s h o p', 't h e r e i s a p e r f o r m e r s t a n d i n g o n t h e y e l l o w c e r a m i c f l o o r t h i s p e r s o n i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r', 'p e r s o n 1 a m a n w i t h b l a c k s k i n i s p u l l i n g t h e b l a c k a n d w h i t e c a t t l e m e a n w h i l e p e r s o n 2 a p e r s o n w i t h w h i t e s k i n i s f i g h t i n g w i t h t h e s a m e b l a c k a n d w h i t e c a t t l e i n f r o n t o f a n a u d i e n c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p u m p k i n i s g r e e n', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g o n t h e b r o w n h i l l', 'a w h i t e s k i n n e d b o y w i t h b l a c k h a i r i s s i t t i n g o n t h e r e d r u b b e r i n f l a t a b l e b o a t', 't h e p e r s o n s t a n d i n g t h e r e i s a g i r l w i t h f a i r s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w a t e r t h a t i s f l o w i n g i s t r a n s p a r e n t', 't h e w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r p e r s o n 1 i s t o u c h i n g p e r s o n 2 w h o i s a l s o a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e c o n t e s t a n t a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i s r i d i n g a b l a c k r e d w h i t e b i k e w h i l e t h e a u d i e n c e m e m b e r a w o m a n w i t h w h i t e s k i n a n d g o l d h a i r i s t a k i n g p i c t u r e s o f h i m', 't h e c o n t e s t a n t i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r a n d h i s a r m i s a p a r t o f h i m']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s t a n d i n g i s a w o m a n w i t h y e l l o w s k i n', 't h e m a t c h i s b e i n g h e l d b y a m a n w i t h w h i t e s k i n a n d w h i t e h a i r t h e m a t c h i t s e l f i s m a d e o f r e d w o o d', 't h e d o g i s b l a c k a n d i t i s s t a n d i n g', 't h e p e r s o n p o u r s t h e r a w e g g b a t t e r i n t o t h e p a n t h e p e r s o n t h e n t o p s i s o f f w i t h s o m e g r a t e d c h e e s e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e g i r l s l i f t s t h e n l o w e r s h e r a r m s k y l a t h e n j u m p s o n t o t h e s h o r t b a r t h e p e r s o n s p i n s b a c k t o t h e t a l l o n e a n d s p i n s t h e p e r s o n d i s m o u n t s a n d h u g s h e r c o a c h h e r f i n a l s c o r e o n a b l a c k s c r e e n', 'a w o m a n w i t h f a i r s k i n i s p o u r i n g s o m e t h i n g i n t o a t r a n s p a r e n t g l a s s b o w l a n d l a t e r s h e c u t s a y e l l o w f r u i t', 't h e p e r s o n s i t t i n g i n t h e a u d i e n c e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n h o l d i n g t h e s l e e v e i s a n e l d e r l y w o m a n w i t h w h i t e s k i n a n d w h i t e h a i r t h e s l e e v e i s m a d e o f w h i t e c l o t h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n i s a g o l d e n h a i r e d b o y w i t h w h i t e s k i n w h o h a p p e n s t o b e a d r u m m e r a n d i s c u r r e n t l y s e a t e d', 'a m a n w i t h y e l l o w s k i n i s e x h a l i n g w h i t e s m o k e', 't h e r e i s a m a n s t a n d i n g w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r o n t h e w h i t e t r a i n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h o l d s u p a p h o n e a n d s p e a k s i n t o t h e m i r r o r', 't h e r e i s a w h i t e s k i n n e d m a n s t a n d i n g', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g o n a b l u e m e t a l p l a t f o r m', 't h e h a n d w h i c h i s p a r t o f a p e r s o n b e l o n g s t o a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r w h o i s a l s o a s p o r t s m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n s t a n d i n g o n t h e g r e e n f i e l d a n d h e h a s w h i t e s k i n', 'a g i r l w i t h f a i r s k i n a n d g o l d e n h a i r i s h o l d i n g a g r e y s h o v e l', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g n e a r p e r s o n 2 a b l a c k s k i n n e d d r u m m e r w h o i s a l s o a m a n', 't h e m o u t h w h i c h i s w h i t e i s p a r t o f a p e r s o n w h o i s a w h i t e m a n w i t h y e l l o w h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s p l a y i n g t h e d r u m w h i c h i s m a d e o f y e l l o w w o o d', 'a w o m a n w i t h y e l l o w h a i r i s s t a n d i n g o n t h e b l a c k m e t a l e l l i p t i c a l m a c h i n e', 't h e r e i s a b r o w n r u b b e r s n e a k e r o n t h e t a b l e a n d t h e t a b l e i t s e l f i s m a d e o f b l u e w o o d', 'p h o t o s o f v a r i o u s p e o p l e r i d i n g h o r s e s a r e s h o w n w o m a n i s r i d i n g a h o r s e i n a r i d i n g t r a c k a g i r l i s j u m p i n g i n t h e t r a c k s t o o']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h a s f a i r s k i n a n d y e l l o w h a i r a n d s h e i s a g i r l t h e u p p e r _ c l o t h e s _ c o l o r i s b l a c k a f t e r a w h i l e h e r u p p e r _ c l o t h e s _ c o l o r i s r e d', 't h e r e i s a m a n w a l k i n g w i t h w h i t e s k i n a n d b r o w n h a i r', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o c o o k s i s s t a n d i n g n e a r t h e t r a n s p a r e n t w a t e r', 't h e p e r s o n s t a n d i n g i s a w o m a n w i t h b r o w n h a i r a n d b l a c k s k i n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r o n a w h i t e r u b b e r m a t', 'a m a n w i t h w h i t e s k i n a n d w h i t e h a i r i s s p e a k i n g', 't h e e q u i p m e n t i s b e i n g t o u c h e d b y a m a n w i t h w h i t e s k i n a n d b r o w n h a i r t h e e q u i p m e n t i t s e l f i s b l a c k', 't h e r e i s a p e r s o n w a l k i n g h e i s a w h i t e m a l e w i t h b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['s e v e r a l p e o p l e s t a n d o u t s i d e o f c a r s p e o p l e g e t i n a r i v e r o n t u b e s p e o p l e f l o a t n e a r a l a r g e b r i d g e t h e w a t e r g e t s a l i t t l e c h o p p y', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s s t a n d i n g', 't h e r e i s a b l a c k s k i n n e d b o y w a l k i n g w i t h b l a c k h a i r', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r w h o i s c u r r e n t l y s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e s c e n e o p e n s u p w i t h a c a r w a s h a n d a n d a d v e r t i s e m e n t t w o m e n a r e m e s s i n g a r o u n d w h i l e c l e a n i n g t h e c a r a s i g n s h o w s t h e s e r v i c e s t h e y o f f e r', 't h e r e i s a m a n s i t t i n g w h o i s a w h i t e s k i n n e d r e f e r e e w i t h b r o w n h a i r', 't h e r e i s a m a n w h o i s w a l k i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r l y i n g o n t h e y e l l o w f l o o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e d o g i s b e i n g l e d b y a y e l l o w n y l o n l e a s h', 'a m a n e x p l a i n s w h i l e s t a n d s o n a f e n c e d c o u r t', 'm a n i s s t a n d i n g o n s i d e o f t h e b a r n', 't h e p e r s o n s t a n d i n g i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d b o y w i t h b r o w n h a i r i s s i t t i n g', 's e v e r a l p e o p l e a r e o u t d o o r s e n j o y i n g t h e b e a c h', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a w r e s t l e r o n t h e w h i t e l i n e n a r e n a', 'a p e r s o n w i t h f a i r s k i n a n d b r o w n h a i r w h o i s a g i r l t h e h a i r _ l e n g t h i s l o n g a f t e r a w h i l e h e r h a i r _ l e n g t h i s s h o r t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s p e a k i n g i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r', 'a h a n d i s s h o w n f l i p p i n g a s w i t c h t h e h o s e o f a l e a f b l o w e r i s s h o w n t h e h o s e b e g i n s f o r c e f u l l y b l o w i n g l e a v e s a w a y f r o m t h e c a m e r a', 't h e p e r s o n p l a y i n g t h e b o w l i n g b a l l i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r w h i l e t h e b o w l i n g b a l l i t s e l f i s m a d e o f g r e e n r u b b e r', 'a w o m a n w i t h w h i t e s k i n i s m a k i n g a b l a c k c l o t h s c a r f']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s h o l d i n g a w i n e g l a s s a n d t a l k i n g t h e p e r s o n s h o w s b o t t l e s t h a t a r e s i t t i n g o n a c o u n t e r t h e p e r s o n p o u r s o i l i n t o a p a n o n a s t o v e t h e p e r s o n a d d s s e a s o n i n g s t o t h e p a n t h e p e r s o n s t i r s a p o t t h a t i s o n t h e s t o v e t h e p e r s o n p i c k s u p h i s w i n e g l a s s a g a i n', 'p e r s o n 1 a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i s r u n n i n g w h i l e p e r s o n 2 a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g', 'a f i r e t h e c o l o r i s y e l l o w a f t e r a w h i l e i t s c o l o r i s b l u e', 't h e r e i s a m a n w i t h w h i t e s k i n b o a t i n g o n t h e g r a y w a t e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d r e d h a i r w h o i s a v i o l i n t e a c h e r i s p e r f o r m i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r o n t h e g r e e n f i e l d w h o i s a c o n t e s t a n t', 't h e r e i s a g r e e n h e d g e n e a r a n o l d m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n h o l d i n g t h e h a m m e r i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d t h e h a m m e r i t s e l f i s m a d e o f s i l v e r m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c o l o r o f t h e s i d e w a l k i s g r a y', 't h e r e i s a t i t l e s c r e e n f a d e i n a n d o u t a m a n a n d a d o g w a l k i n a t r a i n i n g r o o m t h e m a n t h r o w s f r i s b e e s f o r t h e d o g t o c a t c h t h e d o g j u m p s i n t o t h e m a n s a r m s t h e r e i s t h e e n d i n g t i t l e s c r e e n', 'p e r s o n 1 a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r p e r s o n 2 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a m a n p e r f o r m e r i s s t a n d i n g o n t h e b l a c k a r e a']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g w h o h a p p e n s t o b e a b a l l p l a y e r', 't h e s t r e e t i s g r a y', 't h e r e i s a m a n w e a r i n g a w h i t e r u b b e r s u i t w i t h y e l l o w s k i n s l i d i n g o n i t', 'a w o m a n w i t h w h i t e s k i n a n d g o l d h a i r w h o i s a b a r t e n d e r i s t o u c h i n g t h e b l a c k c o u n t e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h a n d w h i c h i s w h i t e b e l o n g s t o a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r', 'm e t a l i s t y p i c a l l y w h i t e', 't h e r e i s a b r o w n r o o m a n d a w h i t e f o o t', 't h e r e i s a t i t l e c a r d w i t h a f a m i l y o n i t a m a n s w i n g s a r o u n d o n a p o m m e l h o r s e t h e m a n i n r e d s h o r t s i s s p i n n i n g w i l d l y t h e p e r s o n s p i n s o n a r o u n d d e v i c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i n g l a s s e s s p e a k s t o t h e c a m e r a', 't h e p e r s o n s t a n d i n g i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n h i t t i n g t h e p i ñ a t a i s a m a n w i t h y e l l o w s k i n a n d b r o w n h a i r a n d t h e p i ñ a t a i t s e l f i s b l u e', 'a m a n i s s i t t i n g d o w n p l a y i n g a s a x o p h o n e t h e p e r s o n e s t o p s p l a y i n g t h e s a x o p h o n e a n d t a l k s t h e p e r s o n s t a n d s u p a n d c o n t i n u e s p l a y i n g t h e s a x o p h o n e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g r o u p o f f o u r b o y s a r e a t a t a b l e', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s h o l d i n g a g r e y m e t a l s h o t', 't h e w o r k e r w i t h f a i r s k i n a n d b l o n d h a i r i s p u s h i n g a r e d m e t a l m o w e r a f t e r s o m e t i m e h e s t a r t s w a l k i n g o n t h e g r e e n g r a s s', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g w h o i s a p e r f o r m e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['w h o i s t h e c h i l d s l i d e r t h e p e r s o n s k i i n g', 't h e s h o e i s b l u e i n c o l o r', 't h e p e r s o n s p e a k i n g i s a m a n w i t h b l a c k h a i r w h o h a s w h i t e s k i n', 'p e r s o n 1 a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g n e a r p e r s o n 2 a n o t h e r g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['s n o w i s w h i t e', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s h o l d i n g a y e l l o w d o g', 't h e r a g i s p i n k', 'p e r s o n 1 a c a u c a s i a n s u m o w r e s t l e r w i t h b r o w n h a i r i s e n g a g e d i n a f i g h t w i t h p e r s o n 2 a n o t h e r c a u c a s i a n s u m o w r e s t l e r s p o r t i n g b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b r o w n d o u g h o n a p l a t e m a d e o f s i l v e r m e t a l', 'a w o m a n p a i n t s a s q u a r e f r a m e w i t h l e g s t h e p e r s o n t u r n s t h e o b j e c t a n d p a i n t s a n o t h e r s i d e t h e c a m e r a p a n s t o f l o w e r s', 'a n i c e c r e a m i s o n t h e t a b l e w i t h t h e i c e c r e a m b e i n g r e d a n d t h e t a b l e b e i n g m a d e o f y e l l o w w o o d', 't h e b l u e t r a i l i s s i t u a t e d b e s i d e t h e w h i t e w a t e r f a l l w i t h t h e t r a i l d i r e c t l y t o u c h i n g t h e w a t e r f a l l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r i v e r i s w h i t e a n d f l o w i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i n t h e b r o w n c o u r t a s a c o n t e s t a n t', 't h e r e i s a y e l l o w c l o c k r u n n i n g', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g o n t h e g r e e n g r a s s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a t r a n s p a r e n t p h o n e i n s i d e a b l a c k c a r', 'a m a n i s s h o w n h o l d i n g u p a l a r g e s i l v e r a w a r d', 't h e r e i s t h e o p e n i n g o f t h e v i d e o', 't h e c u s t o m e r w a l k i n g i n i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n a d u l t w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a m u s i c i a n i s s i t t i n g', 't h e r e i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r s t a n d i n g', 't h e p e r s o n r i d i n g h a s f a i r s k i n a n d b l a c k h a i r', 't h e p e r s o n w h o i s e x e r c i s i n g i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d h e i s a s p o r t s m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g o n t h e w h i t e h i l l', 'a p e r s o n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a s i l v e r m e t a l f l a m e t h r o w e r w h i c h s p i t s y e l l o w f i r e', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i n t h e g r e e n f o r e s t', 't h e r e i s a p e r s o n i n t h e w a t e r a n d t h e p e r s o n i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r t h e w a t e r i n w h i c h s h e i s i m m e r s e d i s t r a n s p a r e n t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k l e a t h e r s h o e i s o n a t a b l e m a d e o f w h i t e w o o d', 't h e p e r s o n s t a n d i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d h e i s a b a l l p l a y e r', 'p e r s o n 1 a m a l e c o n t e s t a n t w i t h y e l l o w s k i n a n d b l a c k h a i r i s e n g a g e d i n a f i g h t w i t h p e r s o n 2 a m a l e s p o r t s m a n w h o a l s o h a s y e l l o w s k i n a n d b l a c k h a i r', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s l y i n g o n t h e g r e e n g r o u n d w h i l e p e r s o n 2 a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s p i t t i n g o u t y e l l o w b e e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n p u s h i n g t h e m o w e r i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r w h i l e t h e m o w e r i t s e l f i s m a d e o f g r e e n m e t a l', 'a c o n t e s t a n t w i t h w h i t e s k i n i s o n t h e w h i t e h i l l', 't h e r e i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a s p o r t s m a n s t a n d i n g', 'a p u m p k i n i s a g l o w i n g o b j e c t t h a t i s o r a n g e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i n a h a t t a l k s a t a p r e s s c o n f e r e n c e t h e r e a r e c a b i n s a n d t r a i l e r s i n a s n o w y a r e a t h e r e a r e m e n s k i i n g t w o m e n p o s e h o l d i n g r i f l e s i n t h e s n o w', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s p u l l i n g a w h i t e c a m e l', 'p e r s o n 1 a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 a n e l d e r l y w h i t e s k i n n e d m a n w i t h w h i t e h a i r w h o h a p p e n s t o b e a v i o l i n t e a c h e r', 't h e c a m e r a t h e n p a n s o u t t o s h o w t h e a u d i e n c e t h e s y m p h o n y c o n t i n u e s t o p l a y a s t h e c o n d u c t o r l e a d s t h e v i d e o e n d s s h o w i n g t h e e n t i r e s y m p h o n y']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a p e r s o n w h o b e i n g a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s p o i n t i n g a t a b r o w n w o o d e n t a b l e', 't h e r e i s a w o m a n s t a n d i n g w i t h w h i t e s k i n a n d b r o w n h a i r', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a s p o r t s m a n i s s i t t i n g o n t h e r e d p l a s t i c t r a c k', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a c o n t e s t a n t i s r u n n i n g o n t h e g r e y b r i d g e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['i s a b e a u t i f u l s p a c e w h e r e o n e c a n e n j o y n a t u r e r e l a x a n d u n w i n d t h e c o l o r i s r e d a f t e r a w h i l e i t s c o l o r i s g r e e n', 't h e p e r s o n w h o i s r i d i n g h a s w h i t e s k i n a n d b l a c k h a i r a n d t h e y a r e a c h i l d', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g n e a r p e r s o n 2 a n o t h e r m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e o p p o n e n t s e r v e s t h e b a l l t h e b a l l g o e s o u t o f b o u n d s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s i t t i n g', 't h e p e r s o n w a l k i n g i s a w o m a n w i t h f a i r s k i n a n d b r o w n h a i r', 't h e p e r s o n b o w i n g i s a m a r t i a l a r t i s t w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e c o n t e s t a n t i s a m a n w i t h d a r k h a i r a n d f a i r s k i n a n d h e i s c u r r e n t l y k n e e l i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s s t a n d i n g w h o i s a n i n s t r u c t o r', 't h e r e i s a m a n s p e a k i n g c h a r a c t e r i z e d b y h i s w h i t e s k i n a n d b l a c k h a i r h e i s a n a c t o r', 't h e p e r s o n o p e n i n g t h e m o u s e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n c o o k i n g i s a n e l d e r l y w o m a n w i t h w h i t e s k i n a n d w h i t e h a i r a n d s h e i s s m i l i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n r i d i n g t h e c r o s s c o u n t r y d r i v e r i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r', 'a w o m a n w i t h w h i t e s k i n a n d w h i t e h a i r i s t h e o n e s p e a k i n g', 'a w h i t e s k i n n e d m a n i s d r a w i n g o n a w h i t e p i e c e o f p a p e r', 'a m a n w i t h w h i t e s k i n i s s t a n d i n g o n t h e g r o u n d w h i c h i s c o v e r e d i n w h i t e i c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a c a r t h a t i s r u n n i n g h a s b l a c k r u b b e r', 't h e p e r s o n w h o i s w o r k i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n s t a n d i n g i s a w o m a n w h o h a s f a i r s k i n a n d b l a c k h a i r', 't h e r e i s a b l a c k t r e a d m i l l i n t h e r o o m a n d t h e r o o m i t s e l f i s y e l l o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a g i r l i n t h e t r a n s p a r e n t p o o l w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a b o y w i t h w h i t e s k i n a n d y e l l o w h a i r s t a n d i n g', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h g o l d e n h a i r i s p a r t i c i p a t i n g i n s p o r t s a s a j a v e l i n t h r o w e r u s i n g a s i l v e r m e t a l j a v e l i n e v e n t u a l l y p e r s o n 2 a m a n w i t h b l a c k h a i r s t a n d s o n t h e g r e e n f i e l d', 't h e s c u b a d i v e r s m a k e h a n d g e s t u r e s a n d j o k e t h e m e n s w i m u p c l o s e i n t o v i e w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s p e a k i n g', 't h e p e r s o n c o o k i n g i s a w o m a n w i t h w h i t e s k i n', 't h e m a n b e g i n s s p i n n i n g h i s b o d y q u i c k l y i n c i r c l e s', 't h e p e r s o n d e s c r i b e d i s a w h i t e s k i n n e d m a l e s p o r t s m a n w i t h b r o w n h a i r t h e h e a d w e a r _ c o l o r i s b r o w n a f t e r a w h i l e h i s h e a d w e a r _ c o l o r i s g r e e n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s p l a y i n g t h e b l a c k w o o d e n p i a n o', 'a g r e e n c a n o e i s l e a d i n g a n o t h e r c a n o e b o t h o f w h i c h a r e g r e e n', 't h e p e r s o n b o w i n g h a s w h i t e s k i n a n d b r o w n h a i r', 'a f e m a l e s p o r t s m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s w a l k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d r e d h a i r i s s p e a k i n g w i t h p e r s o n 2 a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a p e r s o n s i t t i n g w h o i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a p e r s o n i s e x e r c i s i n g o n a h a r d w o o d f l o o r i n t h e g y m a p e r s o n c o n t i n u e s d o i n g h e r s t o m a c h c r u n c h e s', 'a g y m n a s t p r e p a r e s t o m o u n t a b e a m t h e p e r s o n m o u n t s t h e n p r o c e e d s t o d o m a n y f l i p s a n d h a n d s p r i n g s t h e p e r s o n f i n i s h e s a n d d i s m o u n t s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n s t a n d i n g w h o h a s w h i t e s k i n a n d y e l l o w h a i r', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a b a l l p l a y e r r u n n i n g', 't h e e l l i p t i c a l m a c h i n e w h i c h i s m a d e o f b l a c k m e t a l i s c u r r e n t l y i d l e', 't h e c o l o r o f c r e a m i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h o l d i n g t h e y e l l o w f o o d i s a c u s t o m e r w i t h w h i t e s k i n', 't h e m a n s p r a y i n g s p r a y s u p a n d d o w n m a k i n g g o o d t i m e', 'a w h i t e p l a s t i c h o o p i s r o t a t i n g', 't h e r e i s a m a n d e c o r a t i n g a c h r i s t m a s t r e e t h e m a n a d d s a s t r i n g o f l i g h t s a l i t t l e g i r l a d s b u l b s t o t h e t r e e t h e m a n t u r n s t h e l i g h t s o n t h e m a n a n d t h e g i r l a d d b u l b s t o t h e t r e e t h e l a d y g o e s u p a n d o w n t h e s t a i r s t h e l a d y a d d s o r n a m e n t s t o t h e t r e e t h e m a n s t a n d s o n a l a d d e r a n d a d d s o r n a m e n t s t h e m a n a n d w o m a n k i s s e a c h o t h e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s p e a k i n g w i t h p e r s o n 2 a b o y w h o a l s o h a s w h i t e s k i n a n d b l a c k h a i r p e r s o n 1 i s a n i n s t r u c t o r w h i l e p e r s o n 2 i s a s t u d e n t', 't h e r e i s a t r e e m a d e o f g r e e n w o o d n e a r t h e b l u e s k y', 't h e p e r s o n g r a b s a b r u s h a n d c l e a n s a w i n d o w', 'p e r s o n 1 a b l a c k s k i n n e d s p o r t s m a n w h o i s a m a n i s e n g a g e d i n a f i g h t w i t h p e r s o n 2 a n o t h e r b l a c k s k i n n e d m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['m e n w e a r i n g b l a c k u n i f o r m s a r e s t a n d i n g b e h i n d t h e c h e e r t e a m', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s s t a n d i n g w h o h a p p e n s t o b e t h e r e f e r e e', 'a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r i s t o u c h i n g a b l a c k d o g', 't h e r e i s a m a n s t a n d i n g w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w i t h y e l l o w s k i n w h o h a s b l a c k h a i r i s c u r r e n t l y s i t t i n g', 'a g r e e n t r e e i s t o u c h i n g a g r e e n l a k e a n d a f t e r a w h i l e a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s t o u c h i n g a r e d n y l o n r o p e', 'p e r s o n 1 w h o i s a c h i l d s p o r t s m a n w i t h y e l l o w s k i n i s i n v o l v e d i n a c o n f l i c t w i t h p e r s o n 2 w h o i s a l s o a c h i l d s p o r t s m a n w i t h y e l l o w s k i n', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a b a r b e r i s h o l d i n g a b l a c k p r o d u c t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e i n d i v i d u a l i s a m a n', 't h e p e r s o n h o l d i n g t h e a x e i s a w h i t e m a n w i t h b r o w n h a i r a n d t h e a x e i t s e l f i s r e d', 't h e p e r s o n b o w i n g i s a w o m a n w i t h b l a c k s k i n', 'p e r s o n 1 a c h i l d w i t h y e l l o w s k i n a n d b l a c k h a i r i s w a l k i n g w h i l e p e r s o n 2 a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a n a d u l t w h i t e s k i n n e d p e r s o n s t a n d i n g w h o i s a m u s i c i a n w i t h b l a c k h a i r', 'a b l a c k h a i r e d s p o r t s m a n i s e x e r c i s i n g', 'b o y s a r m w r e s t l e i n a m a t c h f o r a l a r g e c r o w d t h e c r o w d c o n g r a t u l a t e s t h e w i n n e r t h e t w o b o y s s h a k e h a n d s', 'a m e a s u r i n g t a p e i s s h o w n u p c l o s e a t r a c k p e r s o n p r e p a r i n g t o r u n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a t r a n s p a r e n t p l a s t i c b o t t l e', 't h e r e i s a b l a c k m e t a l b o w n e a r a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e a r e a m a n f a l l i n t h e w a t e r i n r e v e r s e t h e r e a r e a s e r i e s o f f a l l s t h e m a n s i t s u p a n d s m i l e s', 't h e p e r s o n e x e r c i s i n g i s a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n i s s e a t e d', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s e x e r c i s i n g', 'p e r s o n 1 a m a n w i t h w h i t e s k i n b l a c k h a i r a n d a p o l i c e o f f i c e r i s s t a n d i n g c l o s e t o p e r s o n 2 a n e l d e r l y m a n w i t h w h i t e s k i n a n d g r e y h a i r', 't h e r e i s a m a n w h o i s s p e a k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g w h o i s a n i n s t r u c t o r', 'p e r s o n 1 a b o y w i t h b l a c k s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r b o t h o f w h o m a r e p e r f o r m e r s', 't h e p e r s o n w i t h b l a c k h a i r i s a m a n w i t h b l a c k s k i n a n d h e i s c u r r e n t l y s i t t i n g', 't h e b i k e w h i c h i s b l a c k i s m a d e o f m e t a l a n d i s p a r k e d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b i k e i s i d l e a n d m a d e o f m e t a l w i t h a g r e y c o l o r', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i n a c o u r t m a d e o f o r a n g e w o o d', 't h e r e i s a w h i t e f o o t o n t h e t r a n s p a r e n t r i v e r', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s c l i m b i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n o l d m a n w i t h w h i t e s k i n i s h o l d i n g a s i l v e r m e t a l h a r m o n i c a', 't h e r e i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r o n a w h i t e w a t e r', 'a n e l d e r l y m a n w i t h w h i t e h a i r a n d f a i r s k i n i s s t a n d i n g o n a g r e y s t r e e t a f t e r s o m e t i m e a r e p o r t e r w i t h b l a c k h a i r a n d f a i r s k i n p e r s o n 2 a p p e a r s h o l d i n g a b l a c k m e t a l c a m e r a', 'a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n r u n n i n g i s a m a n w i t h b l a c k h a i r w h o h a s a w h i t e c o m p l e x i o n', 't h e p e r s o n w h o i s a b l a c k s k i n n e d w o m a n w i t h b l a c k h a i r i s a s p o r t s w o m a n w h o i s c u r r e n t l y e x e r c i s i n g', 't h e f a c e o f a w h i t e s k i n n e d m a n w i t h g r e y h a i r i s a n i n t e g r a l p a r t o f h i s o v e r a l l a p p e a r a n c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k m e t a l t e l e v i s i o n i s c u r r e n t l y o n', 'p e r s o n 1 w h o i s a w o m a n w i t h w h i t e s k i n a n d g o l d h a i r i s s t a n d i n g w h i l e p e r s o n 2 w h o i s a l s o a w o m a n w i t h w h i t e s k i n a n d g o l d h a i r i s s i t t i n g', 't h e p e r s o n s t a n d i n g i s a w o m a n w i t h f a i r s k i n a n d g o l d e n h a i r', 't h e p o o l a p p e a r s b l u e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r w h o i s a r e p o r t e r i s e a t i n g t h e b r o w n b r a n f l a k e', 't h e p e r s o n s i t t i n g i n t h e a u d i e n c e i s a w h i t e s k i n n e d m a n', 't h e c o l o r o f a l e m o n i s y e l l o w', 't h e r e i s a b o y w a l k i n g w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w e a r i n g t h e s w e a t e r i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d t h e s w e a t e r i t s e l f i s b l a c k', 'a w o m a n w i t h y e l l o w s k i n i s t o u c h i n g a w h i t e d o g', 't h e p e r s o n i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h o i s a s p o r t s m a n a n d c u r r e n t l y s q u a t t i n g', 'k i d s a r e s i t t i n g i n b u m p e r c a r s t h e p e o p l e b e g i n c r a s h i n g i n t o e a c h o t h e r t h e p e o p l e s t o p a n d s t a r t g e t t i n g o u t o f t h e i r c a r s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a d r u m t h a t i s s i l v e r i n c o l o r a n d a n o t h e r d r u m t h a t i s b l a c k i n c o l o r', 't h e p e r s o n e x e r c i s i n g h a s w h i t e s k i n a n d b l a c k h a i r', 'a p e r s o n w i t h y e l l o w s k i n a n d b l a c k h a i r i s e x e r c i s i n g', 'a w h i t e s k i n n e d m a n i s h o l d i n g a w h i t e g l a s s b o t t l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g i r l i s s t a n d i n g o n t o p o f a b a l a n c e b e a m t h e p e r s o n d o e s f o r w a r d f l i p s o n t h e b e a m', 't h e r e i s a m a n w h o i s a w h i t e s k i n n e d i n s t r u c t o r s t a n d i n g', 'a b l a c k h a i r e d s p o r t s m a n w i t h b l a c k s k i n i s j u m p i n g i n t o t h e y e l l o w p i t', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p e r f o r m i n g w i t h a b a n d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a c a r p e t t h e c o l o r i s g r e y a f t e r a w h i l e i t s c o l o r i s g r e e n', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s t o u c h i n g t h e w h i t e s h a m p o o', 't h e r e i s a m a n s i t t i n g w h o h a s w h i t e s k i n a n d w h i t e h a i r', 't h e p e r s o n h o l d i n g t h e b a s k e t b a l l i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h i l e t h e b a s k e t b a l l i t s e l f i s m a d e o f o r a n g e r u b b e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a l a r g e c r o w d s i t s i n a t h e a t e r c l a p p i n g a n d w a t c h i n g t w o w o m e n a r e s e e n o n s t a g e d a n c i n g', 't h e t o n g u e w h i c h i s r e d i s a p a r t o f t h e p e r s o n w h o i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w h o i s a c o n t e s t a n t i s h o l d i n g t h e b l a c k m e t a l d i s c u s', 'a w h i t e s k i n n e d b o y w i t h b r o w n h a i r i s h o l d i n g a w h i t e p o l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h b l a c k h a i r a n d b l a c k s k i n i s s i t t i n g o n t h e g r e y m e t a l e x e r c i s e m a c h i n e', 't h e r e i s a g r e y p o n d n e a r b y a s w e l l a s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a w h i t e s k i n n e d m a n w i t h g o l d h a i r s t a n d i n g', 't h e r e i s a b o y w i t h w h i t e s k i n s t a n d i n g o n t h e w h i t e i c y s n o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h o l d i n g t h e s t i c k i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r a n d t h e s t i c k i t s e l f i s m a d e o f b l a c k p l a s t i c', 'p e r s o n 1 a m a n w i t h w h i t e s k i n i s n e a r p e r s o n 2 a l s o a m a n w i t h w h i t e s k i n', 'a b r o w n l a n d i s l o c a t e d c l o s e t o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s w e a r i n g a b o a t e r h a t', 'a w o m a n w i t h f a i r s k i n a n d w h i t e h a i r i s s i t t i n g o n a w h i t e l e a t h e r s o f a a f t e r s o m e t i m e a n o t h e r w o m a n w i t h f a i r s k i n d r i v e s a b l a c k m e t a l b o a t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s s t a n d i n g i n f r o n t o f a w h i t e s c r e e n t h e p e r s o n d e m o n s t r a t e s h o w t o p l a y t h e i n s t r u m e n t', 'o n t h e b r o w n w o o d e n f l o o r s t a n d s a w h i t e d o g', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s i t t i n g', 't h e p e r s o n s t a n d i n g i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a n i t e m o n t h e y e l l o w w h i t e w o o d e n t a b l e a n d t h e i t e m i t s e l f i s b l u e w h i t e s i l v e r i n c o l o r', 't h e s l i d e i s c o m p o s e d o f a b l a c k m e t a l s t e p a n d a y e l l o w p l a s t i c s l i d e', 't h e p e r s o n s t a n d i n g i s a m a n w i t h f a i r s k i n a n d b l a c k h a i r w h o h a p p e n s t o b e a s u r f e r', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w a t e r t h a t i s f l o w i n g i s t r a n s p a r e n t', 't h e p e r s o n w h o h a s w h i t e s k i n a n d b r o w n h a i r i s t h r o w i n g a b l a c k m e t a l h a m m e r', 't h e p e r s o n t a l k s t o t h e c a m e r a a s t h e p e r s o n w o r k s b l a c k p o l i s h i s s h o w n d r i p p i n g o n t o t h e p e r s o n s l e g s', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b r o w n h a i r s t a n d s w h o i s a p e r f o r m e r', 't h e p e r s o n s t a n d i n g i s a b o y w i t h b r o w n h a i r a n d h e h a s a w h i t e c o m p l e x i o n', 't h e r e i s a b l a c k r u b b e r t u b e f l o a t i n g o n t h e t r a n s p a r e n t r i v e r', 'i n t h e p o o l i s a w h i t e s k i n n e d w o m a n w h o i s a s w i m m e r a n d t h e p o o l i s m a d e o f b l u e c e r a m i c']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a l s o a p e r f o r m e r', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s s p e a k i n g', 'a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i s c u t t i n g a y e l l o w p o t a t o', 't h e b o a r d i s o r a n g e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e s k i n n e d m a n w a l k i n g', 't h e c o n t e s t a n t w h o i s e x e r c i s i n g i s a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g o n t h e g r e e n f i e l d', 't h e p e r s o n t o u c h i n g t h e b i k e i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d t h e b i k e i t s e l f i s m a d e o f b l a c k m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a g i r l s i t t i n g s h e h a s w h i t e s k i n a n d b r o w n h a i r', 'p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s c o n v e r s i n g w i t h p e r s o n 2 a n o t h e r w o m a n w i t h w h i t e s k i n a n d g o l d h a i r w h o i s a l s o a p r e s e n t e r', 'a p e r s o n p o l i s h a s h o e w i t h a w r a p p e d f i n g e r', 't h e a r r o w i s b e i n g h e l d b y a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d i t i s m a d e o f b l a c k m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b e d i s p u r p l e i n c o l o r a n d t h e g u i t a r i s m a d e o f w o o d a n d h a s a r e d c o l o r', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r s t a n d i n g', 'a g i r l w i t h w h i t e s k i n a n d g o l d h a i r i s e x e r c i s i n g o n a s i l v e r e l l i p t i c a l m a c h i n e t h a t i s r u n n i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
[32m2023-10-19T20:04:10 | utils.basic_utils: [0mTrain Epoch: [0]  [ 400/2288]  eta: 0:26:30  lr: 0.000010  temperature: 0.0123  video-loss_ita: 1.3993  video-loss_itm: 0.6262  time: 0.7920  data: 0.0122  max mem: 7604 res mem: 7876
text in iter ['t h e r e i s a m a n i n t h e b l a c k g y m w h o h a s w h i t e s k i n a n d b l a c k h a i r', 'y o u n g m a n i s p l a y i n g t h e h a r m o n i c a m u s i c a l n o t e s a r e d i s p l a y e d o n s c r e e n w h i l e h a r m o n i c a p l a y s', 't h e m a n w i t h b l a c k h a i r c a r r i e s a g r e y w o o d e n b r i d g e', 'i n t h e r o o m t h e r e i s a p e r s o n w h o i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r w h i l e t h e r o o m i t s e l f i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s t a n d i n g i s a w o m a n w i t h w h i t e s k i n a n d r e d h a i r w h o w o r k s a s a c o o k', 'a p r e g n a n t w o m a n i s s l o w l y m o v i n g i n a r o o m t h e p e r s o n m o v e s s i d e t o s i d e a s s h e g o e s', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g o n a g r e e n f i e l d', 'a p e r s o n w i t h d a r k s k i n w h o i s a b o y t h e h e a d w e a r _ c o l o r i s r e d a f t e r a w h i l e h i s h e a d w e a r _ c o l o r i s b l a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n i s i d e n t i f i e d a s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i n w h i c h t h e h a i r i s a p a r t o f h e r', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g o n t h e g r e e n g r a s s', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t u a t e d c l o s e t o p e r s o n 2 a l s o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a c o n t e s t a n t', 't h e m a c h i n e i s s i l v e r i n c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e s l o p e a p p e a r s t o b e y e l l o w', 'a w o m a n w i t h f a i r s k i n a n d g o l d e n h a i r s t a n d s b e s i d e a f l o w i n g t r a n s p a r e n t w a t e r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a d a n c e r o n t h e b l a c k m e t a l s t a g e', 'p e r s o n 1 w h o i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s c u r r e n t l y e n g a g e d i n a d i s p u t e w i t h p e r s o n 2 w h o i s a l s o a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w o m a n i s w e a r i n g r e d p a n t s', 'o n t h e w h i t e h i l l t h e r e i s a b l a c k w o o d e n s n o w b o a r d', 't h e r e i s a p e r s o n s t a n d i n g w i t h y e l l o w s k i n', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d g o l d e n h a i r l y i n g o n t h e g r e y g r o u n d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a n a d u l t p e r s o n w i t h f a i r s k i n w h o i s c u r r e n t l y s i t t i n g', 't h e r e i s a w o m a n s i t t i n g w h o h a s w h i t e s k i n a n d y e l l o w h a i r', 't w o y o u n g b o y s p e r f o r m m a r t i a l a r t s d a n c e s a g r o u p o f b o y s a r o u n d p e o p l e w a t c h e s o n t h e p e r f o r m e r s r e t u r n t o t h e i r s e a t s', 't h e r o o m i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a g r e e n t r e e n e a r a m a n w h o h a s w h i t e s k i n a n d b r o w n h a i r', 'a c o u p l e o f w o m e n a r e s h o w n i n s i d e a g y m t h e p e r s o n d e m o n s t r a t e s d i f f e r e n t b a l l e t m o v e s a n d p o s i t i o n s', 't h e r e i s a m a n s p e a k i n g w h o h a s w h i t e s k i n', 'p e r s o n 1 a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g w h i l e p e r s o n 2 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a n i n s t r u c t o r i s e x e r c i s i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w e a r i n g t h e s h o e i s a w o m a n w i t h w h i t e s k i n b r o w n h a i r a n d s h e i s a d a n c e r t h e s h o e s h e i s w e a r i n g i s m a d e o f p i n k c l o t h', 'p e r s o n 1 w h o i s a b o y w i t h p a l e s k i n i s n e a r p e r s o n 2 w h o i s a c h i l d', 't h e r o o m i s w h i t e', 't h e p e r s o n w e a r i n g t h e s h i r t i s a w h i t e s k i n n e d m a n a n d t h e s h i r t i t s e l f i s m a d e o f g r e y c l o t h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a p e d e s t r i a n i s w a l k i n g d o w n t h e g r e y s t r e e t a f t e r a l i t t l e w h i l e p e r s o n 2 a n o t h e r p e d e s t r i a n i s s e e n w a l k i n g a g r e y d o g', 't h e m a n w h o i s w o r k i n g h a s w h i t e s k i n', 't h e r e i s a m a n s t a n d i n g w i t h y e l l o w s k i n a n d b l a c k h a i r', 'a m a n i s s e e n k n e e l i n g i n a g y m t h e p e r s o n l e a n s f o r w a r d s e v e r a l t i m e s t h e p e r s o n i s p e r f o r m i n g s l o w s t r e t c h i n g m o v e s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b r o w n w o o d e n p a d d l e i s t o u c h i n g t h e g r e e n w a t e r', 't h e r e i s a w h i t e r o p e n e a r t h e b l a c k m e t a l m o w e r', 'a l i t t l e g i r l u s e s a s w e e p e r t o h i t a d i s c t h e p e r s o n c o n t i n u e s p l a y i n g t h e g a m e u n s u r e h o w t o w i n', 't h e r e i s a m a n s t a n d i n g w h o h a s w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s j u m p i n g', 'a w h i t e s k i n n e d w o m a n w i t h g o l d h a i r w h o i s a s p o r t s e n t h u s i a s t i s h o l d i n g a s i l v e r m e t a l b a r', 't h e r e i s a y e l l o w p l a s t i c k i t e o n t h e g r e e n f i e l d', 'a m a n i s s m o k i n g a p i p e a n d b l o w i n g s m o k e r i n g s t h e m a n u s e s p r o f a n i t y a n d f l i p s t h e c a m e r a o f f']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s s i t t i n g a n d h e i s a w o r k e r', 't h e r e i s a m a n s t a n d i n g w h o h a s w h i t e s k i n b l a c k h a i r a n d w o r k s a s a c o o k', 'a n a d u l t w i t h w h i t e s k i n i s c o o k i n g', 't h e r e i s a m a n w i t h w h i t e s k i n w h o i s r u n n i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e l i g h t i n t h e w h i t e s t a d i u m', 'a b o y w i t h y e l l o w s k i n a n d b l a c k h a i r i s e x e r c i s i n g', 't h e p e r s o n h o l d i n g t h e f i r e i s a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r a n d t h e f i r e i t s e l f i s o r a n g e', 't h e r e i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i n t h e g r e e n y a r d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s j u m p i n g i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a w o m a n w i t h w h i t e s k i n s t a n d i n g', 'a t o d d l e r i s h o l d i n g a l e a f b l o w e r a t e e n i s r a k i n g t h e l a w n', 't h e s h e e t h o l d s a b r o w n d o u g h w h i l e t h e s h e e t i t s e l f i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d w h i t e h a i r i s p l a y i n g t h e b a g p i p e w h i c h i s m a d e o f b l a c k w o o d', 'a w o m a n w i t h w h i t e s k i n i s h o l d i n g a w h i t e c e r a m i c b o w l', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s r a i s i n g a b l a c k m e t a l b a r b e l l', 'a p l a s t i c b r u s h t h e c o l o r i s b l a c k a f t e r a w h i l e i t s c o l o r i s g r e e n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w a i s t i s a p a r t o f a w o m a n w h o h a s y e l l o w s k i n a n d b l a c k h a i r a n d w h o i s a l s o a s p o r t s m a n', 'a r o t a t i n g s a i l m a d e o f t r a n s p a r e n t p l a s t i c i s p r e s e n t', 'a b o y w i t h w h i t e s k i n a n d b l a c k h a i r i s w a l k i n g', 't h e s e n t e n c e c a n b e r e w r i t t e n a s p e r s o n 1 a c a u c a s i a n m a l e b a l l p l a y e r i s t o u c h i n g p e r s o n 2 a n o t h e r c a u c a s i a n m a l e b a l l p l a y e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w h i t e s k i n n e d b o y w i t h b r o w n h a i r i s s p e a k i n g w i t h p e r s o n 2 a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r', 't h e c l i m b e r i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s t r a n s p a r e n t v o d k a i n a g l a s s', 't h e m a n s c a t c h f i n a l l y r e a c h e s t h e s u r f a c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n r u n n i n g i s a g i r l w i t h y e l l o w h a i r', 'p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n b r o w n h a i r a n d a p h o t o g r a p h e r i s n e a r p e r s o n 2 w h o i s a m a n w i t h w h i t e s k i n b r o w n h a i r a n d a n i n s t r u c t o r', 't h e p e r s o n w h o i s j u m p i n g h a s w h i t e s k i n a n d b r o w n h a i r', 'a m e t a l b a r b e l l t h e c o l o r i s s i l v e r a f t e r a w h i l e i t s c o l o r i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n o n a h o r s e g o e s t h r o u g h a r o d e o f e n c e t h e p e r s o n d i s m o u n t s r o p i n g a n d t y i n g a c a l f', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g i n t h e a u d i e n c e', 't h e r e i s a p e r s o n i n t h e w h i t e h o u s e w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'p e r s o n 1 w h o i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d a l s o a s p o r t s m a n i s n e a r p e r s o n 2 a n o t h e r w h i t e s k i n n e d m a n w i t h b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h a s a w h i t e f a c e a n d t h e y a r e a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n s p e a k i n g i s a m a n w i t h w h i t e s k i n b r o w n h a i r a n d a p r o f e s s i o n o f b e i n g a b r i c k l a y e r', 't h e p r o t e c t i v e s u i t i s c o l o r e d b l u e', 't h e p e r s o n h o l d i n g t h e b a t o n i s a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r a n d t h e b a t o n i t s e l f i s m a d e o f w h i t e m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a d a n c e r t h e a c c e s s o r y i s s u n g l a s s e s a f t e r a w h i l e h e r a c c e s s o r y i s b r a c e l e t', 'a w h i t e s k i n n e d m a l e c o n t e s t a n t i s r i d i n g a b l u e m e t a l b i k e', 't h e w o m a n d e m o n s t r a t e s a s m a l l s c r u b b i n g p a d t o t h e c a m e r a t h e w o m a n u s e s t h e p a d o n t h e b a b y', 't h e r o p e w h i c h i s b l a c k i s n y l o n a n d i t i s c u r r e n t l y h a n g i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h i l l i s g r e e n', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s r i d i n g', 'a p e r s o n w h o i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s s t a n d i n g i n a g r e e n f i e l d', 'a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r i s s m o k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s p e a k i n g i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a p r e s e n t e r', 't h e r e i s a b l a c k h o r s e s t a n d i n g', 'a p e r s o n w h o h a s w h i t e s k i n a n d b r o w n h a i r i s s p e a k i n g a n d h e i s a b o y', 't h e s t o m a c h w h i c h i s b l a c k i s p a r t o f a p e r s o n w h o i s a g i r l w i t h b l a c k s k i n a n d b l a c k h a i r a c u s t o m e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r f o r m e r a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g o n a g r e y p i t', 't h e t a n k i n c l u d e s a t r a n s p a r e n t r u b b e r t u b e t h a t i s a l s o t r a n s p a r e n t', 'a y o u n g b o y l a u g h s w h i l e h o l d i n g t w o t o o t h b r u s h e s t h e p e r s o n u s e s a n e l e c t r i c b r u s h t o b r u s h h i s t e e t h', 't h e p e r s o n s t a n d i n g i s a w o m a n w i t h w h i t e s k i n a n d g o l d e n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s w a s h i n g a w h i t e c e r a m i c d i s h w h i l e w e a r i n g b l a c k l e a t h e r g l o v e s', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a s p o r t s m a n i s h o l d i n g t h e w h i t e m e t a l p o l e', 'a w o m a n w i t h w h i t e s k i n a n d g o l d h a i r i s i n t h e g r e e n y a r d', 'a m a n i n a r e d s h i r t i s k n e e l i n g d o w n p e o p l e a r e f i x i n g s o m e t h i n g o n a b i k e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n r u n n i n g i s a m a n a n d h e h a s w h i t e s k i n h e i s a l s o a s p o r t s m a n', 't h e r e i s a w h i t e s k i n n e d b o y s t a n d i n g w i t h b l a c k h a i r', 't w o m e n a r e p l a y i n g f o o s b a l l i n a d a r k r o o m p e o p l e c o m p e t e i n t e n s e l y a t a f a s t p a c e t h e m a n o f t h e r e d t e a m w i n s a l l f o u r t i m e s', 'a w h i t e s k i n n e d b o y w i t h b r o w n h a i r w h o i s d i s a b l e d i s s i t t i n g i n a b l a c k w h e e l c h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e l e g t h a t b e l o n g s t o t h e w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s a p a r t o f h e r b o d y', 't h e b e a u t y s a l o n i s p a i n t e d i n y e l l o w', 't h e r e i s a s p o r t s m a n w i t h b l a c k h a i r a n d b l a c k s k i n w h o i s c u r r e n t l y j u m p i n g', 't h e r e i s a p e r s o n i n t h e g r e e n r o o m w h o h a s w h i t e s k i n b r o w n h a i r a n d i s a d a n c e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k s k i n n e d m a n w i t h b l a c k h a i r i s p l a y i n g t h e p i a n o w h i c h i s m a d e o f b l a c k w o o d', 'p e r s o n 1 a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s i n g e r i s n e a r p e r s o n 2 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a d r u m m e r', 't h e h e a d b e l o n g s t o a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d i t i s b r o w n i n c o l o r', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s t o u c h i n g t h e w h i t e m e t a l b o a r d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s s l i d i n g d o w n a w h i t e h i l l', 'a b l a c k m e t a l r o w i n g m a c h i n e i s i n o p e r a t i o n', 'a b l a c k h a i r e d m a n w i t h a b l a c k c o m p l e x i o n i s h o l d i n g a r e d m e t a l b a r b e l l', 't h e o c e a n a p p e a r s b l u e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a b l a c k s k i n n e d m a n w i t h b l a c k h a i r a n d a b a c k g r o u n d i n s p o r t s i s e n g a g e d i n a c o n f l i c t w i t h p e r s o n 2 a w h i t e s k i n n e d w o m a n a l s o w i t h b l a c k h a i r a n d a s p o r t s b a c k g r o u n d', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s p e a k i n g a n d s h e i s a n a n n o u n c e r', 'a c l o s e u p o f a s t r a w b e r r y i s s h o w n a w o m a n i s t a l k i n g w i t h a n a r r a y o f w a t e r c o l o r s', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g n e a r p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n i s s t a n d i n g b e h i n d a c o u n t e r i n a k i t c h e n a p e r s o n t a k e s t h e l i d o f f o f a p o t o f s a l a d a p e r s o n m o v e s t h e s a l a d i n t o a n e w b o w l a p e r s o n t a k e s t h e t o w e l a n d p u t s i t o v e r t h e l e t t u c e a p e r s o n t o s s e s t h e s a l a d w i t h t w o s p o o n s', 't h e r e i s a m a n w i t h w h i t e s k i n a n d w h i t e h a i r s t a n d i n g o n a w h i t e m e t a l b o a t w h o h a p p e n s t o b e a d i v e r', 'o n t h e g r e e n g r a s s t h e r e l i e s a r e d m e t a l k e t t l e b e l l', 't h e s w i m m e r w i t h w h i t e s k i n i s a m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a g r e e n c u c u m b e r i s i n a y e l l o w c o c k t a i l', 'a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s h o l d i n g a w h i t e w o o d e n b r u s h s h e i s a p a i n t e r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a s u r f e r i s r u n n i n g o n t h e y e l l o w b e a c h', 't h e r e i s a s e c u r i t y g u a r d s i t t i n g w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s s p e a k i n g', 'a p e r s o n w h o i s a m a n w i t h w h i t e s k i n a n d g o l d h a i r i s d r i v i n g t h e w h i t e b o a t', 't h e w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s t o u c h i n g t h e b l a c k b r a i d', 't h e w o m a n r e t r i e v e s a n e w b a l l t h e w o m a n r e t r i e v e s t w o b a l l s t h e n g e t s r i d o f o n e t h e w o m a n r e t r i e v e s a n o t h e r b a l l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h b l a c k h a i r i s s l i d i n g d o w n t h e g r e e n p l a s t i c s l i d e a n d l a t e r s h e i s s e e n t o u c h i n g a b r o w n d o g', 'p e o p l e p l a y f o r a n e x t e n d e d p e r i o d t o g e t h e r', 't h e p e r s o n e x e r c i s i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o h a p p e n s t o b e a s u r f e r', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s e n g a g e d i n a c o n f l i c t w i t h p e r s o n 2 a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o i s a w o m a n w i t h f a i r s k i n i s p l a y i n g t h e w h i t e m e t a l d r u m f o l l o w i n g p e r s o n 2 a m a l e d r u m m e r w i t h f a i r s k i n w h o w a s p l a y i n g t h e y e l l o w w o o d e n d r u m', 'a p e r s o n w i t h w h i t e s k i n i s p l a y i n g a t a g r e e n t a b l e', 't h e p e r s o n r e p a i r i n g i s a w h i t e s k i n n e d m a n', 't h e r e i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a g r e e n b u s h n e a r t h e p e r s o n w h o i s a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r a n d i s a l s o t h e p r e s e n t e r', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a c o o k i s t o u c h i n g t h e w h i t e p l a s t i c b i n', 'a s i l v e r c a r c a n b e s e e n n e a r t h e w h i t e s n o w', 't h e b o w l w h i c h i s m a d e o f g l a s s i s t r a n s p a r e n t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e t r a c k i s m a d e o f b l u e p l a s t i c w h i l e t h e m a t i s m a d e o f b l u e r u b b e r', 'a w o m a n w i t h f a i r s k i n a n d b l a c k h a i r i s s t a n d i n g o n t h e g r a y s i d e w a l k', 't h e c o u r t i s c o l o r e d b r o w n', 't h e r e i s a w h i t e s k i n n e d m a n s l i d i n g o n a w h i t e r o a d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['o n t h e g r e y w o o d e n g a m b l i n g t a b l e l i e s a w h i t e c a r d', 'a w h i t e s k i n n e d m a n i s t o u c h i n g t h e y e l l o w r u b b e r w a t e r p o l o', 't h e m o u t h w h i c h i s r e d i s a p a r t o f t h e p e r s o n w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r s i t t i n g i n t h e a u d i e n c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s s m i l i n g h a s w h i t e s k i n a n d i s a m a n', 't h e r e i s a w o m a n s t a n d i n g w i t h w h i t e s k i n a n d b r o w n h a i r', 'w o m e n i n l e o t a r d s d a n c e t o g e t h e r i n a l i n e w o m e n j u m p i n t o t h e p o o l w o m e n s y n c h r o n i z e d a n c e i n t h e p o o l a n n o u n c e r s t a l k t o t h e c a m e r a m e n i s i n t h e s i d e o f p o o l t a l k m a n i n y e l l o w t a l k s t o t h e c a m e r a m a n i n p i n k l e o t a r d j u m p s o u t o f t h e p o o l', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g o n a b l a c k w o o d e n c a n o e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a s i l v e r m e t a l m i c r o p h o n e i s i n u s e', 'p e r s o n 1 w h o i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s i n c l o s e p r o x i m i t y t o p e r s o n 2 w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n w h o h a s w h i t e s k i n a n d y e l l o w h a i r p o s s e s s e s a w h i t e n a i l', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i n a w h i t e m e t a l b a t h r o o m']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d p e r s o n i s j u m p i n g i n t o a s n o w b a n k w h i c h i s a l s o w h i t e', 't h e p e r s o n s t a n d i n g i s a b o y w i t h g o l d h a i r a n d w h i t e s k i n', 't h e p e r s o n s t a n d i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n e x e r c i s i n g h a s w h i t e s k i n a n d b r o w n h a i r a n d h e i s a m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o i s a w h i t e s k i n n e d b l a c k h a i r e d s p o r t s m a n i s s t a n d i n g c l o s e t o p e r s o n 2 w h o s h a r e s t h e s a m e p h y s i c a l c h a r a c t e r i s t i c s a n d p r o f e s s i o n', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s u r f e r i s s i t t i n g o n t h e w h i t e b o a t', 't h e r e i s a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r s t a n d i n g i n t h e a u d i e n c e', 't h e r e i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r s t a n d i n g w h o i s a p r e s e n t e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w a l k i n g i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h a v i n g a c o n v e r s a t i o n w i t h p e r s o n 2 w h o a l s o h a p p e n s t o b e a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g a n d s h e i s a r e f e r e e', 'p e r s o n 1 w h o h a s y e l l o w s k i n a n d b l a c k t r a n s p a r e n t h a i r i s n e a r p e r s o n 2 w h o h a s b l a c k s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a w o r k e r i s w a l k i n g o n t h e g r e y c a r p e t', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r s t a n d i n g w h o i s a l s o a s p o r t s m a n', 't h e r e i s a b r o w n w o o d l o c a t e d n e a r a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n e x e r c i s i n g i s a w o m a n w i t h f a i r s k i n a n d y e l l o w h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a y e l l o w f l o w e r a n d a y e l l o w l e a f a r e s i t u a t e d c l o s e t o e a c h o t h e r', 't h e p e r s o n s t a n d i n g i s a m a n w i t h b r o w n h a i r a n d a f a i r c o m p l e x i o n', 't h e w o m a n w i t h w h i t e s k i n i s s t a n d i n g a n d s h e h a s b r o w n h a i r', 't h e p e r s o n w h o i s l y i n g h a s w h i t e s k i n a n d b r o w n h a i r a n d s h e i s a w o m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s c u r r e n t l y w a l k i n g', 't h e r e i s g r e e n f o o d o n t h e c o u n t e r a n d t h e c o u n t e r i s m a d e o f y e l l o w s t o n e', 'a g r a p h i c i s s e e n w i t h c a r t o o n s t h e y o u n g m a n d o e s t r i c k s o v e r a n o r a n g e s a f e t y c o n e', 'a p e r s o n w h o i s a g i r l w i t h b l a c k s k i n a n d b l a c k h a i r t h e h a i r _ s t y l e i s s t r a i g h t a f t e r a w h i l e h e r h a i r _ s t y l e i s c u r l y']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e d o g i s w a l k i n g o n a r o a d m a d e o f g r e y s t o n e', 't h e g r o u n d i s c o v e r e d i n w h i t e', 'p e r s o n 1 a w h i t e s k i n n e d w o m a n p a r t i c i p a n t i s e n g a g e d i n a c o n f l i c t w i t h p e r s o n 2 a n o t h e r w h i t e s k i n n e d w o m a n c o n t e s t a n t w i t h b l a c k h a i r', 'a w h i t e r u b b e r b a l l i s f l y i n g i n t e n n i s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e d o g t h a t i s j u m p i n g i s w h i t e', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s c l a p p i n g', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s b r u s h i n g a b l u e w o o d e n f e n c e a n d a f t e r a w h i l e a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s p a i n t i n g a b r o w n w o o d e n b e n c h', 't h e b o a r i s o f a b l a c k c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c a n d l e i s w h i t e', 't h e r e i s w h i t e p o w d e r o n t h e b l a c k w o o d e n b o a r d', 'i n t h e r o o m t h e c o l o r y e l l o w d o m i n a t e s a n d i n i t a h a n d i s v i s i b l e s p o r t i n g a w h i t e c o l o r', 't h e p e r s o n w h o i s b o w i n g h a s w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h f a i r s k i n a n d g o l d e n h a i r i s p l a y i n g w i t h p e r s o n 2 a n o t h e r m a n w i t h f a i r s k i n a n d b l a c k h a i r a f t e r w e a r i n g a b l a c k t s h i r t p e r s o n 2 j o i n s t h e i n t e r a c t i o n', 't h e g i r l w h o h a s w h i t e s k i n a n d y e l l o w h a i r i s a d a n c e r s h e i s h o l d i n g a y e l l o w p l a s t i c b a g a n d a f t e r a w h i l e s h e r a i s e s h e r f o o t w h i c h i s w h i t e', 't h e g l a s s e s a r e b e i n g w o r n b y a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r t h e g l a s s e s t h e m s e l v e s a r e b l a c k', 'a m a n w i t h b r o w n h a i r w h o i s a s p o r t s m a n i s h o l d i n g a g r e y m e t a l s h o t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s m o p p i n g a f l o o r a w o m a n i s e a t i n g', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a y e l l o w f i r e o n t h e b l a c k m e t a l w e l d m e n t', 'p e r s o n 1 a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 w h o a l s o h a s b l a c k s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n h a s a w h i t e b a c k a n d t h e y a r e a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a m a n i s r i d i n g a w a t e r m o t o r b o a t i n t h e o c e a n t h e r e i s a m a n o n a s u r f b o a r d', 't h e a d u l t b a r b e r i s b r a i d i n g h a i r', 't h e r e i s a p u r p l e w a l l n e a r a m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s s t a n d i n g o n a f i e l d t h e p e r s o n k i c k s a b a l l i n t o t h e a i r t h e p e r s o n r u n s t o f i r s t b a s e', 't h e w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a d a n c e r i s t o u c h i n g t h e s i l v e r m e t a l b a r', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g w h o i s a d a n c e r', 't h e r e i s a w o m a n s p e a k i n g s h e h a s w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a r u n n e r w i t h w h i t e s k i n a n d b l a c k h a i r i d e n t i f i e d a s a m a n i s s e e n r u n n i n g o n t h e y e l l o w s t r e e t', 't h e p e r s o n w h o i s l y i n g i s a n a d u l t w i t h w h i t e s k i n', 't h e r e i s a p e r s o n s t a n d i n g a n d h e h a s y e l l o w s k i n', 't h e r e i s a b l a c k w o o d s k i o n t h e w h i t e w o o d b e n c h']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n s t a n d i n g', 't h e c o m p u t e r i s b l a c k a n d i t i s c l o s e d', 't h e r e i s a w o m a n m u s i c i a n w i t h w h i t e s k i n a n d y e l l o w h a i r n e a r t h e b l a c k m e t a l p i a n o', 'a s w i m m e r w h o i s a w h i t e s k i n n e d b o y w i t h b r o w n h a i r i s i n t h e b l u e p o o l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a n w i t h b l a c k h a i r i s r u n n i n g', 'a b l a c k s k i n n e d i n d i v i d u a l t h e a c c e s s o r y i s h e a d s e t a f t e r a w h i l e h i s a c c e s s o r y i s g l o v e', 't h e r e a r e s p e c t a t o r s w a t c h i n g t h e p e r s o n a s t h e p e r s o n s w i n g s s w i f t l y t h e s c o r e b o a r d s h o w s t h e n a m e s o f a l l t h e w i n n e r s', 't h e p e r s o n h o l d i n g t h e s t i c k h a s a d a r k s k i n n e d m a n w i t h b l a c k h a i r a n d t h e s t i c k i t s e l f i s m a d e o f p i n k p l a s t i c']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n i s a b l a c k s k i n n e d w o m a n w i t h b l a c k h a i r w h o i s s p e a k i n g', 'a m a n w i t h w h i t e s k i n i s c o o k i n g', 'p e r s o n 1 a w h i t e s k i n n e d p h o t o g r a p h e r a n d m a n i s n e a r p e r s o n 2 a n o t h e r m a n', 't h e f a c e a p p e a r s t o b e y e l l o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s b o w i n g i s a y e l l o w s k i n n e d m a n w h o w o r k s', 't h e p e r s o n w a s h i n g c l o t h e s i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r a n d h e i s s p e a k i n g', 't h e p e r s o n h o l d i n g t h e s p o o n h a s w h i t e s k i n b r o w n h a i r a n d i s a g i r l t h e s p o o n i s m a d e o f s i l v e r m e t a l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s s t a n d i n g', 'a v o l l e y b a l l p l a y e r t h r o w s t h e b a l l i n t h e a i r t h e p e r s o n s t e a m m a t e c a t c h e s t h e o b j e c t a n d t h r o w s t h e o b j e c t o v e r t h e n e t t h e v o l l e y b a l l p l a y e r s e r v e s t h e b a l l a n o p p o s i n g p l a y e r d i v e s t o s p i k e t h e b a l l t h e p e r s o n s t e a m m a t e t h r o w s t h e b a l l o v e r t h e n e t a n o p p o s i n g p l a y e r h i t s t h e b a l l t h e p e r s o n s t e a m m a t e h i t s t h e o b j e c t b a c k a t h e r t h e t e a m m a t e s p i k e s t h e o b j e c t o v e r t h e n e t t h e o p p o s i n g p l a y e r h i t s t h e b a l l t h e o p p o s i n g p l a y e r h i t s t h e b a l l t o w a r d s t h e p e r s o n s t e a m m a t e t h e p e r s o n s t e a m m a t e h i t s t h e b a l l t h e p e r s o n s t e a m m a t e h i t s t h e b a l l o v e r t h e n e t a n o p p o s i n g p l a y e r d i v e s a n d h i t s t h e b a l l', 't h e r e i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i n t h e g r e e n y a r d', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a n a r c h i t e c t n e a r t h e b r o w n c e r a m i c t i l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h i l l i s w h i t e', 'a w o m a n w e a r i n g s c u b a d i v i n g g e a r i s u n d e r t h e w a t e r p e o p l e g i v e o k s i g n a l s t o t h e p e r s o n w i t h t h e c a m e r a', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s p e a k i n g', 't h e p e r s o n w h o i s b o w i n g i s a w h i t e s k i n n e d w o m a n w i t h g o l d e n h a i r w h o a l s o h a p p e n s t o b e a w o r k e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s s t a n d i n g o n a w h i t e w o o d e n s k a t e b o a r d', 't h e w o m a n w i t h w h i t e s k i n i s p a i n t i n g h e r n a i l s', 't h e p e r s o n h o l d i n g t h e k n i f e i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d t h e k n i f e i t s e l f i s s i l v e r i n c o l o r', 'p e o p l e w a t c h c o m p e t i t o r s g e t r e a d y n e a r a r e d s t a g e t h e j u d g e s i g n a l s t h e b e g i n n i n g o f t h e c o m p e t i t i o n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b i k e w h i c h i s r e d i s p a r k e d', 't h e h a m m e r i s m a d e o f m e t a l a n d h a s a s i l v e r c o l o r w h i l e t h e s k y h a s a b l u e c o l o r', 't h e c o l o r o f t h e p a p e r i s b l u e', 't h e p e r s o n e x e r c i s i n g h a s w h i t e s k i n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e m e t a l r e f r i g e r a t o r i s b e i n g o p e n e d', 't h e f i r s t p e r s o n a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d a s p o r t s m a n h o l d s a b l a c k p l a s t i c s t i c k a f t e r s o m e t i m e t h e s e c o n d p e r s o n a l s o a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d a s p o r t s m a n e m b r a c e s a t h i r d p e r s o n w h o i s a s p o r t s m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a b l u e p l a s t i c b i l l i a r d b a l l i s o n a w h i t e w o o d t a b l e', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r w h o i s a s p o r t s m a n i s t h r o w i n g a w h i t e m e t a l d i s c u s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e l e g i s a p a r t o f t h e p e r s o n s p e c i f i c a l l y a n a d u l t w i t h w h i t e s k i n', 't h e r e i s a w o m a n w i t h w h i t e s k i n b r o w n h a i r a n d s h e i s a t a t t o o a r t i s t s t a n d i n g', 't h e r e i s a p e r s o n s t a n d i n g a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'p e r s o n 1 a g i r l w i t h w h i t e s k i n b r o w n h a i r a n d a d a n c e r i s t o u c h i n g p e r s o n 2 w h o i s a l s o a g i r l w i t h w h i t e s k i n b r o w n h a i r a n d a d a n c e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s t a n d i n g i s a b o y w i t h b r o w n h a i r a n d w h i t e s k i n', 't h e p e r s o n w h o i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r h a s a w h i t e e a r', 't h e p e r s o n s i t t i n g i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a w h i t e s k i n n e d w o m a n w i t h g o l d e n h a i r i s s t a n d i n g b y t h e g r e e n r i v e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b e e r i n t h e b o t t l e i s y e l l o w a n d t h e b o t t l e i t s e l f i s m a d e o f b r o w n g l a s s', 't h e p e r s o n i s d o n e p l a y i n g l o o k s u p a n d s m i l e s', 't h e r e i s a g r e e n n e t n e a r t h e y e l l o w r u b b e r w a t e r p o l o b a l l', 't h e c a m p s i t e h a s a b r o w n c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n i s f a i r s k i n n e d w i t h b l a c k h a i r a n d i s c u r r e n t l y w o r k i n g a s a m a n', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i n t h e y e l l o w w o o d c o u r t', 't h e r e i s a b o y w i t h y e l l o w s k i n a n d b l a c k h a i r s t a n d i n g o n t h e b r o w n s t o n e f l o o r', 'a p e r s o n w i t h w h i t e s k i n a n d b l a c k h a i r i s p o u r i n g s o m e t h i n g i n t o a w h i t e c e r a m i c c u p']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w e a r i n g t h e s u m o o u t f i t i s a n e l d e r l y m a n w i t h w h i t e s k i n t h e s u m o o u t f i t i t s e l f i s m a d e o f b r o w n r u b b e r', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s r a i s i n g p e r s o n 2 a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n s p e a k i n g i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r', 't h e p r e s e n t e r a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w e a r i n g a b r o w n c l o t h s u i t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['i c e c r e a m i s u s u a l l y n o t y e l l o w', 't h e r e i s a w o m a n s t a n d i n g w h o i s a w h i t e s k i n n e d i n s t r u c t o r w i t h y e l l o w h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g w h o h a p p e n s t o b e a r e f e r e e', 't h e p e r s o n e x e r c i s i n g i s a b o y w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s i n g e r i s p l a y i n g a b l a c k g u i t a r', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d a s p o r t s m a n i s n e a r p e r s o n 2 a n o t h e r w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d a l s o a s p o r t s m a n', 'a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s p o r t s m a n i s p e r f o r m i n g', 't h e r e a r e t w o t r e e s n e a r b y o n e i s g r e e n a n d m a d e o f p l a s t i c a n d t h e o t h e r i s g o l d a n d m a d e o f p l a s t i c']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r h a s a f a c e t h a t i s a d i s t i n c t p a r t o f h e r', 't h e c a t i s b l a c k a n d i t i s l y i n g d o w n', 'b l u e t e x t t a l k s a b o u t t h e d e s c r i p t i o n o f t h e v i d e o o n e b o y c o n t i n u o u s l y d o e s l a y u p s u n t i l t h e e n d', 'a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s a l s o a m u s i c i a n i s s p e a k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h e a d i s a p a r t o f a p e r s o n w h i c h i n t h i s c a s e i s w h i t e t h e p e r s o n i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n b o w i n g h a s w h i t e s k i n a n d b r o w n h a i r i d e n t i f y i n g h i m a s a m a n', 'a m a n i s l o o k i n g d o w n a n d t a l k i n g i n t o t h e c a m e r a t h e m a n s h o w s t h e c o n t a c t l e n s t o t h e c a m e r a t h e m a n i n s e r t s t h e c o n t a c t a n d m o v e s h i s e y e a r o u n d t h e m a n s h o w s h i s o t h e r c o n t a c t', 't h e p e r s o n p l a y i n g f o o s b a l l i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d t h e f o o s b a l l t a b l e i s m a d e o f g r e e n w o o d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a n s t r o k e s h i s g o a t e e a n d e x a m i n e s t h e o b j e c t t h e m a n t r i m s h i s c h i n a r e a t o m a k e a m u s t a c h e', 'a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s w a l k i n g', 'a w h i t e h a n d i s g e n t l y t o u c h i n g t h e g o l d h a i r', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p o u r i n g s o m e t h i n g r e d i n t o t h e s a u c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n e w s w o m a n i s t a l k i n g i n a n e w s r o o m b u l l f i g h t e r s a r e s h o w n i n s i d e a r i n g p e o p l e a r e t r y i n g t o e n t i c e t h e b u l l w i t h c a p e s', 't h e p e r s o n h a s a f a c e w h i c h i s w h i t e a n d t h e y a r e a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a b r o w n w o o d e n b o a r d n e a r t h e w o m a n w i t h w h i t e s k i n a n d w h i t e h a i r', 'a m a n w i t h w h i t e s k i n i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a b l a c k b i k e o n t h e g r e y w a l k w a y', 't h e p e r s o n w h o i s a b o y w i t h w h i t e s k i n h a s b r o w n h a i r a n d i s c u r r e n t l y s t a n d i n g', 'a y e l l o w r u b b e r w a t e r p o l o i s f l o a t i n g', 'a p l a s t i c g e a r t h e c o l o r i s b l a c k a f t e r a w h i l e i t s c o l o r i s y e l l o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n a d u l t w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g i n t h e a u d i e n c e', 't h e r e i s a w h i t e s k i n n e d p e r s o n a n o l d w o m a n w i t h w h i t e h a i r s t a n d i n g', 't h e r e i s a b o y w i t h f a i r s k i n s t a n d i n g o n t h e w h i t e h i l l', 't h e r o a d h a s a g r a y c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a f e m a l e c o n t e s t a n t w i t h w h i t e s k i n a n d b r o w n h a i r i s e n g a g e d i n a c o n f l i c t w i t h p e r s o n 2 a n o t h e r f e m a l e c o n t e s t a n t w h o a l s o p o s s e s s e s w h i t e s k i n a n d b r o w n h a i r', 'a g r e e n c a r i s o n t h e g r e e n g r a s s', 't h e s k a t e b o a r d m a d e o f b l a c k w o o d i s s l i d i n g', 't h e r e i s a m a n w i t h b r o w n h a i r w h o h a s f a i r s k i n a n d h e i s b o w i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g o n t h e g r e y s t a g e d a n c i n g', 'a w h i t e s k i n n e d m a n i s s u r f i n g o n t h e w a t e r', 'a p i n k n a i l i s t o u c h i n g t h e w h i t e e y e a n d a f t e r a w h i l e a p e r s o n w i t h w h i t e s k i n a n d g o l d h a i r i s h o l d i n g a t r a n s p a r e n t c o n t a c t l e n s', 't h e c i g a r e t t e i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n s i t t i n g', 't h e p e r s o n j u m p i n g i s a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r w h o i s a l s o a s p o r t s m a n', 'a h o r s e i s o n e o f t h e m o s t m a g n i f i c e n t c r e a t u r e s i n t h e a n i m a l k i n g d o m t h e c o l o r i s b l a c k a f t e r a w h i l e i t s c o l o r i s w h i t e', 'p e o p l e a r e r i d i n g h o r s e s o n a f i e l d t h e h o r s e s a r e r u n n i n g a r o u n d o n t h e f i e l d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r w h o i s c a r r y i n g a b l a c k c l o t h b a g', 'a w h i t e s k i n n e d m a n i s w a l k i n g o n t h e g r e e n l a w n', 'a p e r s o n a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a b l u e m a c h i n e', 't h e r e i s w a t e r i n t h e w h i t e k i t c h e n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m e n b e c o m e a g i t a t e d a n d o n e l e a v e s w i t h s h i r t o f f', 't h e r e i s y e l l o w f o o d o n t h e w h i t e c o u n t e r', 't h e r e i s a t i t l e c a r d f a d e o u t t h e r e a r e t w o k i d s o n a c a m e l a t a c a r n i v a l p e o p l e p a s s t h e p e t t i n g z o o t h e r e i s a m o m t a k i n g p i c t u r e s o f t h e k i d s t h e e n d i n g c a r d i s s h o w n', 'a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s a r e f e r e e i s s t a n d i n g o n t h e g r e e n f i e l d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['c a r s a r e d r i v i n g o n a r o a d p e o p l e a r e s n o w b o a r d i n g d o w n a h i l l o f s n o w', 't h e p e r s o n r u n n i n g i s a g i r l w i t h y e l l o w h a i r a n d w h i t e s k i n', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r s t a n d i n g o n a g r e y s t r e e t', 't h e c u s t o m e r i s a w h i t e s k i n n e d m a n w h o i s s p e a k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n a d u l t c o n t e s t a n t w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g w a t e r p o l o w i t h a y e l l o w r u b b e r b a l l', 'a m a n w i t h y e l l o w s k i n i s s t a n d i n g o n t h e g r e e n f i e l d', 'a b l a c k s k i n n e d w o m a n w i t h b l a c k h a i r i s e a t i n g a b r o w n i c e c r e a m', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s e x e r c i s i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a l e i n s t r u c t o r w i t h b l a c k s k i n i s n e a r b y p e r s o n 2 a f e m a l e i n s t r u c t o r w i t h w h i t e s k i n a n d b l a c k h a i r', 'a s i l v e r p l a s t i c b r o o m t h e l o c a t i o n i s i n d o o r s a f t e r a w h i l e i t s l o c a t i o n i s o u t d o o r s', 't h e p e r s o n s p e a k i n g i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n w h o i s c o o k i n g i s a w o m a n w i t h w h i t e s k i n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a t i t l e s c r e e n a p p e a r s f o r a t u t o r i a l f o r h o c k e y a g i l i t y a n o t h e r t i t l e s c r e e n a p p e a r w i t h a w e b s i t e j u s t b e l o w t h e o b j e c t', 'a n a d u l t w i t h w h i t e s k i n i s s t a n d i n g o n t h e g r e y m e t a l e l l i p t i c a l m a c h i n e', 'a p e r s o n o b s e r v e s a n o l d s a m u r a i t e m p l e', 't h e c o l o r o f t h e c a k e i s y e l l o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r p e r s o n 2 a n o t h e r w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a s p o r t s m a n', 'p e r s o n 1 a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r i s e n g a g e d i n a c o n v e r s a t i o n w i t h p e r s o n 2 a w h i t e s k i n n e d m a n w i t h b l a c k h a i r', 't h e r e i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r o n t h e g r e e n r i v e r', 't h e r e i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r i n a c o u r t r o o m m a d e o f b r o w n w o o d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w a l l i s b l a c k', 't h e m a n t h r o w s t h e b a l l d o w n a n d h i t s s e v e r a l p i n s', 't h e w o m a n w i t h b l a c k h a i r w h o i s c o o k i n g h a s y e l l o w s k i n', 'a m a n w i t h w h i t e s k i n i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r i s s p e a k i n g', 't h e r e i s a w e b p a g e a n d t h e a d r e s s o f t h e c o m p a n y t h e r e a r e g r e e n s i g n s o n a p o l e w o m a n i s t a l k i n g o n t h e p h o n e i n s i d e a c a r s t o r e m a n i s p o l i s h i n g a b l a c k c a r w h i l e p e o p l e i s w a t c h i n g t h r e e c a r s a r e p a r k e d i n f r o n t o f t h e s t o r e', 'a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g', 'a b l a c k s k i n n e d s p o r t s m a n w i t h b l a c k h a i r i s j u m p i n g i n t o a y e l l o w p i t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a n a d u l t r e f e r e e w i t h b l a c k s k i n a n d b l a c k h a i r i s s t a n d i n g', 'p e o p l e p u t i n a w i n d o w a n d e n d b y c l o s i n g u p', 'a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s t h e o n e p e r f o r m i n g', 't h e b a r i s w h i t e i n c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k c a t t l e i s r u n n i n g o n a b l a c k s t r e e t', 't w o s m a l l c h i l d r e n a r e s e e n o u t s i d e b y a s w i n g s e t o n e m a n k i c k s t h e o t h e r b o y a n d h e b e n d s o v e r', 't h e r e i s a w o m a n w i t h y e l l o w s k i n a n d b l a c k h a i r s t a n d i n g o n t h e b l u e s t o n e b r i d g e', 'a b l a c k s k i n n e d m a n w i t h b l a c k h a i r i s t h r o w i n g a b l a c k v o l l e y b a l l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b l a d e i s b l a c k', 'a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r i s w e a r i n g a b l a c k m e t a l b l a d e', 't h e r e i s a m a n s t a n d i n g a n d h e i s a w h i t e s k i n n e d i n s t r u c t o r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a s p o r t s p e r s o n i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e y a r d i s g r a y', 't h e p e r s o n w h o i s e x e r c i s i n g i s a m a l e r a c e r', 't h e p e r s o n r i d i n g i s a w h i t e s k i n n e d b o y', 'a t r a n s p a r e n t r i v e r i s f l o w i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w i l d e b e e s t w a l k i n g i s b l a c k', 't h e h o r s e h a s a g r e y l i p a n d i s y e l l o w i n c o l o r', 'p e r s o n 1 a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a r e d p l a s t i c c u p a f t e r a w h i l e p e r s o n 2 a l s o a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a b l u e p l a s t i c b o t t l e o f m o u t h w a s h', 'a p e r s o n w i t h w h i t e s k i n i s l y i n g o n a b l a c k p l a s t i c c h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e b o a t w h i c h i s w h i t e a n d m a d e o f m e t a l i s r u n n i n g', 't h e r e i s a b r o w n w o o d e n b a r n e a r t h e p e r s o n w h o i s a w h i t e s k i n n e d w o m a n w i t h b l a c k h a i r', 'a w o m a n w i t h w h i t e s k i n a n d g o l d e n h a i r w h o i s a n a t h l e t e i s r u n n i n g', 'a s e c o n d m a n d o e s t h e s a m e a t h i r d m a n f o l l o w s t h e p e r s o n a f o u r t h m a n g o e s a f t e r t h e p e r s o n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m o u t h w h i c h i s w h i t e i s p a r t o f a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e f i e l d i s b l a c k', 't h e p e r s o n s p e a k i n g h a s f a i r s k i n a n d b l a c k h a i r a n d s h e i s a w o m a n', 't h e r e i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s w o r k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a p e r s o n s i t t i n g w i t h y e l l o w s k i n a n d b l a c k h a i r', 't h e r e i s a w h i t e s k i n n e d c o n t e s t a n t w h o i s s t a n d i n g', 'p e o p l e a r e h o l d i n g b a t o n s a s p e o p l e m a r c h p e o p l e w a l k a w a y o f f t h e c o u r t', 't h e h a n d t h a t i s w h i t e b e l o n g s t o a p e r s o n w h o h a s w h i t e s k i n a n d t o g e t h e r t h e y f o r m a w h o l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d w h i t e h a i r i s s t a n d i n g', 't h e c l o t h e s a r e w h i t e', 't h e r e i s a f l o w i n g r i v e r t h a t a p p e a r s b l u e', 'a s u m o w r e s t l e r c h a r a c t e r i z e d b y y e l l o w s k i n a n d b l a c k h a i r i s s t a n d i n g o n a b r o w n s t a g e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e m a n c o n t i n u e s r i d i n g a r o u n d w i t h t h e d o g', 'p e r s o n 1 a g i r l w i t h f a i r s k i n a n d y e l l o w h a i r i s w e a r i n g a w h i t e c l o t h c o s t u m e w h i l e p e r s o n 2 a g i r l w i t h f a i r s k i n a n d b l a c k h a i r i s a l s o w e a r i n g a w h i t e c l o t h c o s t u m e', 't h e r e i s a g i r l i n t h e p l a y g r o u n d w i t h w h i t e s k i n a n d b r o w n h a i r a n d t h e p l a y g r o u n d i t s e l f i s m a d e o f r e d m e t a l', 'p e r s o n 1 w h o i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s a p a r t o f p e r s o n 2 w h o i s a l s o a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s e x e r c i s i n g i s a w h i t e s k i n n e d m a n w i t h w h i t e h a i r a n d a b o a t e r h a t', 'a w o r k e r w i t h y e l l o w s k i n a n d b l a c k h a i r i s s q u a t t i n g o n a r e d m e t a l l a d d e r', 't h e s w i n g w h i c h i s b l a c k i n c o l o r i s m a d e o f m e t a l a n d h a n g s', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s i n a f i g h t w i t h p e r s o n 2 a l s o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o h a p p e n s t o b e a b a l l p l a y e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n i n t h e b l u e g y m w h o h a s w h i t e s k i n a n d b r o w n h a i r a n d h e i s a s p o r t s m a n', 't h e r e i s a b l a c k b r i d g e n e a r a w h i t e h i l l', 't h e b r o w n h o r s e h a s a h o r s e b a c k w h i c h i s a l s o b r o w n', 'a g r e e n r u b b e r k i c k b a l l i s n e a r a p e r s o n w h o i s a b l a c k b o y w i t h b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
[32m2023-10-19T20:05:27 | utils.basic_utils: [0mTrain Epoch: [0]  [ 500/2288]  eta: 0:24:39  lr: 0.000010  temperature: 0.0126  video-loss_ita: 1.3637  video-loss_itm: 0.6330  time: 0.7444  data: 0.0074  max mem: 7604 res mem: 7876
text in iter ['t h e f i e l d a p p e a r s t o b e g r e y', 't h e r e i s a w h i t e s k i n n e d m a n w h o h a p p e n s t o b e a b r i c k l a y e r o n t h e b r o w n r o o f', 't h e p e r s o n e x e r c i s i n g i s a s p o r t s m a n w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a b l a c k s k i n n e d m a n s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n w h o i s a p e r f o r m e r i s h o l d i n g a r e d c l o t h f l a g', 'a n o t h e r m a n p u l l s t h e s p r i n g b o a r d o u t o f t h e w a y a l a r g e c r o w d w a t c h e s f r o m t h e s t a n d s i n t h e g y m t h e g y m n a s t d o e s a p a r a l l e l b a r r o u t i n e s e v e r a l o t h e r m a l e g y m n a s t s w a l k a r o u n d i n t h e b a c k g r o u n d', 't h e s k i t h a t i s l e a n i n g i s b l a c k w h i t e a n d r e d', 't h e p e r s o n a d j u s t s a k n o b o n t h e v a c u u m c l e a n e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c u p i s b e i n g h e l d b y a w o m a n w i t h w h i t e s k i n y e l l o w h a i r w h o i s a b a r t e n d e r a n d t h e c u p i t s e l f i s m a d e o f s i l v e r m e t a l', 'a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r i s p l a y i n g a b l a c k m e t a l h a r m o n i c a', 'a g i r l w i t h w h i t e s k i n a n d g o l d h a i r i s t o u c h i n g a r e d m e t a l b a r', 't h e s c r a p e r i s m a d e o f p l a s t i c a n d h a s a g r e e n c o l o r w h i l e t h e c a r i s m a d e o f m e t a l a n d h a s a w h i t e c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s t o u c h i n g a g r e e n w o o d e n t a b l e', 'a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r i s h o l d i n g t h e b l a c k h o s e', 't h e p e r s o n e x e r c i s i n g i s a c o n t e s t a n t w h o i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r', 't h e r e i s a p e r s o n s t a n d i n g w h o i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e n a i l w h i c h i s w h i t e b e l o n g s t o a w o m a n c u s t o m e r w i t h b l a c k s k i n a n d b l a c k h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s t a n d i n g w h o i s a s w i m m e r', 'a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s d a n c i n g g r a c e f u l l y', 't h e l e a f i s b r o w n a n d i t i s f l y i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a p e r s o n s t a n d i n g h e i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r a n d h e i s a d r u m m e r', 'p e r s o n 1 a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 w h o i s a l s o a m a n w i t h y e l l o w s k i n a n d w o r k s a s a r e f e r e e', 't h e p e r s o n e x e r c i s i n g h a s w h i t e s k i n a n d b r o w n h a i r a n d h e i s a m a n', 'a w o m a n w i t h w h i t e s k i n b l a c k h a i r a n d a n a t h l e t i c b u i l d s t a n d s o n t h e g r e e n p l a s t i c f i e l d h o l d i n g a s i l v e r m e t a l d i s c u s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e s k i n n e d p e r s o n w i t h y e l l o w h a i r i n t h e w h i t e a r e n a', 'a g i r l w i t h y e l l o w s k i n a n d b l a c k h a i r i s h o l d i n g a v i o l i n m a d e o f b r o w n w o o d', 't h e p e r s o n k n e e l i n g i s a w o m a n w h o i s a d a n c e r w i t h w h i t e s k i n a n d b r o w n h a i r', 'a m a n o f b l a c k s k i n i s p l a y i n g a b r o w n w o o d e n f l u t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s t o u c h i n g t h e r e d b o x', 'p e r s o n 1 w h o i s a w o m a n w i t h w h i t e s k i n a n d g o l d h a i r i s n e a r p e r s o n 2 w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n w i t h b l a c k h a i r w h o i s s i t t i n g i s a m a n w i t h w h i t e s k i n', 't h e r e i s a g r e e n b u s h i n t h e p a i n t i n g a n d t h e p a i n t i n g i t s e l f i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n i s p u l l i n g a w h i t e m e t a l a r r o w', 't h e w o m a n b u c k l e s h e r s h o e s', 'a w h i t e s k i n n e d m a n w h o i s a c o o k i s t o u c h i n g t h e t r a n s p a r e n t g l a s s', 'a f i r e h a s e r u p t e d n e a r b y t h e c o l o r i s y e l l o w a f t e r a w h i l e i t s c o l o r i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d b o y i s s t a n d i n g', 't h e w o m a n i s t h e n s h o w n a l o n e a n d s h e b e g i n s t a l k i n g', 't h e p e r s o n h o l d i n g t h e t r o p h y i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r w h i l e t h e t r o p h y i t s e l f i s m a d e o f t r a n s p a r e n t g l a s s', 'w o m a n i s s t a n d i n g i n f r o n t o f a s c r e e n b o a r d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w h o i s w h i t e s k i n n e d w i t h b r o w n h a i r a n d h e i s a s p o r t s m a n h e i s c u r r e n t l y s t a n d i n g', 'a y e l l o w c a m e l i s s t a n d i n g', 't h e p e r s o n w i t h w h i t e s k i n w h o h a s b l a c k h a i r i s l y i n g', 't h e p e r s o n r e p a i r i n g h a s w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n r i d i n g t h e b r o w n h o r s e w i t h b l a c k h a i r i s a p o l i c e o f f i c e r a n d t h e y a r e w a l k i n g o n a g r e y s t r e e t', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s n e a r p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r a n d i s a n a u d i e n c e m e m b e r', 'w h o i s t h e m a l e c o n t e s t a n t t h a t i s r u n n i n g', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g', 't h e r e i s a r e d m e t a l c a r p a r k e d', 's e v e r a l c h i l d r e n s i t a l o n g a p o o l p e o p l e a r e a l l w e a r i n g f l i p p e r s a g i r l i s u n d e r w a t e r w e a r i n g s c u b a g e a r s e v e r a l c h i l d r e n p r a c t i c e w e a r i n g s c u b a g e a r', 't h e h o r s e i s b l a c k a n d l y i n g d o w n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a p a i r o f p a n t s m a d e f r o m g r e y c l o t h', 't h e p e r s o n e x e r c i s i n g i s a f e m a l e i n s t r u c t o r w i t h w h i t e s k i n a n d y e l l o w h a i r', 'a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s p l a y i n g b a s k e t b a l l w i t h a r e d r u b b e r b a l l', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w e a r i n g a w h i t e j a c k e t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s i t t i n g i s a n a n n o u n c e r a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a p e r s o n w h o i s a f e m a l e w i t h f a i r s k i n a n d b l a c k h a i r a n d a l s o h a p p e n s t o b e a c h e e r l e a d e r t h e u p p e r _ c l o t h e s _ c o l o r i s r e d a f t e r a w h i l e h e r u p p e r _ c l o t h e s _ c o l o r i s b l a c k', 't h e r e i s a s u r f e r s t a n d i n g o n a b l a c k s u r f b o a r d w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e p e r s o n s t a n d i n g t h e r e i s a b o y w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k m e t a l r o b o t i s f i g h t i n g a n o t h e r r o b o t', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s d r i n k i n g', 't h e r e i s a w h i t e p v c a n d a t r a n s p a r e n t p v c', 't h e p e r s o n s t a n d i n g o v e r t h e r e i s a b o y w i t h y e l l o w s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e s k i n n e d m a n w i t h b l a c k h a i r i s s i t t i n g a n d h e i s a p e r f o r m e r', 'a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s s p e a k i n g h e i s a s p o r t s m a n', 'a m a n w i t h w h i t e s k i n i s p o i n t i n g a t t h e c o m p u t e r w h i c h i s m a d e o f w h i t e m e t a l', 't h e r e i s a w h i t e b o a t r u n n i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w h i t e e a r i s a p a r t o f a g i r l w h o h a s w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n w e a r i n g t h e c l o t h e s a p p e a r s t o b e a m a n w i t h b l a c k s k i n a n d b l a c k h a i r t h e c l o t h e s t h e m s e l v e s a r e m a d e o f b l a c k c l o t h', 't h e r e i s a b l a c k c a b l e h a n g i n g', 'p e r s o n 1 a w h i t e s k i n n e d m a l e s w i m m e r i s e n g a g e d i n a d i s p u t e w i t h p e r s o n 2 a n o t h e r w h i t e s k i n n e d m a l e s w i m m e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s d r i n k i n g t r a n s p a r e n t w a t e r', 't h e p e r s o n w h o h a s w h i t e s k i n a n d b r o w n h a i r i s a s p o r t s m a n c u r r e n t l y e n g a g e d i n e x e r c i s e', 't h e r o o f i s g r a y', 't h e p e r s o n w h o h a s b l a c k h a i r i s a m a n w i t h w h i t e s k i n a n d h e i s s m i l i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e o p l e r e d o t h e a r m w r e s t l i n g', 'a m o n t a g e o f c a n o e s p r i n t i n g i s s h o w n t h e w i n n e r s c e l e b r a t e a n d b o t h m e n s a n d w o m e n s a r e s h o w n', 'a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r i s s q u a t t i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r h o l d i n g a b l a c k r u b b e r p i p e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a w h i t e w a v e f l o w i n g', 'a w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r i s p e r f o r m i n g a s a d a n c e r', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s i t t i n g w h o h a p p e n s t o b e a r e f e r e e', 'a n o l d m a n w i t h w h i t e s k i n a n d w h i t e h a i r i s p o i n t i n g a t a w h i t e b i r d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s o n t h e y e l l o w b e a c h', 'a d a n c e r p o s i t i o n s h e r s e l f t o b e g i n h e r d a n c e t h e d a n c e r p e r f o r m s h e r d a n c e r o u t i n e h o l d i n g a w a n d t h e w o m a n t a k e s a b o w f i n i s h i n g h e r d a n c e', 't h e d a n c e r w h o i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r i s d a n c i n g', 'a b l a c k s k i n n e d m a n i s s p e a k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s n e a r p e r s o n 2 a w o m a n w i t h w h i t e s k i n', 't h e f o o t i s a p a r t o f a p e r s o n s p e c i f i c a l l y a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'b l a c k h o r s e h a i r w h i c h i s p a r t o f t h e h o r s e i s b l a c k', 'a n o l d m a n w i t h w h i t e h a i r w h o h a s w h i t e s k i n i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w i t h b l a c k s k i n w h o i s o u t d o o r s i n a g r e e n f i e l d i s l a t e r i n d o o r s', 't h e r e i s a y e l l o w b r e a d o n a b l u e c e r a m i c d i s h', 't h e r e i s a m a n w i t h w h i t e s k i n s t a n d i n g h e h a s b r o w n h a i r', 'a p e r s o n i s s p e a k i n g w h o i s a w h i t e s k i n n e d c o n t e s t a n t w i t h b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h y e l l o w s k i n a n d g o l d h a i r s t a n d i n g w h o i s a c o n t e s t a n t', 't h e b u s h i s g r e e n', 'a g i r l w i t h f a i r s k i n a n d b r o w n h a i r r a i s e s h e r f i n g e r w h i c h i s a l s o f a i r i n c o l o r a f t e r a w h i l e s h e h o l d s a y e l l o w l e m o n', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r n e a r a b l u e p i t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s m o k i n g t h e w h i t e s m o k e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a p e r s o n w i t h f a i r s k i n a n d b l a c k h a i r i s p l a y i n g a d r u m s e t m a d e o f s i l v e r m e t a l a f t e r s o m e t i m e h e c o n t i n u e s p l a y i n g t h e s i l v e r m e t a l d r u m', 't h e p e r s o n s t a n d i n g i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a b r o w n b a r a n d a t r a n s p a r e n t b o t t l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w a l k i n g', 't h e r e i s a b l a c k s a i l o n t h e b o a r d w h i c h i s m a d e o f w h i t e w o o d', 't h e b l a c k a n d w h i t e c u e t o u c h e s t h e y e l l o w b l a c k a n d w h i t e s h u f f l e b o a r d', 't h e c o n t e s t a n t c l i m b i n g i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n i s s h o w n t a l k i n g i n h e r k i t c h e n', 'p e r s o n 1 w h o i s a m a l e a c t o r w i t h y e l l o w s k i n i s s t a n d i n g c l o s e t o p e r s o n 2 w h o i s a l s o a m a l e a c t o r w i t h y e l l o w s k i n a n d b l a c k h a i r', 't h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s i t t i n g i n t h e a u d i e n c e', 't w o k i d s a r e j u m p r o p i n g o u t s i d e t h e w o m a n i s t a l k i n g t o t h e c a m e r a']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g t h e r e d c l o t h s h i r t', 'a l e g i s p a r t o f a w o m a n w h o i s a n i n s t r u c t o r w i t h w h i t e s k i n a n d b r o w n h a i r a n d t h e l e g i s a l s o w h i t e i n c o l o r', 'a p e r s o n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g w h i l e a b l a c k s t o n e c u r l i n g i s s l i d i n g', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a p e r f o r m e r i s n e a r p e r s o n 2 a n o t h e r m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s a l s o a p e r f o r m e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c u p i s b e i n g h e l d b y a m a n w h o i s w h i t e s k i n n e d w i t h b r o w n h a i r h e i s t h e d r i v e r', 't h e f o o t w h i c h i s w h i t e i s a p a r t o f t h e p e r s o n w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r c o m p e t i n g a s a c o n t e s t a n t', 't h e r e i s a m a n s t a n d i n g w h o h a s w h i t e s k i n a n d b r o w n h a i r a n d i s a p e r f o r m e r', 'a n o l d m a n w i t h w h i t e h a i r a n d w h i t e s k i n i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a c o n t e s t a n t w i t h w h i t e s k i n a n d b l a c k h a i r i s t h e p e r s o n w h o i s l y i n g', 't h e p e r s o n p o u r s l i q u i d s o v e r a g l a s s f i l l e d w i t h i c e t h e p e r s o n t h e n g a r n i s h e s t h e f i n a l p r o d u c t f o r s e r v i n g', 'a g i r l k n o c k s o n a d o o r b u t n o b o d y a n s w e r s t h e p e r s o n f i g h t s a n d t h e n b o t h g i r l s s e p a r a t e', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d g o l d e n h a i r i s p o s i t i o n e d c l o s e t o p e r s o n 2 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h r e e d i f f e r e n t w o m e n a r e s h o w n i n s u c c e s s i o n e a c h w o m a n i s s e a t e d p l a y i n g d r u m s a n d c y m b a l s', 't h e c o l o r o f t h e d r i n k i s y e l l o w', 'a m a n i s h o l d i n g a b l a c k p l a s t i c b r u s h w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n s p e a k i n g i s a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r a n d s h e i s a d a n c e r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e w o m a n p e r f o r m e r w i t h w h i t e s k i n a n d b l a c k h a i r i s h o l d i n g a p a i r o f b r o w n c l o t h p a n t s', 't h e p e r s o n w e a r i n g t h e g r e y t s h i r t i s a w o m a n s h e h a s w h i t e s k i n a n d g o l d h a i r a n d s h e w o r k s a s a c r o s s c o u n t r y d r i v e r', 'a w h i t e r i v e r i s f l o w i n g', 'a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n w i t h y e l l o w s k i n a n d b l a c k h a i r t h e u p p e r _ c l o t h e s _ t y p e i s c o a t a f t e r a w h i l e h i s u p p e r _ c l o t h e s _ t y p e i s t s h i r t', 't h e c a r w a s h e r a p e r s o n w i t h y e l l o w s k i n a n d b l a c k h a i r i s w i p i n g t h e s i l v e r r u b b e r t i r e', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g a s i l v e r m e t a l b o w l', 'f o u r p e o p l e a r e d o i n g s i t u p s o n t h e g r o u n d t h e t h i r d p e r s o n i s p a u s e d t h e f a r t h e s t p e r s o n i s b a r e l y v i s i b l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s i t t i n g i n t h e a u d i e n c e i s a m a n w i t h w h i t e s k i n', 't h e l a n e i s a r e d p l a s t i c p a r t o f t h e t r a c k', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s c l i m b i n g t h e b r o w n s t o n e r o c k', 'm a n b e g i n s t o r i p u p c a r p e t u n d e r l a y t h e p e r s o n m e a s u r e s t h e s l a t t o p u t b e t w e e n t h e d o o r o p e n i n g t h e p e r s o n p l a c e s m a t e r i a l s u n d e r n e a t h t h e c a r p e t u n d e r l a y t h e p e r s o n p u t s a w o o d e n s l a t i n t h e d o o r e n t r a n c e t h e p e r s o n p i c k s t h e s l a t u p t h e p e r s o n c u t s t h e s l a t t h e p e r s o n l a y s t h e s l a t d o w n a g a i n t h e p e r s o n d r i l l s t h e o b j e c t i n t o p l a c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n w i t h w h i t e s k i n a n d b l a c k h a i r i s s q u a t t i n g', 'a m a n i s o u t s i d e w i t h t w o d o g s o n l e a s h e s t h e p e r s o n p u t s o n a s h o w w i t h t h e t r a i n e d d o g s', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g o n t h e b l a c k r o o f', 't h e r e i s a m a n s t a n d i n g w h o h a s w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r s i t t i n g a m o n g t h e a u d i e n c e', 'a g r e y w o o d i s i n t h e f o r e s t w h i c h i s g r e y w o o d a f t e r a w h i l e i t i s n e a r t h e f o r e s t', 'a n a d u l t w i t h w h i t e s k i n i s s k i i n g', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s p o r t s m a n i s p l a y i n g w i t h a w h i t e m e t a l h a m m e r a f t e r s o m e t i m e a n o t h e r m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s e e n s t a n d i n g o n t h e g r e e n f i e l d']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h o r s e w a l k i n g i s b r o w n', 't h e r e i s a m a n w i t h w h i t e s k i n s t a n d i n g o n a b l a c k w o o d e n s k a t e b o a r d', 't h e i n s t r u c t o r i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s w a l k i n g', 'a c o n t e s t a n t a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s p l a y i n g w i t h a r e d p l a s t i c r u b i k s c u b e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a p e r f o r m e r i s p l a y i n g w i t h a r e d p l a s t i c r u b i k s c u b e', 'a w h i t e p a s t e i s n e a r a w o m a n w i t h f a i r s k i n a n d b l a c k h a i r', 'p e r s o n 1 a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g c l o s e t o p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a g i r l w i t h w h i t e s k i n a n d y e l l o w h a i r i s h o l d i n g a b l a c k m e t a l h a n d l e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c o n t e s t a n t w h o i s r a c i n g i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r', 'p e r s o n 1 i s a c h e e r l e a d e r a w h i t e s k i n n e d w o m a n w i t h y e l l o w h a i r w h o i s n e a r p e r s o n 2 a n o t h e r w h i t e s k i n n e d w o m a n w i t h b r o w n h a i r', 'a m a n w i t h b l a c k h a i r a n d b l a c k s k i n i s e x e r c i s i n g', 't h e f a c e w h i c h h a s b l a c k s k i n a n d b l a c k h a i r b e l o n g s t o a g i r l w h o i s b l a c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n e x e r c i s i n g i s a w h i t e s k i n n e d s p o r t s m a n', 'a c h e e r l e a d e r a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g o n t h e b l u e f i e l d', 'a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s s i t t i n g', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s w a l k i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s w h i t e g l u e o n t h e w h i t e m e t a l r o o f', 't h e s c e n e r y i n c l u d e s a b r o w n w o o d e n t r e e a n d g r e e n s u r r o u n d i n g s', 't h e p e r f o r m e r i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d h e i s c u r r e n t l y s t a n d i n g', 't h e r e i s a w h i t e s k i n n e d w o m a n s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s s p e a k i n g i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d i s a s p o r t s m a n', 't h e p e r s o n w i t h b l a c k h a i r w h o i s a m a n w i t h y e l l o w s k i n i s c u r r e n t l y e x e r c i s i n g', 't h e r e i s a m a n s t a n d i n g w h o i s a p e r f o r m e r w i t h w h i t e s k i n', 'a w o m a n w i t h w h i t e s k i n i s p a i n t i n g o n a g r e y c a n v a s']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s k n e e l i n g', 't h e p e r s o n e x e r c i s i n g h a s f a i r s k i n a n d b l a c k h a i r', 'a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r i s t h r o w i n g a w h i t e t o y', 'a b l a c k d o g i s c h a s i n g a b l u e p l a s t i c f r i s b e e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h a i r t h a t b e l o n g s t o t h e w o m a n i s b r o w n i n c o l o r a n d i t i s c o n s i d e r e d a p a r t o f h e r p h y s i c a l a p p e a r a n c e w h i c h a l s o i n c l u d e s h e r w h i t e s k i n', 't h e p e r s o n w h o i s a w h i t e s k i n n e d m a n w i t h b r o w n h a i r i s r e p a i r i n g t h e g r e e n m e t a l b i k e', 'o n t h e b l a c k r o o f s t a n d s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a b l u e w a l l n e a r a n e l d e r l y m a n w i t h w h i t e s k i n a n d w h i t e h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a b l a c k s k i n n e d w o m a n w i t h b l a c k h a i r t h e a c c e s s o r y i s g l a s s e s a f t e r a w h i l e h e r a c c e s s o r y i s b r a c e l e t', 'a w h i t e s k i n n e d m a n i s k n e e l i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r o n a g r e e n l a k e', 'p e o p l e a r e p a i n t i n g a w o o d e n f e n c e i n a y a r d a d o g w a l k s b e h i n d t h e m p e o p l e c o n t i n u e p a i n t i n g t h e f e n c e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a p e r s o n w h o h a s w h i t e s k i n a n d y e l l o w h a i r i s s p e a k i n g', 't h e r e i s a p e r s o n i n t h e a r e n a w h o i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r s e r v i n g a s t h e r e f e r e e t h e a r e n a i t s e l f i s w h i t e', 'p e r s o n 1 a m a l e d a n c e r w i t h b l a c k s k i n a n d b l a c k h a i r i s d a n c i n g w i t h p e r s o n 2 a f e m a l e d a n c e r w i t h w h i t e s k i n a n d b l a c k h a i r', 'p e r s o n 1 w h o i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s i n c l o s e p r o x i m i t y t o p e r s o n 2 w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a w o m a n w i t h w h i t e s k i n a n d y e l l o w h a i r i s f i r s t h o l d i n g a b l u e m e t a l b r u s h a n d l a t e r t r a n s i t i o n s t o h o l d i n g a b l a c k m e t a l r o l l e r', 't h e c o n t e s t a n t a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s h o l d i n g t h e w h i t e r o p e', 't h e p e r s o n w i t h w h i t e s k i n a n d b r o w n h a i r i s w e a r i n g a g r e e n k i l t w h i l e p l a y i n g a b l a c k w o o d e n b a g p i p e', 'a w o m a n w i t h w h i t e s k i n i s w a s h i n g a b o w l a n d a f t e r s o m e t i m e s h e s t a n d s u p']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p e r f o r m i n g', 't h e r e i s a s i l v e r m e t a l s i n k n e a r a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r', 't h e r e i s a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r w h o i s r u n n i n g', 'a y e l l o w c l o t h i s b e i n g u s e d t o w i p e a t r a n s p a r e n t g l a s s w i n d o w']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e c r e d i t s o f t h e c l i p a r e s h o w n g u y s t h r o w b a l l s o n a f i e l d a g u y h o l d s a f e w b a l l s a n d t a l k s t w o m e n s i t w i t h o n e m a n h o l d i n g a f l a t b a t g u y s h i t b a l l s w i t h t h e f l a t b a t t h e c r e d i t s o f t h e v i d e o a r e s h o w n', 't h e r e i s a b l a c k r u b b e r b o a r d n e a r t h e w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a b o y w i t h w h i t e s k i n a n d b r o w n h a i r i s d r i v i n g a g r e e n m e t a l c a r', 't h e c o l o r o f i c e c r e a m i s b r o w n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o h a s f a i r s k i n a n d b r o w n h a i r i s r u n n i n g o n t h e y e l l o w b e a c h a f t e r a w h i l e p e r s o n 2 a l s o w i t h f a i r s k i n a n d b r o w n h a i r s t a r t s p l a y i n g f o o t b a l l w i t h a y e l l o w r u b b e r b a l l', 'a w h i t e p l a s t i c b i l l i a r d b a l l i s o n a t a b l e m a d e o f b l u e w o o d', 't h e r e i s a m a n i n t h e r e d r o o m w i t h w h i t e s k i n a n d b l a c k h a i r', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r o n t h e w h i t e h i l l']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h a n d a p p e a r s y e l l o w', 'p e r s o n 1 a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d a w o r k e r i s s q u a t t i n g a f t e r p e r s o n 2 a l s o a w h i t e s k i n n e d m a n w i t h b r o w n h a i r a n d a w o r k e r h a s f i n i s h e d w o r k i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d h e i s s t a n d i n g', 'a m a n w i t h y e l l o w s k i n a n d b l a c k h a i r i s s i t t i n g w h o i s a c o n t e s t a n t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e s k y s c o l o r v a r i e s g r e a t l y d e p e n d i n g o n t h e t i m e o f d a y a n d w e a t h e r c o n d i t i o n s t h e c o l o r i s g r e e n a f t e r a w h i l e i t s c o l o r i s b l u e', 'a w h i t e s k i n n e d s p o r t s m a n i s w a l k i n g', 't h e r e i s a m a n w i t h w h i t e s k i n a n d y e l l o w h a i r w h o i s w a l k i n g', 'a m a n w i t h w h i t e s k i n i s h o l d i n g a r e d w o o d e n s t i c k']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n w h o i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r h a s a b l a c k t a t t o o a s a p a r t o f h i s b o d y', 't h e p e r s o n d a n c i n g i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r', 'a m a n i s b e n t d o w n o n a m a t t h e p e r s o n d r o p s t h e w e i g h t o n t o t h e g r o u n d a m a n i n a b l u e s h i r t c l a p s', 'a w h i t e s k i n n e d w o m a n w i t h g o l d e n h a i r w h o i s a n a i l a r t i s t i s s i t t i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s o m e r s a u l t i n g i s a s p o r t s m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e p e r s o n s t a n d i n g i s a c o n t e s t a n t w h o h a s y e l l o w s k i n a n d b l a c k h a i r', 'a p i n k p i n a t a m a d e o f b r o w n w o o d i s h a n g i n g o n t h e t r e e', 'a m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s s t a n d i n g o n a g r e y s t r e e t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e s i g n w h i c h i s g r e e n i n c o l o r i s m a d e o f m e t a l a n d i s h a n g i n g', 'a g r o u p o f p e o p l e s t a n d b e h i n d a m a s t e r y o g i t h e p e r s o n i n s t r u c t s p e o p l e o n p o s i t i o n a n d l e a d s t h e m i n y o g a p e o p l e p e r f o r m s e v e r a l m o v e s s l o w l y a n d g r a c e f u l l y', 't h e p e r s o n h a s w h i t e s k i n a n d b l a c k h a i r a n d h e i s c u r r e n t l y s p e a k i n g', 'a p e r s o n w i t h a f a i r c o m p l e x i o n a n d g r e y h a i r i s c o o k i n g t h e a g e & s e x i s o l d m a n a f t e r a w h i l e a g e & s e x i s m a n']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n s p e a k i n g w h o h a s w h i t e s k i n a n d y e l l o w h a i r a n d i s w e a r i n g a b o a t e r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r w h o i s a b a l l p l a y e r t h e u p p e r _ c l o t h e s _ c o l o r i s w h i t e a f t e r a w h i l e h i s u p p e r _ c l o t h e s _ c o l o r i s b l a c k', 't h e r e i s a p e r s o n o n t h e r o p e a m a n w i t h w h i t e s k i n a n d b l a c k h a i r a n d t h e r o p e i s m a d e o f b l a c k n y l o n', 't h e r e i s a g i r l w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s s t a n d i n g s h e i s a s t u d e n t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e r e i s a m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s a s u m o w r e s t l e r s t a n d i n g o n t h e y e l l o w a r e n a', 't h e w a i s t i s b l a c k', 'a g i r l w i t h y e l l o w h a i r i s w a s h i n g a t r a n s p a r e n t p l a s t i c p l a t e', 'a h i l l g e n t l y s l o p e d d o w n i n t o t h e v a l l e y t h e c o l o r i s b r o w n a f t e r a w h i l e i t s c o l o r i s w h i t e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e h a n d i s a p a r t o f t h e p e r s o n t h e p e r s o n i s a w h i t e s k i n n e d g o l d h a i r e d w o m a n w h o i s a s p o r t s m a n', 't h e r e i s a m a n w i t h b l a c k s k i n a n d b l a c k h a i r w h o i s c u r r e n t l y e x e r c i s i n g', 't h e p e r s o n h o l d i n g t h e k i t e i s a n o l d m a n w i t h w h i t e s k i n w h i l e t h e k i t e i t s e l f i s m a d e o f g r e e n p l a s t i c', 'a n i r o n w h i c h i s a r e d m e t a l i s c u r r e n t l y i n u s e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n w i t h b l a c k s k i n a n d b l a c k h a i r w h o i s a s k a t e r i s j u m p i n g o n t h e g r e y s t o n e s t a i r s', 'a m a n a n d w o m a n a r e s i t t i n g o n a s t a g e t o g e t h e r p e o p l e a r e t a l k i n g a b o u t t h e t a n g o d a n c e p e o p l e s p i n a n d t w i r l b e f o r e a n a u d i e n c e', 't h e l o b s t e r i s g r e e n', 'p e r s o n 1 a w h i t e s k i n n e d m a l e c o n t e s t a n t i s i n c l o s e p r o x i m i t y t o p e r s o n 2 a w h i t e s k i n n e d m a l e r e f e r e e']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s d a n c i n g w i t h p e r s o n 2 w h o i s a w o m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e r e i s a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r w h o i s c u r r e n t l y w o r k i n g', 'p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s c l o s e t o p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 'a m a n w i t h w h i t e s k i n a n d b r o w n h a i r i s s t a n d i n g']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['a m a n i s c e l e b r a t i n g w i t h h i s a r m s i n t h e a i r t h e p e r s o n i s s h o w n s p i n n i n g o n a f i e l d', 't h e r e i s a m a n i n t h e a u d i e n c e s i t t i n g a n d h a v i n g w h i t e s k i n a n d b l a c k h a i r', 't h e i n s t r u c t o r d e m o n s t r a t e s a s p o t t u r n b a l l e t t u r n s', 'a b l a c k b u l l i s e n g a g e d i n a f i g h t']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t h e p e r s o n s t a n d i n g i s a g i r l w i t h w h i t e s k i n a n d b r o w n h a i r', 'a m a n i s a n i n d i v i d u a l w h o i d e n t i f i e s a s m a l e t h e s k i n _ c o l o r i s w h i t e a f t e r a w h i l e h i s s k i n _ c o l o r i s y e l l o w', 'a b o y w i t h w h i t e s k i n a n d b l a c k h a i r w h o h a p p e n s t o b e a b a l l p l a y e r i s o n t h e y e l l o w f i e l d', 'a p e r s o n w i t h f a i r s k i n a n d b r o w n h a i r i s s t a n d i n g o n a b r o w n l e a f a n d a f t e r a w h i l e t h e y b e g i n w a l k i n g o n t h a t s a m e b r o w n l e a f']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 w h o i s a m a n w i t h w h i t e s k i n b r o w n h a i r a n d a p e r f o r m e r i s s t a n d i n g n e a r p e r s o n 2 w h o i s a l s o a m a n w i t h w h i t e s k i n a n d b r o w n h a i r', 't h e w o m a n w i t h b l a c k h a i r i s a s p o r t s w o m a n w h o h a s w h i t e s k i n a n d i s c u r r e n t l y e x e r c i s i n g', 'a g r o u p o f p e o p l e a r e o n a n o b s t a c l e c o u r s e t o g e t h e r', 't h e r o o f h a s a y e l l o w c o l o r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['t w o m e n a r e t a l k i n g i n f r o n t o f a h e l i c o p t e r', 'i t s e e m s l i k e h e i s b e i n g j u d g e d f o r a t o u r n a m e n t t h e p e r s o n l a n d s a n d p o s e s a n d t h e a u d i e n c e i s s h o w n', 't i t l e c a r d s f l a s h a c r o s s t h e s c r e e n i m a g e s o f r a f t s a r e s h o w n p e o p l e s i t t i n g i n t h e i r r a f t t h e n s t a r t r o w i n g a w a t e r f a l l s p i l l s i n t o t h e r a f t t w o b o a t s o f r a f t e r s r a f t d o w n a r i v e r t h e f i r s t b o a t s p l a s h e s t h e r e a r b o a t t h e r a f t e r s s p l a s h e a c h o t h e r a v a n i s d r i v i n g d o w n t h e r o a d t h e e n d t i t l e c a r d a p p e a r s o n t h e s c r e e n', 'a m a n w i t h w h i t e s k i n i s p l a y i n g a b l a c k w o o d e n g u i t a r']
text in forward torch.Size([4, 60, 768])
pooled_text_embeds in forward torch.Size([4, 768])
image in forward torch.Size([4, 788, 768])
pooled_image_embeds in forward torch.Size([4, 4, 768])
text_feat in get_sim torch.Size([4, 256])
image_feat in get_sim torch.Size([4, 4, 256])
sim_i2t_targets in get_contrastive_loss tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]], device='cuda:0')
text in iter ['p e r s o n 1 a w o m a n w i t h w h i t e s k i n a n d b l a c k h a i r i s p l a y i n g w i t h p e r s o n 2 a m a n w i t h w h i t e s k i n a n d b r o w n h a i r b o t h b e i n g s w i m m e r s', 'a w h i t e s k i n n e d m a n w h o i s a c r o s s c o u n t r y d r i v e r i s o n t h e y e l l o w r o a d', 'a w h i t e s k i n n e d m a n w i t h y e l l o w h a i r w h o i s a w o r k e r i s t o u c h i n g t h e b l a c k m e t a l b a r', 't h e r e i s a w h i t e s k i n n e d m a n w i t h b l a c k h a i r s t a n d i n g w h o h a p p e n s t o b e t h e r e f e r e e']
